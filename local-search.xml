<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>从零开始搭建Github博客(其一)</title>
    <link href="/2020/04/07/github%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2(%E4%B8%80)/"/>
    <url>/2020/04/07/github%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2(%E4%B8%80)/</url>
    
    <content type="html"><![CDATA[<h1 id="搭建-github-博客之旅-（Part-1）"><a href="#搭建-github-博客之旅-（Part-1）" class="headerlink" title="搭建 github 博客之旅 （Part 1）"></a>搭建 github 博客之旅 （Part 1）</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><details>    <summary>这废话蛮多的简介，可以跳过！</summary><p>搭建博客其实还是有很好处的，比如随时记录自己的<code>idea</code>，记录学习过程，让别人了解你,etc…<br>搭建博客的方式有很多，但是必不可少的肯定是：</p><ul><li>服务器</li><li>前端页面  </li></ul><p>没有服务器，怎么办？我们有 <code>Github Pages</code>。<br>前端页面写起来太麻烦？ 我们有 <code>hexo or jekyll</code>。<br>部署麻烦？我们有 <code>travis</code> 自动部署。<br>emm,好像看起来很简单？就是避坑总结？ 没人看怎么办？<br><strong>当然没那么简单！</strong><br>我们再加点新东西，速度优化，自动化脚本，全部往上面加！话不多说，不要浪费自己的计数能力，就是冲！<br>综上，所以有了我们这个小系列文章，越看越精彩！</p></details><h2 id="Github-Pages"><a href="#Github-Pages" class="headerlink" title="Github Pages"></a>Github Pages</h2><h3 id="1-GithubPages-简介"><a href="#1-GithubPages-简介" class="headerlink" title="1. GithubPages 简介"></a>1. GithubPages 简介</h3><details><summary>Github Pages是...</summary><blockquote><p>GitHub Pages 是一项静态站点托管服务，它直接从 GitHub 上的仓库获取 HTML、CSS 和 JavaScript 文件，（可选）通过构建过程运行文件，然后发布网站。 您可以在 <a href="https://github.com/collections/github-pages-examples" target="_blank" rel="noopener">GitHub Pages 示例集合</a>中查看 GitHub Pages 站点的示例。<br> 您可以在 GitHub 的 github.io 域或自己的自定义域上托管站点。 更多信息请参阅“对 GitHub Pages 使用自定义域”。</p></blockquote><p>通俗的说，就是你可以把一个仓库当作<strong>一台服务器(静态)</strong>，可以用 <code>github.io</code> 的域名来访问。<br>这就解决我们的服务器问题了！  </p><p><code>Github Pages</code> 有三类——项目、用户和组织。<br>区别不大，主要是域名及发布分支的区别。<br>我们教程使用的 <code>Github Pages</code> 是用户类，默认发布源只能为 <code>master</code>。（这里要注意哦，只能为 <code>master</code>，发布目录为根目录或者 <code>/docs</code>）<br>So，我们开始吧。</p></details><h3 id="2-创建-Github-Pages"><a href="#2-创建-Github-Pages" class="headerlink" title="2. 创建 Github Pages"></a>2. 创建 <code>Github Pages</code></h3><ul><li>a. 创建<code>Github Pages</code>仓库，名字为 <code>&lt;username&gt;.github.io</code>。 <a href="https://help.github.com/cn/github/working-with-github-pages/creating-a-github-pages-site" target="_blank" rel="noopener">详细教程</a></li><li>b. 克隆创建的仓库<br><code>git clone https://github.com/username/username.github.io</code></li><li>c. 创建页面文件并部署页面<pre><code class="bash"> cd username.github.io   echo &quot;my first page in git hub&quot; &gt; index.html  # 创建 index.html 文件 # 开始部署 git add --all  git commit -m &quot;init first page&quot; git push -u origin master  # 推到 master 分支后相当于自动部署</code></pre> 做完上述操作后，我们打开<a href="">你的站点页面(https://username.github.io)</a><br> 就能看到我们的创建的网站～不过目前只有一句话。</li></ul><h3 id="3-总结"><a href="#3-总结" class="headerlink" title="3. 总结"></a>3. 总结</h3><p><code>Github Pages</code>就相当于一个<strong>独立站点</strong>，从上面的操作步骤可以看出。展示内容与我们的仓库内容相关。尤其是 <code>index.html</code>。<br>那么，我们就有很多发挥空间了。<br>编写静态博客太麻烦？<br>上 <code>Hexo</code> ！</p><h2 id="Hexo"><a href="#Hexo" class="headerlink" title="Hexo"></a>Hexo</h2><h3 id="1-Hexo-简介"><a href="#1-Hexo-简介" class="headerlink" title="1. Hexo 简介"></a>1. Hexo 简介</h3><details>  <summary>Hexo是...</summary><blockquote><p><code>Hexo</code> 是一个快速、简洁且高效的<strong>博客框架</strong>。<code>Hexo</code> 使用 <code>Markdown</code>（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。</p></blockquote><p>也就是说，我们不用从零开始编写静态网站，利用现有的博客生成器就可以了！<br>而且 支持 <code>Markdown</code>！写文档必备。<br>效果如何？马上来看。</p></details><h3 id="2-安装并生成博客"><a href="#2-安装并生成博客" class="headerlink" title="2. 安装并生成博客"></a>2. 安装并生成博客</h3><ul><li><h4 id="a-安装-hexo"><a href="#a-安装-hexo" class="headerlink" title="a. 安装 hexo"></a>a. 安装 <code>hexo</code></h4><pre><code>npm install -g hexo-cli</code></pre></li></ul><ul><li><h4 id="b-初始化-Hexo-博客"><a href="#b-初始化-Hexo-博客" class="headerlink" title="b. 初始化 Hexo 博客"></a>b. 初始化 <code>Hexo</code> 博客</h4><pre><code class="bash">   hexo init docs # docs 为文件夹名称   cd docs   npm install  # 安装相关依赖</code></pre><p>新建完成后，我们可以看到目录如下：</p><pre><code>   .   ├── _config.yml  # 配置文件   ├── package.json  # 安装依赖   ├── scaffolds  # 模版文件   ├── source  # 资源文件   |   ├── _drafts   |   └── _posts   └── themes  # 主题文件夹，根据不同主题生成不同的静态资源</code></pre></li><li><h4 id="c-开始写博客"><a href="#c-开始写博客" class="headerlink" title="c. 开始写博客"></a>c. 开始写博客</h4><p>我们根据模板创建一片文章<br><code>hexo new poster_name  # poster_name 为文章名字，当然都可以改</code><br>可以看到，运行命令之后，我们在 <code>source/_posts</code> 下生成了一个叫 <code>&lt;poster_name&gt;.md</code> 的文件。<br>这就是我们的博客文件，我们用 <code>Markdown</code> 语法简单测试一下。写入以下内容：</p><pre><code class="markdown">## 这是我的第一篇博客&gt; 引用能用吗？```python# 我是 python 代码a = 1print(a)```</code></pre></li><li><h4 id="d-实时博客效果"><a href="#d-实时博客效果" class="headerlink" title="d. 实时博客效果"></a>d. 实时博客效果</h4><p>文章写好了。怎么看效果呢？<br>我们运行 <code>hexo server</code> 即可。</p><pre><code class="bash">$ hexo server # or hexo sINFO  Start processingINFO  Hexo is running at http://localhost:4000 . Press Ctrl+C to stop.</code></pre><p>得到输出结果如上，打开 <a href="http://localhost:4000" target="_blank" rel="noopener">http://localhost:4000</a> 就能看到我们的页面了！</p><blockquote><p>待补图</p></blockquote><blockquote><p>我们更改一下我们的 <code>md</code> 文件，再刷新一下，就能<strong>实时</strong>看到效果。</p></blockquote></li><li><h4 id="e-生成静态站点并部署"><a href="#e-生成静态站点并部署" class="headerlink" title="e.生成静态站点并部署"></a>e.生成静态站点并部署</h4><p>博客预览ok，那么就可以准备生成静态站点文件了。<br>So，我们运行</p><pre><code class="bash">hexo generate # or hexo g</code></pre><p>就能看到有一堆文件产生，都放在了我们的 <code>public</code> 文件夹下面。<br>最重要的 <code>index.html</code> 也在其中。<br>那么问题来了，因为 <code>index.html</code> <strong>必须</strong>在 <code>/ or /docs</code> 目录下面。<br>而现在我们的目录结构是 <code>/docs/public/index.html</code> 。这样直接推上去肯定是不行的，那么怎么办呢？</p><blockquote><p>当然，解决办法有很多<br>例如：</p><ul><li>单开一个分支用来写，master 只用来部署，保留 public 文件夹内容。实现方式利用软连接即可，这样可以写一个分支，部署一个分支，做到分离。</li><li>改变 git 根目录，改变仓库位置。</li></ul></blockquote><p>这时候，就可以寄出我们的部署神器 <code>hexo-deployer-git</code><br>首先安装它（记得切换一个分支， 比如 <code>writing</code> ， 专门用来写文章）：</p><pre><code>npm install hexo-deployer-git</code></pre><p>之后编辑一下 <code>_config.yml</code>， 在末尾加上：</p><pre><code># Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: git@github.com:username/username.github.io.git branch: master</code></pre><p>之后运行</p><pre><code>hexo deploy # hexo d# 或者 生成加部署 hexo g &amp; d</code></pre><p>就能自动部署完成了！<br>一气呵成。</p></li></ul><p>那么第一篇就到这里(第一步踩坑完成)，之后我们会出第二篇，会加上一些小操作～来让我们写博客更简单！</p><blockquote><p>详细文档<br><a href="https://help.github.com/cn/github/working-with-github-pages/about-github-pages" target="_blank" rel="noopener">Github Pages 中文文档</a><br><a href="https://hexo.io/zh-cn/docs/" target="_blank" rel="noopener">Hexo 中文文档</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>blog</category>
      
    </categories>
    
    
    <tags>
      
      <tag>github_pages</tag>
      
      <tag>hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>iterators,generators,coroutines</title>
    <link href="/2020/04/07/iterators-generators-coroutines(tr)/"/>
    <url>/2020/04/07/iterators-generators-coroutines(tr)/</url>
    
    <content type="html"><![CDATA[<h2 id="Python-101-iterators-generators-coroutines"><a href="#Python-101-iterators-generators-coroutines" class="headerlink" title="Python 101: iterators,generators,coroutines"></a>Python 101: iterators,generators,coroutines</h2><blockquote><p>作者：<br>Mark McDonnell<br>发布时间: 2019-12-28<br>原文链接：<a href="https://www.integralist.co.uk/posts/python-generators/" target="_blank" rel="noopener">https://www.integralist.co.uk/posts/python-generators/</a>  </p><p>翻译:<br>Dustyposa  </p></blockquote><p>在这篇文章中，我将讨论一下什么是生成器<code>(generators)</code>以及和协程<code>(coroutines)</code>作比较，但是为了了解这两个概念<em>（生成器和协程）</em>我们需要回头看一看并了解迭代器<code>(Iterator)</code>的概念。<br>我们最终将会讨论…</p><ul><li><a href="#迭代器">迭代器(Iterators)</a><ul><li><a href="#为什么使用迭代器%3F">为什么要使用迭代器？</a></li><li><a href="#迭代器的实现">迭代器的实现</a></li><li><a href="#迭代器示例">迭代器示例</a></li></ul></li><li><a href="#生成器">生成器(Generators)</a><ul><li><a href="#为什么使用生成器？">为什么要使用生成器？</a></li><li><a href="#生成器的实现">生成器的实现</a></li><li><a href="#生成器示例">生成器示例</a></li><li><a href="#生成器表达式">生成器表达式</a></li><li><a href="#生成器嵌套（例如：yield-from）">嵌套生成器（例如:yield from）</a></li></ul></li><li><a href="#协程">协程(Coroutines)</a><ul><li><a href="#为什么使用协程？">为什么要使用协程？</a></li><li><a href="#协程的实现">协程的实现</a></li><li><a href="#协程示例">协程示例</a></li><li><a href="#Aysncio%3A-基于生成器的协程">Asyncio: 基于生成器的协程</a></li><li><a href="#Asyncio%3A-新的-async-协程">Asyncio: 新的 async 协程</a></li><li><a href="#协程的种类">协程的种类</a></li><li><a href="#其他方面">其他方面</a></li></ul></li></ul><p>每个章节都会引导到下一章节，所以这篇文章的最好的阅读方式就是按照默认章节的顺序。除非你已经熟悉前面的部分，更喜欢跳读。</p><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><hr><p>在之后我们将讨论的所有东西的摘要如下：</p><ul><li>迭代器允许你对自定义对象进行迭代</li><li>生成器构建于迭代器之上（它们较少了模版）。</li><li>生成器表达式比生成器更加简洁</li><li>协程就<em>是</em>生成器，但是协程的<code>yield</code>语句会接收一个值。</li><li>协程可以暂停和重新执行（对于并发来说是非常好的）</li></ul><blockquote><p>† think <a href="https://gist.github.com/e5310d1082b0ff8307e39b71a6f9bae5" target="_blank" rel="noopener">comprehensions</a>.</p></blockquote><h3 id="迭代器"><a href="#迭代器" class="headerlink" title="迭代器"></a>迭代器</h3><hr><p>根据官方<a href="https://docs.python.org/3.7/glossary.html#term-iterator" target="_blank" rel="noopener"><code>Python术语表</code></a>，<em>迭代器</em>是…  </p><blockquote><p>表示数据流的对象</p></blockquote><h3 id="为什么使用迭代器"><a href="#为什么使用迭代器" class="headerlink" title="为什么使用迭代器?"></a>为什么使用迭代器?</h3><p>迭代器是很有用的，因为它允许使用标准的<code>Python for-in</code>语法对任意自定义对象进行迭代。这就是内部列表和字典类型的工作方式，以及它们如何允许<code>for-in</code>对它们进行迭代。<br>更重要的是，迭代器（我们会发现）非常节省内存，这就意味着一次只能处理一个元素。因此，你可以有一个提供无限元素的序列可迭代对象并且你会发现你的程序永远不会耗尽内存分配。</p><h3 id="迭代器的实现"><a href="#迭代器的实现" class="headerlink" title="迭代器的实现"></a>迭代器的实现</h3><p>一个迭代器是（通常）是一个实现了<code>__iter__ and __next__</code><em>‘双下(dunder)’</em>方法，尽管<code>__next__</code>方法不需要作为定义了<code>__iter__</code>方法的对象的一部分被定义。让我澄清一下…</p><p><code>&#39;迭代器&#39;</code>实际上只是一些数据的容器。这个<code>&#39;容器&#39;</code>，根据*<a href="https://docs.python.org/3.7/library/stdtypes.html#iterator.__iter__" target="_blank" rel="noopener">协议文档(protocol documentation)</a>*必须有一个<code>__iter__</code>方法，应该返回一个可迭代对象（例如：一些含有<code>__next__</code>方法的东西）。<code>__next__</code>方法会在相关数据集中向前移动。</p><p>所以，你可以设计一个同时包含<code>__iter__ and __next__</code> 方法的单类<em>(single class)</em>(就像我在下面展示的)，或者你可能想把<code>__next__</code>方法定义为单独类的一部分（这取决于你感觉的什么是对于你项目来说最好的方式）。</p><blockquote><p>注意：<a href="https://docs.python.org/3.7/library/collections.abc.html#collections.abc.Iterator" target="_blank" rel="noopener">collections.abc</a>对应的<code>Python</code>文档强调了那些<code>Pytrhon</code>拥有的以及各种它们需要的方法(可以看一些<a href="https://www.integralist.co.uk/posts/python-code-design/#interfaces-protocols-and-abstract-methods" target="_blank" rel="noopener">我的早期文章</a>，详细讨论了<code>protocols + abstract classes</code>)其他<em>‘协议(protocols)’*。如果你对</em>‘双下’方法还部不熟悉，我给你推荐一篇很好的文章:<a href="https://rszalski.github.io/magicmethods/" target="_blank" rel="noopener">魔术方法指南</a>*</p></blockquote><p>通过实现这两个方法，能使<code>Python</code>迭代一个’集合(collection)’。它不关心集合是什么，只要迭代器对象定义了<code>Python</code>知道如何去迭代的行为。</p><h3 id="迭代器示例"><a href="#迭代器示例" class="headerlink" title="迭代器示例"></a>迭代器示例</h3><p>下面是一个样例，展示了如何创建这样的对象。在这个例子中，我们通过一个字符串列表传递给类的构造函数，该类实现了允许进行<code>for-in</code>迭代数据集合的相关方法。</p><pre><code class="python">class Foo:    def __init__(self, collection):        self.collection = collection        self.index = 0    def __iter__(self):        &quot;&quot;&quot;        我们返回 self，所以 &#39;iterator object&#39;就是 Foo 类实例的本身。        但是我们也可以返回一个完全不同的新的实例，只要另一个 class 在它上面定义了 __next__ 方法。        &quot;&quot;&quot;        print(&#39;iter be called&#39;)        return self    def __next__(self):        &quot;&quot;&quot;        这个方法处理状态并向迭代器容器通知我们目前指向的我们数据集合的位置        &quot;&quot;&quot;        if self.index &gt; len(self.collection) - 1:            raise StopIteration        value = self.collection[self.index]        self.index += 1        return value# 我们现在可以遍历我们的自定义 Foo 类了！for element in Foo([&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]):    print(element)</code></pre><blockquote><p>注意： 抛出 <code>StopIteration</code> 异常是正确实现一个迭代器的必要条件。</p></blockquote><p>在这个示例中，我们也可以<strong>手动</strong>迭代我们的<code>Foo</code>类，用<code>iter and next</code>函数，就像这样：</p><pre><code class="python">foo = Foo(list(&quot;abc&quot;))iterator = iter(foo)next(iterator)  # &#39;a&#39;next(iterator)  # &#39;b&#39;next(iterator)  # &#39;c&#39;</code></pre><blockquote><p>注意：<code>iter(foo)</code> 和 <code>foo.__iter__()</code>相同，而<code>next(iterator)</code> 和 <code>iterator.__next__()</code>相同——所以这些函数都是由标准库提供的基础语法糖，可以让我们的代码看起来更清爽。</p></blockquote><p>这种类型的迭代器被叫做’基于类的迭代器<code>(class-based iterator)</code>‘，不是唯一实现可迭代对象的方法。<a href="https://www.integralist.co.uk/posts/python-generators/#generators" target="_blank" rel="noopener">生成器</a>以及<a href="https://www.integralist.co.uk/posts/python-generators/#generator-expressions" target="_blank" rel="noopener">生成器表达式</a>(请参考以下章节)是另一些节省内存的迭代对象的方式。<br>我们也可以通过使用<code>list</code>方法提取所有集合，就像这样：</p><pre><code class="python">iterator = Foo(list(&quot;abc&quot;))list(iterator)</code></pre><blockquote><p>注意：小心点，因为如果迭代器产生无数的元素，之后就会耗尽你应用的所有内存！</p></blockquote><h3 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h3><hr><p>根据官方<a href="https://docs.python.org/3.7/library/stdtypes.html#generator-types" target="_blank" rel="noopener">Python文档</a>,’生成器’提供…</p><blockquote><p>一个简便的方式去实现可迭代协议。如果一个容器对象的<code>__iter__()</code>方法被作为一个生成器实现，它将会自动返回一个可迭代对象。</p></blockquote><h3 id="为什么使用生成器？"><a href="#为什么使用生成器？" class="headerlink" title="为什么使用生成器？"></a>为什么使用生成器？</h3><p>他们不仅为了创建简单的迭代器提供了很好的语法，而且可以帮助减少让一些东西可迭代所需的模版代码。</p><p>一个生成器可以帮助减少与’基于类’的迭代器相关的模版代码，因为他们可以被设计来去处理’状态管理(<code>state management</code>)’逻辑，否则你不得不自己编写。</p><h3 id="生成器的实现"><a href="#生成器的实现" class="headerlink" title="生成器的实现"></a>生成器的实现</h3><p>生成器是一个返回’生成器迭代器<code>(gerator iterator)</code>‘的函数，所以它的行为和<code>__iter__</code>工作方式类似（记住它返回一个迭代器）。</p><p>实际上，生成器是迭代器的子类。生成器函数本身应该利用<code>yield</code>语句将控制权返回给生成器函数的调用方。</p><p>调用方在之后可以通过<code>for-in</code>语句或者<code>next</code>函数来推进生成器迭代器（和我们之前的’基于类’的迭代器的例子中看到的那样），这再次突出了生成器实际上是迭代器的子类。</p><p>当生成器<code>yields</code>时，它实际上在那时候暂停了函数并返回了一个值。调用<code>next</code>（或者作为<code>for-in</code>的一部分）将会推进函数，要么移动到生成器函数结束或者在生成器函数中的下一个<code>yield</code>声明处停止。</p><h3 id="生成器示例"><a href="#生成器示例" class="headerlink" title="生成器示例"></a>生成器示例</h3><p>下面的例子将会先打印 <code>a</code>, 然后<code>b</code>，最后<code>c</code>：</p><pre><code class="python">def generator():    yield &quot;a&quot;    yield &quot;b&quot;    yield &quot;c&quot;for v in generator():    print(v)</code></pre><p>如果我们用<code>next()</code>函数作为替代，我们可以执行如下操作：</p><pre><code class="python">gen = generator()next(gen)  # anext(gen)  # bnext(gen)  # cnext(gen)  # raises StopIteration</code></pre><p>注意，和我们早期自定义’基于类’迭代器相比，我们已经大大的减少了我们的代码样板，因为不需要再去在类示例上定义<code>__iter__ and __next__</code>方法（我们自己也不需要管理任何状态）。我们简单地调用<code>yield</code>。</p><p>如果我们的使用足够简单，那么生成器就够了。否则如果我们需要执行非常特殊的逻辑，可能就需要自定义’基于类’的生成器了。</p><p>记住，迭代器（以及生成器扩展）是非常节省内存的，因此我们可以创建一个生成无限多元素的生成器，就像这样：</p><pre><code class="python">def unbouded_generator():    while True:        yield &quot;some value&quot;gen = unbouded_generator()next(gen)  # some valuenext(gen)  # some valuenext(gen)  # some valuenext(gen)  # some valuenext(gen)  # ...# 译者注，我们也可以关闭或者抛出异常来结束生成器，就像这样gen.close()next(gen)  # StopIterationgen.throw(ValueError(&quot;Too many balue&quot;))  # ValueError</code></pre><p>所以，就像我们之前提到的，当对生成器函数用<code>list()</code>的时候也要小心（见下面的例子），因为这将获取整个集合，可能耗尽你应用的内存。</p><pre><code class="python">def generator():    yield &quot;a&quot;    yield &quot;b&quot;    yield &quot;c&quot;gen = generator()list(gen)  # [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]</code></pre><h3 id="生成器表达式"><a href="#生成器表达式" class="headerlink" title="生成器表达式"></a>生成器表达式</h3><p>根据官方的<a href="https://www.python.org/dev/peps/pep-0289/" target="_blank" rel="noopener">PEP 289文档</a>，对于生成器表达式…</p><blockquote><p>生成器表达式是列表推导式的一个高性能，省内存的泛化。</p></blockquote><p>本质上它们是一种用与<a href="https://gist.github.com/e5310d1082b0ff8307e39b71a6f9bae5" target="_blank" rel="noopener">列表推导式</a>相似的语法创建生成器的方法。</p><p>以下是一个会打印<code>&quot;foo&quot;</code>5次的生成器函数的示例：</p><pre><code class="python">def generator(limit):    for i in range(limit):        yield &quot;foo&quot;for v in generator(5):    print(v)</code></pre><p>这和生成器表达式是一样的：</p><pre><code class="python">for v in (&quot;foo&quot; for i in range(5)):    print(v)</code></pre><p>生成器表达式的语法也和推导式的语法很相似，不同之处在我们使用<code>()</code>替代了边界/分界符<code>[] or {}</code>。</p><pre><code class="python">(expression for item in collection if condition)</code></pre><blockquote><p>注意： 尽管没有演示，因为支持<code>&quot;if&quot;</code>条件，你也可以过滤生成值。</p></blockquote><h3 id="生成器嵌套（例如：yield-from）"><a href="#生成器嵌套（例如：yield-from）" class="headerlink" title="生成器嵌套（例如：yield from）"></a>生成器嵌套（例如：yield from）</h3><p>Python 3.3 提供了 <code>yield from</code>语句，提供了一些基础语法糖来处理嵌套生成器。</p><p>让我们来看一下如果没有<code>yield from</code>我们需要怎么做：</p><pre><code class="python">def baz():    for i in range(10):        yield idef bar():    for i in range(5):        yield idef foo():    for v in bar():        yield v    for v in baz():        yield vfor v in foo():    print(v)</code></pre><p>注意我们有两个单独的<code>for-in</code>循环（在<code>foo</code>生成器函数中），每个循环对应一个嵌套生成器。</p><p>现在，让我们看看用<code>yield from</code>会怎样：</p><pre><code class="python">def baz():    for i in range(10):        yield idef bar():    for i in range(5):        yield idef foo():    yield from baz()    yield from bar()for v in foo():    print(v)</code></pre><p>Ok 这并不是很突出的功能，但是如果你曾经对<code>yield from</code>很疑惑，你现在知道了它是<code>for-in</code>语法的简单版外观。</p><p>尽管值得指出的是，如果我们没有<code>yield from</code>，我们仍然可以使用<code>itertool</code>模块的<code>chain()</code>函数来改写我们的原代码，就像这样：</p><pre><code class="python">from itertools import chaindef baz():    for i in range(10):        yield idef bar():    for i in range(5):        yield idef foo():    for v in chain(bar(), baz()):        yield vfor v in foo():    print(v)</code></pre><blockquote><p>注意：请参阅<a href="https://www.python.org/dev/peps/pep-0380/" target="_blank" rel="noopener">PEP 380</a>以获得更多关于<code>yield from</code>的详细信息，以及将其包含在·Python·语言中的基本原理。</p></blockquote><h3 id="协程"><a href="#协程" class="headerlink" title="协程"></a>协程</h3><hr><p>协程（就<code>Python</code>而言）一直被设计成生成器的扩展。</p><blockquote><p>协程是计算机程序的一类组件，推广了协作式多任务的子程序，允许执行被挂起与被恢复。—— 维基百科</p></blockquote><h3 id="为什么使用协程？"><a href="#为什么使用协程？" class="headerlink" title="为什么使用协程？"></a>为什么使用协程？</h3><p>因为协程可以暂停和恢复执行上下文，对于并发编程来说非常合适，因为它们可以让程序决定什么时候’切换上下文’。</p><p>这就是协程为什么经常被用来处理例如：<a href="https://www.integralist.co.uk/posts/python-asyncio/#event-loop" target="_blank" rel="noopener">事件循环</a>(构建于<code>Python</code>的 <code>asyncio</code>之上)。</p><h3 id="协程的实现"><a href="#协程的实现" class="headerlink" title="协程的实现"></a>协程的实现</h3><p>生成器用<code>yield</code>关键字在函数中在某时间点返回值，但是对于协程，<code>yield</code>指令<strong>也</strong>可以被用在<code>=</code>操作符的右边。表示它可以在这个时间点<strong>接收一个值</strong>。</p><h3 id="协程示例"><a href="#协程示例" class="headerlink" title="协程示例"></a>协程示例</h3><p>下面是一个协程的示例。记住！协程任然是一个生成器，所以你会看到我们的例子用了和生成器相关的特性（例如：<code>yield</code> 和 <code>next()</code>函数）：</p><blockquote><p>注意：请参考注释来提高可读性</p></blockquote><pre><code class="python">def foo():    &quot;&quot;&quot;    注意我们在传统的生成器和协程上都使用了 yield    &quot;&quot;&quot;    msg = yield  # 协程特性    yield msg  # 生成器特效coro = foo()# 因为一个协程是一个生成器，我们需要驱动返回的生成器到达生成器函数中的第一个 yieldnext(coro)# .send() 语法对于生成器来说是很特别的，这一句代表了向第一个yield 发送了 &quot;bar&quot;# msg 变量将被分配这个值result = coro.send(&quot;bar&quot;)# 因为我们的协程也产生了 msg 变量# 这意味着我们可以打印值print(result)  # bar</code></pre><blockquote><p>注意：<code>coro</code>是一个标识符，通常指代一个协程。要查看其他更多的协程可以用的方法，请查看<a href="https://docs.python.org/3.8/reference/datamodel.html#coroutines" target="_blank" rel="noopener">文档</a>。</p></blockquote><p>下面是用协程使用<code>yield</code>在调用方通过<code>.send()</code>方法接收值之前向调用者返回了一个值。</p><pre><code class="python">def foo():    msg = yield &quot;beep&quot;    yield msgcoro = foo()print(next(coro))  # beepresult = coro.send(&quot;bar&quot;)print(result)  # bar</code></pre><p>你可以看到上面的例子，当我们移动生成器协程到一个<code>first</code>语句(使用<code>next(coro</code>)时，值<code>&quot;beep&quot;</code>被返回给我们用来<code>print</code>了。</p><h3 id="Aysncio-基于生成器的协程"><a href="#Aysncio-基于生成器的协程" class="headerlink" title="Aysncio: 基于生成器的协程"></a>Aysncio: 基于生成器的协程</h3><p>当<code>asyncio</code>模块首次被推出时，它还不支持<code>async/await</code>语法，因此当它被引入时，为了确保任何有需要被并发运行的遗留代码(例如: <code>awaited</code>)都需要使用一个<code>asyncio.coroutine</code>装饰器函数，来让它和新的<code>async/await</code>语法保持兼容。</p><blockquote><p>注意：有关这个被弃用的特性（从 <code>Python</code> 3.10开始） ，以及一些其他适用于基于协程的生成器函数，比如<code>asyncio.iscoroutine</code>的信息，请参考文档。</p></blockquote><p>最初基于生成器的协程意味着任何基于<code>asyncio</code>的代码都需要使用<code>yield from</code>在<code>Futures</code>以及另外协程上等待。</p><p>下面的示例演示了如何同时使用新的<code>async</code>协程和早期的基于生成器的协程：</p><pre><code class="python">import asyncio@asyncio.coroutinedef old_style_coroutine():    yield from asyncio.sleep(1)async def main():    await old_style_coroutine()</code></pre><h3 id="Asyncio-新的-async-协程"><a href="#Asyncio-新的-async-协程" class="headerlink" title="Asyncio: 新的 async 协程"></a>Asyncio: 新的 async 协程</h3><p>使用<code>async def</code>创建的协程是用的最新的<code>__await__</code>双下方法（<a href="https://docs.python.org/3.8/reference/datamodel.html#coroutines" target="_blank" rel="noopener">文档在这里</a>）,然而基于生成器的协程使用了传统的基于’生成器’的实现。</p><h3 id="协程的种类"><a href="#协程的种类" class="headerlink" title="协程的种类"></a>协程的种类</h3><p>这导致了术语’协程’在不同的语境下有不同的含义。我们现在有：</p><ul><li><code>simple coroutines</code>：传统的生成器协程（非 async io）</li><li><code>generator coroutine</code>: 用传统的 <code>asyncio</code>实现的 async io</li><li><code>native coroutines</code>：用最新的 <code>async/await</code>实现的async io</li></ul><h3 id="其他方面"><a href="#其他方面" class="headerlink" title="其他方面"></a>其他方面</h3><p><code>Python</code>提供的一些有趣的装饰器函数可能有一些让人迷惑，因为这些函数看起来有重叠的功能。</p><p>它们并不重叠，但似乎是一起使用的：</p><ul><li><code>types.coroutine</code>: 将生成器函数转为一个协程</li><li><code>asyncio.coroutine</code>: 确保<code>asyncio</code>兼容性的抽象</li></ul><blockquote><p>注意：之后我们会看到，<code>asyncio.coroutine</code>实际上调用了<code>types.coroutine</code>。在处理<code>asyncio</code>代码时，你最好使用前者。</p></blockquote><p>更具体的来说，如果我们看一下<a href="https://github.com/python/cpython/blob/master/Lib/asyncio/coroutines.py#L105" target="_blank" rel="noopener"><code>asyncio.coroutine</code></a>代码的实现，我们可以看到：</p><ol><li>如果被装饰的函数已经是一个协程了，那么就直接返回。</li><li>如果被装饰的函数是一个生成器，那么就将它转为协程(使用<code>types.coroutine</code>)。</li><li>否则装饰被装饰的函数，以便当它被转为协程时，它可以<code>await</code>任何可以等待的结果。</li></ol>]]></content>
    
    
    <categories>
      
      <category>翻译</category>
      
      <category>advance</category>
      
      <category>网络</category>
      
      <category>异步</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>async</tag>
      
      <tag>generator</tag>
      
      <tag>iterator</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>异步网络爬虫</title>
    <link href="/2020/04/07/%E5%BC%82%E6%AD%A5%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB(tr)/"/>
    <url>/2020/04/07/%E5%BC%82%E6%AD%A5%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB(tr)/</url>
    
    <content type="html"><![CDATA[<h2 id="异步网络爬虫"><a href="#异步网络爬虫" class="headerlink" title="异步网络爬虫"></a>异步网络爬虫</h2><blockquote><p>作者：<br>A. Jesse Jiryu Davis<br>Guido van Rossum  </p><p>原文链接：<a href="http://aosabook.org/en/500L/a-web-crawler-with-asyncio-coroutines.html" target="_blank" rel="noopener">http://aosabook.org/en/500L/a-web-crawler-with-asyncio-coroutines.html</a></p><p>翻译:<br>Dustyposa</p></blockquote><h3 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h3><p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 经典的计算机科学更着力于让计算机高效地完成计算的算法。但是许多与网络有关的程序并不是因为计算而耗费大量时间。而是因为程序需要维持大量传输很慢或者闲置的连接。这些程序都面临着不一样的挑战：需要高效地等待大量的网络连接。现在的一种解决方案是非同步I/O,也叫做”异步”。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;本章介绍一个简单的web爬虫。爬虫是一个典型的异步应用，因为它需要等待很多响应，而很少做计算任务。只要能够抓取到更多的页面，程序就能运行的更快。如果为每一个进行中的请求分配一个线程，那么随着大量并发请求的增加，在耗尽所有socket对象之前，内存或者线程相关的资源<a href="线程相关资源">^1</a>就会先被耗尽了。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们会分三个阶段展示代码。第一阶段，我们展示一个异步事件循环并<strong><em>编写or描述</em></strong>一个使用带有回调的事件循环的爬虫：这非常高效，但是当代码拓展到解决更复杂的问题时将会导致代码极难维护，变成面条式代码（<code>spaghetti code</code>）。第二阶段，因此，我们会展示兼顾高效和可拓展性强的<code>Python</code>协程。我们会在<code>python</code>中使用生成器实现几个协程的例子。在第三阶段，我们使用来自<code>python</code>标准库中功能更全面的<code>asyncio</code>协程库，并使用异步队列协调任务。</p><h3 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;编写一个发现和下载目标网站上所有页面的爬虫，用来存档或者做索引。从一个根URL开始，抓取每个页面，然后解析页面并获取未显示页面的链接，并且将解析url加入一个队列。当抓到一个没有任何链接并且待抓取队列为空时停止抓取。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们可以通过同时抓取多个页面来加速这个过程。当爬虫发现新的链接时，在不同的套接字上对新页面进行同步抓取。当响应返回时进行解析，将新链接加入队列。由于过多的并发会降低抓取性能，所以抓取的速度会越来越慢。为了解决这个问题，我们限制了并发请求的数量，在正在运行的请求任务完成之前，将剩余连接保存在队列中。</p><h2 id="传统方法"><a href="#传统方法" class="headerlink" title="传统方法"></a>传统方法</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们如何实现爬虫的并发？一般情况下我们会创建一个线程池，每个线程通过一个套接字负责一个网页的下载。例如，从<code>xkcd.com</code>下载一个页面：</p><pre><code class="python">def fetch(url: str) -&gt; None:    sock = socket.socket()  # 创建套接字对象    sock.connect((&quot;xkcd.com&quot;, 80))  # 与 xkcd.com 的80端口握手    request = f&#39;GET {url} HTTP/1.0\r\nHost: xkcd.com\r\n\r\n&#39;  # 构建请求头    sock.send(request.encode(&quot;ascii&quot;))  # 发送数据    response = b&#39;&#39;  # 初始化响应    chunk = sock.recv(4096)  # 每次接收 4096 b的数据    # 循环接收，拼接响应    while chunk:        response += chunk        chunk = sock.recv(4096)    # 页面已经下载完    links = parse_links(response)  # 解析页面，提取链接    q.add(links)  # 队列中加入链接</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 默认情况下，套接字操作是<em>阻塞的</em>，当线程调用像<code>connect</code>或者<code>recv</code>方法时，线程在操作完成之前都会暂停。[^2]因此为了一次下载更多页面，我们需要更多的线程。一个复杂的应用通过在线程池中维护空余线程来分摊创建线程的开销，然后检查线程池，以便在下次任务中重复利用他们，与连接池中的套节字相同。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 然而，线程比较昂贵，操作系统对一个进程，用户或者机器拥有的线程数量有种种限制。在Jesse[^3]的系统中，一个Python线程大约消耗50k的内存，并且启动数万个线程时程序就会崩溃。如果我们扩展到对数万个套接字进行并发操作，在消耗完所有套接字之前，线程就消耗完了。每个线程的开销或者系统对线程的限制就是线程并发的瓶颈了。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 在他的知名文章”The C10K problem”[^4]中,Dan Kagel 概述了多线程对I/O并发的限制。他说到：</p><blockquote><p>你不认为是时候网络服务器去解决同时处理一万个客户端的时候吗？毕竟，网站现在是一个巨大的容器。</p></blockquote><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Kegel 在1999年创造了”C10K”这个术语。一万个连接现在听起来比较简单，但是这个问题其实只改变了连接的数量大小，问题种类并没有发生改变。当时，C10K的每个连接都使用一个线程是不现实的。不过现在的单线程的连接数量限制上升了几个数量级。实际上，我们的玩具爬虫可以很好地使用线程工作。然而对于有数十万连接规模的超大型应用来说，上限依然存在：大多数系统即使可以继续创建套接字，但是也会耗尽所有线程。我们如何克服这个问题呢？</p><h2 id="异步（Async）"><a href="#异步（Async）" class="headerlink" title="异步（Async）"></a>异步（Async）</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 异步I/O框架在单线程上使用<em>非阻塞</em>套接字完成并发操作。在我们的异步爬虫中，在套接字链接到服务器之前，我们将其设置为非阻塞式的，代码如下：</p><pre><code class="python">sock = socket.socket()  # 创建套接字对象sock.setblocking(False)  # 设置成非阻塞try:    sock.connect((&quot;xkcd.com&quot;, 80))except BlockingIOError:    pass</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 令人厌烦的是，即使工作正常，非阻塞套接字也会抛出连接异常。这个异常是复制了底层C语言函数的扰人行为，它将<code>errno</code>设置成<code>EINPROGRESS</code>告诉你（连接）已经开始了。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 现在我们的爬虫需要一个能够知道何时已经建立连接的方法，我们可以通过发送HTTP请求（来测试连接是否建立）。我们通过简单的while循环来实现：</p><pre><code class="python">request = f&quot;GET {url} HTTP/1.0\r\nHost: xkcd.com\r\n\r\n&quot;  # 最后两个\r\n代表请求头结束encoded = request.encode(&quot;ascii&quot;)while True:    try:        sock.send(encoded)  # 发送 HTTP 请求        break  # 连接建立成功    except OSError as e:        passprint(&quot;发送成功&quot;)</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 这个方法不仅费电，而且不能高效地在<em>多个</em>套接字上进行等待。以前，BSD Unix的解决方案是<code>select</code>, 一个 等待事件在非阻塞套接字上或者一个小的事件数组上发生的C 语言函数。如今，对于有大量连接的互联网应用的需求导致了（<code>select</code>）被例如<code>poll</code>，在BSD上的<code>kqueue</code>和在Linux上的<code>epoll</code>替换。这些接口都与<code>select</code>相似，但是在大量请求的情况下依然表现地很好。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Python3.4的<code>DefaultSelector</code>选择了在你的系统上可用的最佳的类<code>select</code>函数。为了注册关于网络<code>I/O</code>的通知，我们创建了一个非阻塞套接字并且使用默认<code>selector</code>注册它：</p><pre><code class="python">from selectors import DefaultSelector, EVENT_WRITEselector = DefaultSelector()  # 创建选择器对象sock = socket.socket()sock.setblocking(False)try:    sock.connect((&quot;xdcd.com&quot;, 80))except BlockingIOError:    # 使用非阻塞必定抛出该异常    passdef connected() -&gt; None:    selector.unregister(sock.fileno())    print(&quot;connected!&quot;)selector.register(sock.fileno(), ENENT_WRITE, connected)  # 一个套接字会占用一个描述符，通过描述符来进行注册，事件（ENENT_WRITE）发生后，回调 connected 函数。</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 我们忽略掉假错误，调用<code>selector.register</code>, 传入套接字文件描述符和一个常量，该常量表示我们正在等待的事件。为了当连接可以用时得到通知，我们传入<code>EVENT_WRITE</code>：也就是说，我们想知道什么时候套接字是”可写的”。同时我们也传入了一个Python函数<code>connected</code>,以便在事件发生时运行。这样的函数就叫做<code>回调函数</code>。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 当选择器收到<code>I/O</code>通知时，我们在循环中进行处理：</p><pre><code class="python">def loop() -&gt; None:    while True:        events = selector.select()        for event_key, event_mask in events:            callback = envent_key.data            callback()</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 回调函数<code>connected</code>被保存在<code>event_key.data</code>中，一旦非阻塞套接字连接完成，我们将读取并执行该回调函数。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 与之前的<code>while</code>循环不同（套接字循环发送代码段），当代码运行到<code>select</code>时会暂停，等待下一次的<code>I/O</code>事件。然后循环运行等待这些事件的回调完成。如果程序未完成将会一直挂起，直到事件循环中有新的通知。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 到目前为止我们已经展示了哪些呢？我们展示了如何开始注册事件并当事件准备就绪后执行回调函数。一个可以在单线程中运行并发操作的异步的框架就是构建于我们已经展示的两个特性（非阻塞套接字和事件循环）。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 我们在这里实现了”并发”，但是不是传统意义上的”并行”。也就是说我们构建了一个重叠I/O[^ 5](在Windows API 中被叫做异步I/O)的微型系统。它可以在其他操作正在进行时执行新的操作。实际上它并没有利用多核来执行并行计算。然而，这个系统为I/O密集型问题设计的，而不是为了计算密集型任务。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 因此，我们的事件循环对并发I/O的场景是很有效的，因为它没有分配线程资源给每个连接。但是在我们继续之前，必须纠正一个常见的误解，即异步比多线程更快。实际上，在Python中，像我们这样的事件循环在服务少量活跃连接的时候是比多线程稍慢的。在没有全局解释锁时，多线程能够表现的更好。异步<code>I/O</code>最适合的有很多慢、不活跃以及闲置的连接的应用[^6]。</p><h2 id="回调编程"><a href="#回调编程" class="headerlink" title="回调编程"></a>回调编程</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 到目前为止，我们编写了一个很小的异步框架，但是我们如何才能编写一个网络爬虫呢？即使是简单的URL提取都很难下手。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 我们从创建尚未抓取的URL集合和浏览过的URL集合开始：</p><pre><code class="python">urls_todo = set([&quot;/&quot;])seen_urls = set([&quot;/&quot;])</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <code>seen_urls</code>集合包括<code>urls_todo</code>加上已经抓取过的URLs。这两个集合都用根URL<code>&quot;/&quot;</code>初始化。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 抓取一个页面需要一套回调函数。当套接字连接上时触发<code>connected</code>回调函数，然后给服务器发送一个<code>GET</code>请求。但是必须等待响应的返回，所以我们需要注册另一个回调函数。如果回调触发时，还不能读取所有响应，那就再次注册，以此类推。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 让我们把这些回调函数放进一个<code>Fetcher</code>对象。它需要一个<code>URL</code>、一个套接字对象和一个存放字节响应的地方：</p><pre><code class="python">class Fetcher:    def __init__(self, url: str) -&gt; None:        self.response = b&quot;&quot;        self.url = url        self.sock = None</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 我们从调用<code>Fetcher.fetch</code>开始：</p><pre><code class="python">        # Fetcher 类的方法    def fetch(self) -&gt; None:        self.sock = socket.socket()        self.sock.setblocking(False)        try:            self.sock.connect((&quot;xkcd.com&quot;, 80))        except BlockingIOError:            pass        # 注册下一步的回调        selector.register(            self.sock.fileno(),            EVENT_WRITE,            self.connected        )</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>fetch</code>方法始于连接到一个套接字。但是需要注意的是该方法在连接建立好之前已经返回了。它必须返回控制权给事件循环以便等待连接建立。至于为什么，假设我们整个应用的结构是这样的：</p><pre><code class="python"># 开始抓取 http://xkcd.com/353/fetcher = Fetcher(&quot;/353/&quot;)fetcher.fetch()while True:    events = selector.select()    for event_key, event_mask in events:        callback = event_key.data        callback(event_key, event_mask)</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当调用<code>select</code>方法时，所有事件通知都会在事件循环中处理。因此<code>fetch</code>必须将控制权给事件循环，以便程序知道什么时候套接字已经建立好连接了。只有这样，<code>while</code>循环才能回调在上述<code>fetch</code>方法结束时注册的<code>connected</code>函数，</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以下是<code>connected</code>的实现：</p><pre><code class="python">    # Fetcher 类的方法    def connected(self, key, mask) -&gt; None:        print(&quot;connected!&quot;)        selector.unregister(key.fd)        request = f&quot;GET {self.url} HTTP/1.0\r\nHost: xkcd.com\r\n\r\n&quot;        self.sock.send(request.encode(&quot;ascii&quot;))        # 注册下一个回调函数        selector.register(            key.fd,            EVENT_READ,            self.read_response        )</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 该方法发送一个<code>GET</code>请求。不过一个真正的应用是需要检查<code>send</code>的返回值（译者注：<code>send</code>函数的返回值表示成功发送的字节数），以防止没有一次性发送完所有数据。但是我们的请求信息比较少，而且我们的程序也很简单。直接调用<code>send</code>，然后等待响应的返回。当然，程序必须注册另一个回调函数并把控制权交回事件循环。下一个也是最后一个回调函数，<code>read_response</code>,处理服务器的回应：</p><pre><code class="python">    # Fetcher 类的方法    def read_response(self, key, mask) -&gt; None:        global stopped        chunk = self.sock.recv(4096)  # 每块 4K 大小        if chunk:            self.reponse += chunk        else:            selector.unregister(key.fd)  # 读取响应完成            links = self.parse_links()            # Python 集合处理逻辑            for link in links.difference(seen_urls):                urls_todo.add(link)                  Fetcher(link).fetch()   # 创建新的 Fetcher            seen_urls.update(links)            urls_todo.remove(self.url)            if not urls_todo:                stopped = True</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 每当<code>selector</code>检测到套接字可读时（”可读”可能意味着两件事：套接字有收到数据了或者已经关闭了）就会执行该回调函数。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 该回调需要从套接字获取4k的数据。如果数据不够，不论数据是否可用<code>chunk</code>都会阻塞。如果数据足够的话，<code>chunk</code>就有4k长度并且套接字也会保留可读性，所以事件循环在下一次收到通知时，会再次执行该回调函数。当全部响应读取完成时，目标服务器就会关闭套接字，并且<code>chunk</code>就没有数据了。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 未展示的<code>parse_links</code>方法返回值是一个<code>URL</code>的集合。我们为每个新<code>URL</code>都创建了一个<code>fetcher</code>，这里没有并发上限。注意，用回调进行异步编程的有一个优势就是：即使对公共数据进行写操作我们也不需要互斥锁，例如在我们向<code>seen_urls</code>添加链接时。因为不是抢占式多任务，所以我们的代码在任何位置都不能被中断[^7]。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 我们添加一个全局变量<code>stopped</code>用来控制循环：</p><pre><code class="python">stoped = Falsedef loop() -&gt; None:    while not stoped:        events = selector.select()        for event_key, event_mask in events:            callback = event_key.data            callback()</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一旦所有页面抓取完成，<code>fetcher</code>就让全局的事件循环停止并退出程序。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个例子反映出了异步编程的一个典型的问题：面条式代码。我们需要某种方式来表示一系列的计算和I/O操作，并调度多个此类操作让他们并发执行。但是没有了线程，这一系列的操作都不能写到同一个函数中：只要函数开始进行一个I/O操作，它都需要显示地保存将来需要处理的任何状态（译者注：例如可读、可写等），然后返回。你需要自己思考和编写这个状态保存的代码。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;让我们解释一下上面说的到底是什么意思。先看一下在一个线程中使用传统的阻塞套接字抓取一个链接有多简单：</p><pre><code class="python"># 阻塞版本 def fetch(url: str) -&gt; None:    sock = socket.socket()    sock.connect((&#39;xkcd.com&#39;, 80))    request = f&#39;GET {url} HTTP/1.0\r\nHost: xkcd.com\r\n\r\n&#39;    sock.send(request.encode(&#39;ascii&#39;))    response = b&#39;&#39;    chunk = sock.recv(4096)    while chunk:        response += chunk        chunk = sock.recv(4096)    # 页面下载完成    links = parse_links(response)    q.add(links)</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在一次套接字操作和下一次操作之间，函数记录了什么状态呢？它有一个套接字对象，一个URL和可增长的<code>response</code>。运行在线程的中的函数利用编程语言的基础特性将临时变量保存在其堆栈的局部变量中。该函数也有一个“continuation（延伸）“——即计划在I/O完成后执行的代码。运行时通过保存线程的指令指针来记住这个 continuation 部分。你不需要考虑在I/O完成后如何恢复这些局部变量以及 contination 部分。语言本身的特性就帮你解决了。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但是对于基于回调的异步框架，这些语言特性是没有任何帮助的。只要在等待I/O，函数必须显示保存它的状态，因为一旦函数在I/O完成之前就会返回，并且会丢失堆栈帧。在之前的回调示例中，作为局部变量的替代，我们把<code>sock</code>和<code>response</code>作为<code>Fetcher</code>实例化后的<code>self</code>的属性来保存。为了替代指令指针，通过注册<code>connected</code>和<code>read_reponse</code>回调函数来保存它的 continuation 。由此可见，随着应用功能的增加，我们手动保存回调状态的复杂性也在增加。如此繁杂的记账式工作让程序员很头痛。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;更糟糕的是，在一次回调和下一次回调之间抛出异常会发生什么？假设我们<code>parse_links</code>方法写的很差，在解析某些HTML时抛出了异常：</p><pre><code class="python">Traceback (most recent call last):  File &quot;loop-with-callbacks.py&quot;, line 111, in &lt;module&gt;    loop()  File &quot;loop-with-callbacks.py&quot;, line 106, in loop    callback(event_key, event_mask)  File &quot;loop-with-callbacks.py&quot;, line 51, in read_response    links = self.parse_links()  File &quot;loop-with-callbacks.py&quot;, line 67, in parse_links    raise Exception(&#39;parse error&#39;)Exception: parse error</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;栈回溯信息只能展示事件循环正在运行一个回调函数。我们不知道是什么导致了错误。回调链的两端都被破坏了，不知道从哪开始从哪结束。这种上下文丢失的情况叫做“堆栈撕裂（stack ripping）”，在很多情况下都会让我们束手无策。堆栈撕裂还会阻止我们为回调链设置异常处理，即通过“<code>try/except</code>”块封装函数调用及其调用树[^8]。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因此，除了关于多线程和异步谁的运行效率更高的争论以外，还有一个关于哪个更容易出错的争论：如果在同步时失误，线程更容易受到数据争夺（译者注：公有数据，线程的同步与互斥问题。）的影响，但是回调发生堆栈撕裂时，调试会变得令人痛苦不堪。</p><h2 id="协程（Coroutines）"><a href="#协程（Coroutines）" class="headerlink" title="协程（Coroutines）"></a>协程（Coroutines）</h2><blockquote><p>译者注：下面这部分的代码比较老了，因为python34还没有 <code>await</code> <code>async</code> 这类东西，用的原始的 <code>yiled from</code> 实现的协程。以下部分可以当做原理了解，项目实操中请不要使用，请用最新写法，推荐py37+版本。后面计划出最新的<code>python</code>协程教程，敬请期待。</p></blockquote><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 我们向你保证。编写高效回调与多线程编程简单的代码风格相结合的异步代码也是没有问题的（译者注：py37+更简单了！）。这种结合是通过一种叫“协程（coroutines）”的模式实现的。使用Python3.4的<code>asyncio</code>标准库和叫做<code>aiohttp</code>的第三方库，在协程中抓取一个URL就很简单了[^9]:</p><pre><code class="python">    @asyncio.coroutine    def fetch(self, url):        response = yield from self.session.get(url)        body = yield from response.read()</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 当然，代码的可扩展性也是没有问题的。与每个线程需要<code>50k</code>内存和操作系统对其有硬限制的多线程相比，一个<code>python 协程</code>在 Jesse的系统上仅仅需要<code>3k</code>的内存。python 可以轻轻松松地开启成千上万个协程。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 协程的概念可以追溯到计算机科学的早期，也很简单：一个可暂停和继续的例程（译者注：<a href="https://en.wikipedia.org/wiki/Coroutine#Comparison_with_subroutines" target="_blank" rel="noopener">协程的子集</a>）。多线程是抢占式的的，并发优先级是由操作系统控制，但是协程是协作式的：由自身选择什么时候暂停，什么时候运行下一个协程。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 协程有很多的实现方式，即使在python中也有几种实现方式（译者注：最著名的例如：<code>gevent</code>三方库和<code>asynico</code>标准库 ，实现方式就不同）。Python3.4中的标注库<code>asynico</code>中的协程是基于生成器，<code>Future</code>类和<code>yield from</code> 语句构建的。从 Python3.5 开始，协程就是语言的一个原生特性了[^8]。但是，了解最初在在Python3.4中使用现存的语言工具实现的协程，是在Python3.5中实现原生协程的基础。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 为了解释Python3.4中基于生成器实现的协程，我们将介绍生成器以及在它如何在<code>asyncio</code>中作为协程使用。相信你你阅读如我写书这般享受。在解释完基于生成器实现的协程之后，我们将异步网络爬虫中使用协程。</p><h2 id="Python-生成器是如何工作的"><a href="#Python-生成器是如何工作的" class="headerlink" title="Python 生成器是如何工作的"></a>Python 生成器是如何工作的</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 在你掌握<strong>Python</strong>生成器之前，你需要去了解正常的<strong>Python</strong>函数如何工作的。正常情况下，当<code>Python</code>函数调用一个子例程(subroutine)时，子例程在函数返回或者抛出异常之前会保留控制权。之后将郭志全返回给调用者：</p><pre><code class="python">&gt;&gt;&gt; def foo():...     bar()...&gt;&gt;&gt; def bar():...     pass</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 标准的<strong>Python</strong>解释器使用<strong>C</strong>写的。执行<strong>Python</strong>函数的<strong>C</strong>函数被统称为<code>PyEval_EvalFrameEx</code>。它接收一<code>Python栈帧对象</code>并在框架上下文中计算<code>Python字节码</code>。下面是<code>foo</code>的字节码：</p><pre><code class="python">&gt;&gt;&gt; import dis&gt;&gt;&gt; dis.dis(foo)  5           0 LOAD_GLOBAL              0 (bar)              2 CALL_FUNCTION            0              4 POP_TOP              6 LOAD_CONST               0 (None)              8 RETURN_VALUE</code></pre><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <code>foo</code>函数将<code>bar</code>加载到堆栈上，并调用它，然后从堆栈中弹出它的返回值，将<code>None</code>加载到堆栈上，最后返回<code>None</code>。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 当<code>PyEval_EvalFrameEx</code>碰到<code>CALL_FUNCTION</code>字节码时，它会新建一个<code>Python 栈帧</code>并递归：也就是说，它用一个新的帧递归地调用<code>PyEval_EvalFrameEx</code>，该帧用来执行<code>bar</code>。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 理解<code>Pthon栈帧</code>是堆内存分配这件事是极其重要的！<code>Python</code>解释器是一个普通的C程序，所以他的栈帧也是普通的栈帧。但是它操作的<code>Python栈帧</code>在堆上。出乎意料的是，这意味着一个<code>Python栈帧</code>可以比它的函数调用存在更久。要想看交互式的效果，在<code>bar</code>中保存当前帧：</p><pre><code class="python">&gt;&gt;&gt; import inspect&gt;&gt;&gt; frame = None&gt;&gt;&gt; def foo():...     bar()...&gt;&gt;&gt; def bar():...     global frame...     frame = inspect.currentframe()...&gt;&gt;&gt; foo()&gt;&gt;&gt; # 帧正在执行 &#39;bar&#39; 的代码&gt;&gt;&gt; frame.f_code.co_name&#39;bar&#39;&gt;&gt;&gt; # 下一个帧指向的为&#39;foo&#39;&gt;&gt;&gt; caller_frame = frame.f_back&gt;&gt;&gt; caller_frame.f_code.co_name&#39;foo&#39;</code></pre><p><img src="https://i.loli.net/2019/11/13/siMN7VcqEPIfAuU.png" srcset="/img/loading.gif" alt="function-calls.png"></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  Figure 5.1 - Function Calls </p><p>现在为<code>Python生成器</code>设置好了同样的阶段，使用相同的构建块——代码对象和栈帧——得到了很好的效果。</p><p>这是一个生成器函数：</p><pre><code class="python">&gt;&gt;&gt; def gen_fn():...     result = yield 1...     print(f&#39;result of yield: {result}&#39;)...     result2 = yield 2...     print(f&#39;result of 2nd yield: {result2}&#39;)...     return &#39;done&#39;... </code></pre><p>当<code>Python</code>将<code>gen_fn</code>编译为字节码时，编译器看到<code>yield</code>声明就知道<code>gen_fn</code>是一个生成器函数，不是一个常规的函数。它会设置一个<code>flag</code>去记住这个事实：</p><pre><code class="python">&gt;&gt;&gt; # 生成器标志是 5比特位(bit position 5)&gt;&gt;&gt; generator_bit = 1 &lt;&lt; 5&gt;&gt;&gt; bool(gen_fn.__code__co_flags &amp; generator_bit)True</code></pre><p>当你调用一个生成器函数时，<code>Python</code>看见生成器<code>flag</code>并不会真的运行这个函数。反而它会创建一个生成器：</p><pre><code class="python">&gt;&gt;&gt; gen = gen_fn()&gt;&gt;&gt; type(gen)&lt;class &#39;generator&#39;&gt;</code></pre><p><code>Python</code>生成器封装了一个栈帧和一个对某些代码的引用，<code>gen_fn</code>的主体:</p><pre><code class="python">&gt;&gt;&gt; gen.gi_code.co_name&#39;gen_fn&#39;</code></pre><p>从对<code>gen_fn</code>的调用到所有的生成器都指向相同的代码。但是每个都有自己的栈帧。这个栈帧不在任何真实的栈上面，它在堆内存中等待被使用：</p><p><img src="https://i.loli.net/2019/11/13/lEUd6p8Doz4ZrSh.png" srcset="/img/loading.gif" alt="generator.png"></p><p>这个帧有一个“最后的指令”指针，就是它最近执行的指令。在刚开始的时候，最后的指令指针为<code>-1</code>，意味着生成器还没开始：</p><pre><code class="python">&gt;&gt;&gt; gen.gi_frame.f_lasti-1</code></pre><p>当我们调用<code>send</code>的时候，生成器到达第一个<code>yield</code>并暂停。<code>send</code>的返回值是<code>1</code>，这是由<code>gen</code>通过<code>yield</code>表达式传递的：</p><pre><code class="python">&gt;&gt;&gt; gen.send(None)1</code></pre><p>生成器指令指针现在是3字节码，部分通过编译的<code>Python</code>有56字节：</p><pre><code class="python">&gt;&gt;&gt; gen.gi_frame.f_lasti3&gt;&gt;&gt; len(gen.gi_code.co_code)56</code></pre><p>生成器可以在任何时候从任何函数复位(resumed)，因为它的栈帧并没有真正的存在栈上：它在堆上。它在调用层次结构中位置是不固定的，并且它不需要遵循常规函数执行时的先进后出的顺序。它是自由的，像自由漂浮的云。</p><p>我们可以给生成器发送<code>hello</code>，它会成为<code>yield</code>表达式的结果，生成器继续运行只到它<code>yields 2</code>:</p><pre><code class="python">&gt;&gt;&gt; gen.send(&#39;hello&#39;)retult of yield: hello2</code></pre><p>它的栈帧现在有了局部变量<code>result</code>:</p><pre><code class="python">&gt;&gt;&gt; gen.gi_frame.f_locals{&#39;result&#39;: &#39;hello&#39;}</code></pre><p>从<code>gen_fn</code>创建的其他生成器有它们自己的栈帧和局部变量。</p><p>我们可以再次调用<code>send</code>，生成器继续运行直到遇到第二个<code>yield</code>，在抛出一个特殊的<code>StopIteration</code>错误后结束掉。</p><pre><code class="python">&gt;&gt;&gt; gen.send(&#39;goodbye&#39;)result of 2nd yield: goodbyeTraceback (most recent call last):  File &quot;&lt;input&gt;&quot;, line 1, in &lt;module&gt;StopIteration: done</code></pre><p>这个异常有一个值，就是作为生成器返回的值：字符串”done”.</p><h2 id="用生成器构建协程"><a href="#用生成器构建协程" class="headerlink" title="用生成器构建协程"></a>用生成器构建协程</h2><p>因此，一个生成器可以暂停，用一个值可以恢复并且有一个返回值。这听起来很好的原始方法去构建一个异步编程模型，并且不需要复杂(<code>spaghetti</code>)的回调！我们想去构建一个<code>&quot;coroutine&quot;</code>:一个可以和其他的例程在程序中协同调度的例程。我们的协程将是<code>Python</code>标准库<code>&quot;asynico&quot;</code>库中的那些协程的简化版本。跟<code>asyncio</code>中的一样，我们将使用<code>generators,futures,and &#39;yield from&#39;语法</code>。</p><p>首先，我们需要一种方式来表示协程正在等待的一些<code>futrue</code>结果。一个精简版:</p><pre><code class="python">class Future:    def __init__(self):        self.result = None        self._callbacks = []    def add_done_callback(self, fn: Callable) -&gt; None:        self._callbacks.append(fn)    def set_result(self, result) -&gt; None:        self.result = result        for fn in self._callbacks:            fn(self)</code></pre><p>一个<code>future</code>刚开始是<code>pending</code>状态。通过调用<code>set_result</code>[^11]变为<code>&quot;resolved&quot;</code>状态。</p><p>让我们调整我们的<code>fetcher</code>，使用<code>futures and coroutines</code>.我们用回调编写<code>fetch</code>。</p><pre><code class="python">class Fetcher:    def fetch(self) -&gt; None:        self.sock = socket.socket()        self.sock.setblocking(False)        try:            self.sock.connect((&quot;xkcd.com&quot;, 80))        except BlockingIOError:            pass        selector.register(            self.sock.fileno(),            EVENT_WRITE,            self.connected        )    def connected(self, key, mask) -&gt; None:        print(&#39;connected!&#39;)        # And so on....</code></pre><p><code>fetch</code>方法开始连接一个<code>socket</code>,然后注册回调，<code>connected</code>,当<code>socket</code>准备好后回调会被执行。现在我们可将这两倍结合到一个协程中：</p><pre><code class="python">def fetch(self) -&gt; Generator:    self.sock = socket.socket()    self.sock.setblocking(False)    try:        self.sock.connect((&#39;baidu.com&#39;, 80))    except BlockingIOError:        pass    f = Future()    def on_connected():        f.set_result(None)    selector.register(        self.sock.fileno(),        EVENT_WRITE,        on_connected    )    yield f    selector.unregister(self.sock.fileno())</code></pre><p>现在,<code>fetch</code>是一个生成器函数，并不是常规的函数，因为它包含了<code>yield</code>语句。我们创建了一个<code>pending</code>状态的<code>future</code>,然后<code>yield</code>它去暂停<code>fetch</code>直到<code>socket</code>准备好。内部函数<code>on_connected</code>将会<code>resolves future</code>。</p><p>但是当<code>future resolves</code>时，怎么恢复生成器呢？我们需要一个协程掌舵者(<code>driver</code>).让我们叫它<code>task</code>:</p><pre><code class="python">class Task:    def __init__(self, coro):        self.coro = coro        f = Future()        f.set_result(None)        self.step(f)    def step(self, future: Future) -&gt; None:        try:            next_future = self.coro.send(future.result)        except StopIteration:            return        next_future.add_done_callback(self.step)# 开始抓取 http://xkcd.com/353fetcher = Fetcher(&#39;/353/&#39;)Task(fetcher.fetch())loop()</code></pre><p><code>taak</code>通过发送<code>None</code>给<code>fetch</code>生成器来启动它。然后<code>fetch</code>开始运行直到<code>yields</code>一个<code>future</code>,它回被<code>task</code>被当作<code>next_future</code>捕获。当<code>socket</code>建立连接成功后，事件循环会运行回调函数<code>on_connected</code>，来释放<code>future</code>，<code>future</code>将会调用<code>step</code>,从而恢复<code>fetch</code>。</p><h2 id="用yield-from代理协程"><a href="#用yield-from代理协程" class="headerlink" title="用yield from代理协程"></a>用<code>yield from</code>代理协程</h2><p>一旦<code>socket</code>建立连接成功，我们就发送<code>HTTP GET</code>请求并读取服务器的响应。这些步骤不需要分散在回调函数之间；我们将它们放到同一生成器函数中：</p><pre><code class="python">    def fetch(self) -&gt; Generator:        # ... 连接逻辑同上，然后：        self.sock.send(request.encode(&#39;ascii&#39;))        while True:            f = Future()            def on_readable():                f.set_result(self.sock.recv(4096))            selector.register(                self.sock.fileno(),                EVENT_READ,                on_readable            )            chunk = yield f            selector.unregister(self.sock.fileno())            if chunk:                self.response += chunk            else:                # 响应读取完成                break</code></pre><blockquote><p> <em>译者注： 这里网络状况问题比较多，建议配合译者的响应代码文件食用，尽量测试客户端连接本地服务器，不然结果会有一些不尽人意。</em></p></blockquote><p>这段代码，会从<code>socket</code>中读取整个信息，通常看起来很有用。我们如何把它从<code>fetch</code>中分解成一个子例程呢？现在<code>Python 3</code>有名的<code>yield from</code>登场了。它把一个生成器委托给了另一个。</p><p>为了了解如何操作，让我们回到一个简单的生成器例子:</p><pre><code class="python">&gt;&gt;&gt; def gen_fn():...     result = yield 1...     print(f&#39;result of yield: {result}&#39;)...     result2 = yield 2...     print(f&#39;result of 2nd yield: {result2}&#39;)...     return &#39;done&#39;... </code></pre><p>为了从另一个生成器中调用这个生成器，用<code>yield from</code>进行委托。</p><pre><code class="python">&gt;&gt;&gt; # 生成器函数&gt;&gt;&gt; def caller_fn():...     gen = gen_fn()...     rv = yield from gen...     print(f&#39;return value of yield-from: {rv}&#39;)...     &gt;&gt;&gt; # 从生成器函数生成一个生成器&gt;&gt;&gt; caller = caller_fn()</code></pre><p><code>caller</code>生成器的行为和<code>gen</code>相似，生成器委托给了：</p><pre><code class="python">&gt;&gt;&gt; caller.send(None)1&gt;&gt;&gt; caller.gi_frame.f_lasti15&gt;&gt;&gt; caller.send(&#39;hello&#39;)result of yield: hello2&gt;&gt;&gt; caller.gi_frame.f_lasti  # 未增加15&gt;&gt;&gt; caller.send(&#39;goodbye&#39;)result of 2nd yield: goodbyereturn value of yield-from: doneTraceback (most recent call last):  File &quot;&lt;input&gt;&quot;, line 1, in &lt;module&gt;StopIteration</code></pre><p>当<code>caller yields from gen</code>时，<code>caller</code>没有增加<em>(指针)</em>[^12]。请注意，即使内部的生成器<code>gen</code>从一个<code>yield</code>语句运行到下一个<code>yield</code>语句，它的指针也保持在 15，即声明<code>yield from</code>的位置。从外部<code>caller</code>的角度来看，我们不能够判断它<code>yield</code>的值来自<code>caller</code>还是来自它委托的生成器。从内部的<code>gen</code>来看，我们不能判断发送的值是来自<code>caller</code>或者来自它的外部。<code>yield from</code>语句是一个流畅的通道，在<code>gen</code>结束之前，值通过它出入<code>gen</code>。</p><p>一个协程可以用<code>yield from</code>将工作委托给一个子协程，并接收子协程工作的结果。需要注意的是，在上面的代码中，<code>caller</code>打印了<code>&quot;return value of yield-from: done&quot;</code>。当<code>gen</code>执行完成时，它返回的值成为了<code>caller</code>中 <code>yield from</code> 语句产生的值：</p><pre><code class="python">    rv = yield from gen</code></pre><p>之前，在我们批评基于回调的异步编程的时候，我们最突出的抱怨是关于<code>&quot;stack ripping&quot;</code>的：当一个回调抛出一个异常时，堆栈追踪通常是无用的。它仅仅展示了时间循环正在运行回调，而不是<em>原因</em>。那么协程怎么样？</p><pre><code class="python">&gt;&gt;&gt; def gen_fn():...     raise Exception(&#39;my error&#39;)&gt;&gt;&gt; caller = caller_fn()&gt;&gt;&gt; caller.send(None)Traceback (most recent call last):  File &quot;&lt;input&gt;&quot;, line 1, in &lt;module&gt;  File &quot;&lt;input&gt;&quot;, line 3, in caller_fn  File &quot;&lt;input&gt;&quot;, line 2, in gen_fnException: my error</code></pre><p>这就有用多了！堆栈追踪展示了当异常抛出时，<code>caller_fn</code>正在委托<code>gen_fn</code>。更令人欣慰的是，我们可以把对子协程的调用封装在异常处理中，这和普通的子例程相同：</p><pre><code class="python">&gt;&gt;&gt; def gen_fn():...     yield 1...     raise Exception(&#39;uh oh&#39;)...&gt;&gt;&gt; def caller_fn():...     try:...         yield from gen_fn()...     except Exception as exc:...         print(f&#39;caught {exc}&#39;)...&gt;&gt;&gt; caller = caller_fn()&gt;&gt;&gt; caller.send(None)1&gt;&gt;&gt; caller.send(&#39;hello&#39;)caught uh oh</code></pre><p>所以，就像常规的子例程一样，我们分解一下子协程程的逻辑。让我们从我们的<code>fetcher</code>中分解一些有用的子协程。我们写一个<code>read</code>写成来接收一个<code>chunk</code>:</p><pre><code class="python">def read(sock: socket.socket):    f = Future()    def on_readable():        f.set_result(sock.recv(4096))    selector.register(        sock.fileno(),        EVENT_READ,        on_readable    )    chunk = yield f  # 读一个chunk    selector.unregister(sock.fileno())    return chunk</code></pre><p>我们在<code>read</code>的基础上构建一个<code>read_all</code>协程，用于接收整个消息：</p><pre><code class="python">def read_all(sock: socket.socket):    response = []    # 读取所有消息    chunk = yield from read(sock)    while chunk:        response.append(chunk)        chunk = yield from read(sock)    return b&#39;&#39;.join(response)</code></pre><p>如果你以正确的方式换角度看的话，<code>yield from</code>语句就会消失，并且这些语句看起来和常规的函数一样，会阻塞<code>I/O</code>。但实际上，<code>read</code>和<code>read_all</code>都是协程。<code>yield from read</code>会暂停 <code>read_all</code>直到所有的<code>I/O</code>完成。当<code>reda_all</code>暂停时，<code>asyncio</code>的事件循环会执行其他的工作并等待(awiat)其他的<code>I/O</code>事件；一旦事件就绪，<code>read_all</code>就会在下一个循环中恢复并获得<code>read</code>的结果。</p><p>在堆栈的根<em>(此处指 <strong>main</strong> 的全局空间)</em>，<code>fecth</code>调用<code>read_all</code>:</p><pre><code class="python">class Fetcher:    def fetch(self) -&gt; Generator:        # ... 连接逻辑同上，然后：        self.sock.send(request.encode(&#39;ascii&#39;))        self.response = yield from read_all(self.sock)</code></pre><p>令人惊喜的是，<code>Task</code>类不需要做任何修改。它和以前一样，驱动外部的<code>fetch</code>协程就行：</p><pre><code class="python">Task(fetcher.fetch())loop()</code></pre><p>当然<code>read</code> yield 一个<code>future</code> 时，<code>task</code>通过<code>yield from</code>语句的通道接收它，就像<code>future</code>是直接从<code>fetch</code>中产生<em>(yielded)</em>的一样。当循环释放一个<code>future</code>时，<code>task</code>把结果发送到了<code>fetch</code>，并且通过<code>read</code>直接把值接收了，就像<code>task</code>直接在驱动<code>read</code>:</p><p><img src="http://aosabook.org/en/500L/crawler-images/yield-from.png" srcset="/img/loading.gif" alt="figure_yield"></p><p>​                                                                                Figure 5.3 - Yield From  </p><p>为了完善我们的协程实现，我们改进了一个标记：当它等待一个<code>future</code>时，我们的代码使用的<code>yield</code>，当它委托给一个子协程时，使用的<code>yield from</code>。如果我们在协程暂停时使用<code>yield from</code>，效果会更好。那么洗成就不需要关注它等待的东西是什么类型。</p><p>我们利用了<code>Python</code>中生成器和迭代器的深度对应关系。对于调用者来说，推进的生成器和推进的迭代器都是一样的。所以我们让我们的<code>Future</code>类通过一个特殊的方法实现可迭代：</p><pre><code class="PYTHON">    # Future 类的方法    def __iter__(self):        # 告诉 Task 在这里继续        yield self        return self.result</code></pre><p><code>future</code>的<code>__iter__</code>方法是一个<code>yields future 自身</code>的协程。现在当我们像这样替换代码时:</p><pre><code class="python"># f is a Future.yield f</code></pre><p>…用这样的代码进行替换：</p><pre><code class="python"># f is a Future.yield from f</code></pre><p>…结果是一样的！驱动器<code>Task</code>调用<code>send</code>收到<code>future</code>,并且当<code>future</code>结束时，它会将新的结果发送回协程。</p><p>到处都使用<code>yield from</code>的好处是什么？为什么比用<code>yield</code>等待<code>future</code>以及用<code>yield</code>委托给子协程好？好的原因是因为现在，一个方法可以自由的改变实现而不影响调用者：它可以是一个常规的函数，返回一个<code>future</code>然后将会<code>resolve</code>一个值，或者它也可以是一个协程，包含了<code>yield from</code>语句并<code>returns</code>一个值。在这两种情况下，调用者都只需要<code>yield from</code>去等待结果。</p><p>读者们，我们已经愉快的完成了对在<code>asyncio</code>中协程的阐述。我们探究了生成器的机制，并勾画实现了<code>futures and tasks</code>。我们概述了异步是如何取得这两方面的最佳效果的:并发I/O比线程更有效，比回调更清晰。当然，真正的<code>asyncio</code>是比我们简述版复杂的多的。真正的框架实现了零拷贝<code>I/O</code>,平衡调度，异常处理和大量的其他功能。</p><p>对于一个<code>asyncio</code>用户来说，用协程编程比你在这里看到的简单多。在上面的代码中，我们从基本原理开始实现协程，所以你看到了回调，<code>tasks and futures</code>。甚至你看见了非阻塞的<code>socket</code>和<code>select</code>调用。但是当需要用<code>asyncio</code>构建应用的时候，这些都不会出现在你的代码里。如我们所承诺的，你现在可以轻松抓取一个<code>URL</code>：</p><pre><code class="python">    @asyncio.coroutine        def fetch(self, url):            response = yield from self.session.get(url)            body = yield from response.read()</code></pre><p>满足于此，我们回到了最初的任务:使用<code>asyncio</code>编写一个异步<code>web</code>爬虫。</p><h2 id="整合协程"><a href="#整合协程" class="headerlink" title="整合协程"></a>整合协程</h2><p>我们首先描述了我们希望爬虫如何工作。现在，是时候去用<code>asyncio 协程</code>实现它了。</p><p>我们的爬虫将抓取第一个页面，解析它的链接，并把它们加入一个队列。之后，它会散布在整个网站上，并发抓取页面。但是为了限制客户端和服务器的负载，我们希望有一些最大运行数量的<code>works</code>，而不是无限多。当一个<code>worker</code>抓取到一个页面，它应该立即从队列中<code>pull</code>下一个链接。我们将会经历一段没有足够的工作去做的时期，所以一些<code>workers</code>必须暂停。但是当一个<code>worker</code>点击一个有很多新链接的页面时，队列会突然增加，并且任何暂停的<code>workers</code>都应该苏醒并开始工作。最后，一旦<code>work</code>结束，我们的程序必须退出。</p><p>想象一下，如果这些<code>workers</code>是线程们。我们怎样才能表达这个爬虫算法？我们需要使用一个<code>Python</code>标准库中的同步队列[^13]。每当一个<code>item</code>放入队列，队列就会增加<code>&quot;tasks&quot;</code>的计数。工作线程在完成一个<code>item</code>工作后调用<code>task_done</code>。主线程将会阻塞在<code>Queue.join</code>直到每个放到队列中<code>item</code>被<code>task_done</code>调用匹配，然后退出。</p><p>协程与<code>asyncio</code>队列使用完全相同的模式！ 首先我们导入它：</p><pre><code class="python">try:    from asyncio import JoinableQueue as Queueexcept ImportError:    # 在 Python 3.5，asyncio.JoinableQueue 并入到了 Queue    from asyncio import Queue</code></pre><p>我们在一个<code>crawler</code>类中收集<code>workers</code>的共享状态，并将主要逻辑写在<code>crawl</code>方法中。我们在一个协程中启动<code>crawl</code>并运行<code>asyncio</code>时间循环，直到<code>crawl</code>结束：</p><pre><code class="python">loop = asyncio.get_event_loop()crawler = crawling.Crawler(&#39;http://xkcd.com&#39;,                           max_redirect=10)loop.run_until_complete(crawler.crawl())</code></pre><p><code>crawler</code>从一个根<code>URL</code>和<code>max_reirect</code>开始，抓取任何一个<code>URL</code>时都会遵循<code>redirects</code>的次数。它会把<code>(URL, max_redirect)</code>成对放入队列中（至于原因，请继续关注）。</p><pre><code class="python">class Crawler:    def __init__(self, root_url: str, max_redirect: int):        self.max_tasks = 10        self.max_redirect = max_redirect        self.q = Queue()        self.seen_urls = set()        # aiohttp 的 ClientSession 执行连接池 并且 HTTP 为我们 keep-alive        self.session = aiohttp.ClientSession(loop=loop)        # 把 (URL, max_redirect) 放入队列        self.q.put((root_url, self.max_redirect))</code></pre><p>没有完成的<code>tasks</code>数量现在只有一个。回到我们的主脚本，我们运行事件循环和<code>crawl</code>方法：</p><pre><code class="python">loop.run_until_complete(crawler.crawl())</code></pre><p><code>crawl</code>协程让<code>workers</code>开始工作。看起来像一个主线程：它阻塞在<code>join</code>直到所有的任务结束，而<code>workers</code>在后台运行。</p><pre><code class="python">    @asyncio.coroutine    def crawl(self):        &quot;&quot;&quot;运行 crawler 直到所有的工作完成&quot;&quot;&quot;        wokers = [asyncio.Task(self.work())                  for _ in range(self.max_tasks)]        # 当所有任务完成，退出        yield from self.q.join()        for w in wokers:            w.cancel()</code></pre><p>如果我们的<code>workers</code>是线程，我们可能并不希望他们在同一时刻开始。为了在确定需要其他线程之前避免创建昂贵的线程，线程池通常需要按需增长。但是协程很廉价，所以我们简单的在开始设置最大数目即可。</p><p>值得注意的是我们如何关闭<code>crawler</code>的。当<code>join</code>的<code>future</code>释放时<em>（resolve）</em>，<code>worker</code>的任务还存在但是已经暂停了：它们等着更多的<code>URLs</code>但是还没有到来。所以，主协程在退出之前取消掉它们。否则，当<code>Python</code>解释器关闭并调用所有对象的析构函数时，正在运行的任务会提示到：</p><pre><code>ERROR:asyncio:Task was destroyed but it is pending!</code></pre><p>那么我们如何<code>cancel</code>工作？生成器有一个特性我们还没有给你展示过。你可以从外面向生成器里面抛出一个异常。</p><pre><code class="python">&gt;&gt;&gt; gen = gen_fn()&gt;&gt;&gt; gen.send(None)  # 和往常一样启动生成器。1&gt;&gt;&gt; gen.throw(Exception(&#39;error&#39;))Traceback (most recent call last):  File &quot;&lt;input&gt;&quot;, line 3, in &lt;module&gt;  File &quot;&lt;input&gt;&quot;, line 2, in gen_fnException: error</code></pre><p>生成器由<code>throw</code>恢复，但是它现在引出了一个异常。如果没有代码在生成器的调用栈中捕获异常，该异常会冒泡回到栈顶。所以去取消一个<code>task</code>的协程：</p><pre><code class="python">  # Task 类的方法    def cancel(self):        self.coro.throw(CancelledError)</code></pre><p>不论生成器在哪里暂停，在某个<code>yield from</code>语句，它都会恢复并抛出一个异常。我们在<code>task</code>的<code>step</code>方法中处理该取消：</p><pre><code class="python">  # Task 类的方法    def step(self, future: Future) -&gt; None:        try:            next_future = self.coro.send(future.result)        except CancelledError:            self.cancelled = True            return         except StopIteration:            return        next_future.add_done_callback(self.step)</code></pre><p>现在<code>task</code>知道它被取消了，所以当它被摧毁时，它不会对看不到光芒而愤怒。</p><p>一旦<code>crawl</code>已经取消了<code>workers</code>，它会退出。事件循环看见协程结束了<em>（之后我们再看）</em>，它也会退出。</p><pre><code>loop.run_until_complete(crawler.crawl())</code></pre><p><code>crawl</code>方法包含了所有我们主协程必须做的事。从队列中获取<code>URLs</code>，抓取和解析新链接是<code>worker</code>协程做的事情。每个<code>worker</code>都会独立的运行<code>work</code>协程：</p><pre><code class="python">    @asyncio.coroutine    def work(self):        while True:            url, max_redirect = yield from self.q.get()            # 下载页面并向 self.q 中增加新链接            yield from self.fetch(url, max_redirect)            self.q.task_done()</code></pre><p><code>Python</code>发现代码中包含<code>yield from</code>语句，将其编译成生成器函数。所以在<code>crawl</code>中，当主协程调用<code>self.work</code>10次，它不会真正的执行函数：它仅仅创建了10个引用这段代码的生成器对象。它会封装每个<code>Task</code>.<code>Task</code>每次收到生成<code>yields</code>的<code>future</code>，当<code>future resolves</code>时，就会通过调用每个带有<code>future</code>结果的<code>send</code>来驱动该生成器。因为每个生成器都有它们自己的栈帧，它们运行独立，有隔离的局部变量及程序计数器。</p><p><code>worker</code>通过队列和伙伴们协调。等待新的<code>URL</code>:</p><pre><code class="python">    url, max_redirect = yield from self.q.get()</code></pre><p>队列的<code>get</code>方法本身就是一个协程：在有人放一个<code>item</code>到队列中之前都是暂停的，之后就会恢复并返回<code>item</code>。</p><p>顺便说一句，当主协程取消它时，这个地方就是在<code>crawl</code>的最后被暂停的位置。以协程的角度来看，当<code>yield from</code>引出一个<code>CancelledError</code>异常时，最后一次循环就结束了。</p><p>当一个<code>worker</code>抓取一个页面时，解析链接并向队列中放入新的链接，之后调用<code>task_done</code>并递减计数器。最终，一个<code>worker</code>抓取一个其<code>URLs</code>已被全部抓取的页面，并且队列中也没有剩余的<code>work</code>。因此，<code>workers</code>调用<code>task_done</code>计数器递减至0。在这之后正在等待队列的<code>join</code>方法的<code>crwal</code>将不再暂停并结束运行。</p><p>我们答应了解释为什么放入队列的<code>items</code>为什么是一对，就像：</p><pre><code class="python"># 去抓取的 URL， 剩余重定向的次数(&#39;http://xkcd.com/353&#39;, 10)</code></pre><p>新的<code>URLs</code>有10次重定向次数。获取这个特定的<code>URL</code>将导致重定向到一个后面带有斜杠的新位置。我们递减保留的重定向数目，并将下一个地址放入队列中：</p><pre><code class="python"># 末尾有斜杠的 URL, 剩余9次重定向(&#39;http://xkcd.com/353/&#39;, 9)</code></pre><p>我们使用的<code>aiohttp</code>包默认的会遵循重定向并给我们最后的响应。但是，我们告诉它不要这样做，在<code>crawler</code>中处理重定向，所以这样就可以合并指向相同位置的重定向地址：如果是我们抓取过这个<code>URL</code>，它会在<code>self.seen_urls</code>中并且我们也从不同的入口点开始了：</p><p><img src="http://aosabook.org/en/500L/crawler-images/redirects.png" srcset="/img/loading.gif" alt="Redirects"></p><p>​                                                                                <em>Figure 5.4 - Redirects</em></p><p><code>crawler</code>抓取<code>&quot;foo&quot;</code>并看到了它重定向到<code>&quot;baz&quot;</code>，所以它将<code>&quot;baz&quot;</code>加进队列和<code>seen_urls</code>。如果下个页面抓取的是同样会重定向到<code>&quot;baz&quot;</code>的<code>&quot;bar&quot;</code>，<code>fetcher</code>不会再将<code>&quot;baz&quot;</code>入队。如果响应是一个页面，而不是重定向，<code>fetch</code>会解析页面的链接并将新的链接放入队列。</p><pre><code class="python">    @asyncio.coroutine    def fetch(self, url: str, max_redirect: int):        # 我们自己处理 redirects        response = yield from self.session.get(            url, allow_redirects=False        )        try:            if is_redirect(response):                if max_redirect &gt; 0:                    next_url = response.headers[&#39;location&#39;]                    if next_url in self.seen_urls:                        # 我们已经下载过这个路径                        return                # 记录我们已经看过这条连接                self.seen_urls.add(next_url)                # 跟进重定向，重定向次数减一                self.q.put_nowait((next_url, max_redirect - 1))            else:                links = yield from self.parse_links(response)                # python集合逻辑                for link in links.dirrerence(self.seen_urls):                    self.q.put_nowait((link, self.max_redirect))                self.seen_urls.update(links)        finally:            # 返回连接池            yield from response.release()</code></pre><p>如果这是多线程的代码，则竞争条件会很糟糕。比如说，<code>woker</code>检查一个链接是否在<code>seen_urls</code>中时，如果不在，<code>worker</code>将会把链接放入队列并加入<code>seen_urls</code>。如果在两次操作中间被打断，然后另一个<code>worker</code>可能从一个不同的页面解析到同样的链接，也需要检查它不是不是不在<code>seen_urls</code>中，并且也需要把它加入队列。那么现在同样的链接将会在队列中出现两次，导致（最好的情况下）重复工作和错误的统计信息。</p><p>然而，一个协程只会在有<code>yield from</code>语句时容易中断。这就是一个关键区别，使得协程代码比多线程代码更不容易出现竞争：多线程代码必须利用锁来显示的进入临界部分，否则它是可以中断的。一个<code>Python</code>协程默认情况下是不可中断的，只有当它显式的<code>yields</code>时才会放弃控制。</p><p>我们不再需要一个像我们基于回调的程序中的<code>fetcher</code>类。该<code>class</code>是一个缺少回调的解决办法：当在等待<code>I/O</code>时他们需要一些位置来存储状态，因为它们的局部变量是不会在回调之间保留。但是<code>fetch</code>协程可以与常规函数一样在局部变量中保存状态，所以这里不再需要一个<code>class</code>。</p><p>当<code>fetch</code>处理完<code>server</code>的响应时，它会返回给调用方<code>work</code>。<code>work</code>方法调用队列的<code>task_done</code>方法，然后从队列中获取到下一个要被抓取的<code>URL</code>。</p><p>当<code>fetch</code>放入一个新的链接到队列时，它会增加未完成的<code>tasks</code>的数量，并使在等待<code>q.join</code>的主协程暂停。但是，如果没有未抓取过的链接，该链接就是队列中的最后一个链接，在<code>work</code>调用<code>task_done</code>之后，未完成的<code>tasks</code>的数量将会降为0。该事件将会不再暂停<code>join</code>，主协程完成。</p><p>协调<code>workers</code>和主协程的队列代码就像这样[^14]：</p><pre><code class="python">import asyncioclass Queue:    def __init__(self):        self._join_future = Future()        self._unfinished_tasks = 0        # ... 其他的初始条件    def put_nowait(self, item):        self._unfinished_tasks += 1        # ... 保存 item    def task_done(self):        self._unfinished_tasks -= 1        if self._unfinished_tasks == 0:            self._join_future.set_result(None)    @asyncio.coroutine    def join(self):        if self._unfinished_tasks &gt; 0:            yield from self._join_future</code></pre><p>主协程<code>crawl</code>，<code>yields from</code> <code>join</code>。所有当最后一个<code>worker</code>将减少未完成的<code>tasks</code>的数量减少至<code>0</code>的时候，就标志着<code>crawl</code>恢复并结束。</p><p>旅程快结束了。我们的程序以调用<code>crawl</code>开始：</p><pre><code>loop.run_until_complete(self.crawler.crawl())</code></pre><p>程序怎么结束的呢？因为<code>crawl</code>是一个生成器函数，调用之后返回一个生成器。为了驱动生成器，<code>asyncio</code>封装了一个<code>task</code>:</p><pre><code class="python">class EventLoop:    def run_until_complete(self, coro):        &quot;&quot;&quot;运行直到生成器结束&quot;&quot;&quot;        task = Task(coro)        task.task_done_callback(stop_callback)        try:            self.run_forever()        except StopError：            passclass StopError(BaseException):    &quot;&quot;&quot;抛出停止事件循环&quot;&quot;&quot;def stop_callback(future):    raise StopError</code></pre><p>当<code>task</code>结束，它会引发作为循环使用的作为正常结束的信号<code>StopError</code>。</p><p>但是这是什么？<code>task</code>有一个叫做<code>add_done_callback</code>的方法和<code>result</code>？你可能会认为<code>task</code>就像<code>future</code>。你的直觉是对的。我们必须承认一个我们向你隐藏的<code>Task类</code>的细节：<code>task</code>就是<code>future</code>。</p><pre><code class="python">class Task(Future):    &quot;&quot;&quot;封装在 Future 的协程&quot;&quot;&quot;</code></pre><p>正常情况下，一个<code>future</code>被某些其他调用自己的<code>set_result resolves</code>。但是当协程停止时，<code>task resolves</code><em>自己</em>。请记住，在我们直接对<code>Python生成器的</code>探索中，当一个生成器<code>return</code>时，它会引发一个特殊的<code>StopIteration</code>异常：</p><pre><code class="python">    def step(self, future: Future) -&gt; None:        try:            next_future = self.coro.send(future.result)        except CancelledError:            self.cancelled = True            return        except StopIteration as exc:            # Task 用 coro&#39;s 返回值 resolves 自己             self.set_result(exc.value)            return        next_future.add_done_callback(self.step)</code></pre><p>所以当事件循环调用<code>task.add_done_callback(stop_callback)</code>时，它就准备被<code>task</code>停止。这里再一次的<code>run_until_complete</code>：</p><pre><code class="python">    def run_until_complete(self, coro):        &quot;&quot;&quot;运行直到生成器结束&quot;&quot;&quot;        task = Task(coro)        task.task_done_callback(stop_callback)        try:            self.run_forever()        except StopError:            pass</code></pre><p>当<code>task</code>捕获到<code>StopIteration</code>并<code>resolves</code>自己，回调在循环中引发<code>StopError</code>。循环停止，调用堆栈退回到<code>run_until_complete</code>。 我们的程序结束了。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>现代程序越来越经常受<code>I / O</code>约束，而不是受<code>CPU</code>约束。对于这样的程序，<code>Python</code>线程在这些领域是很糟糕的：全局解释锁阻止了它们真实地执行并行计算，并且抢占式切换让它们容易发生竞争。异步通常是正确的选择。但是随着基于回调的异步代码增长，它往往会变成一团糟。协程是一个不错的选择。它们自然地将异常处理和堆栈跟踪纳入子程序。</p><p>如果我们眯着眼并模糊的看<code>yield from</code>语句，协程看起来就像传统的阻塞<code>I/O</code>线程。甚至我们可以用多线程编程中的经典模式来协调协程。无需重复造轮子。因此，与回调相比，协程对于多线程编程经验丰富的程序员来说是一种更有吸引力的习惯用法。</p><p>但是当我们睁开眼并聚焦到<code>yield from</code>语句时，我们可以看到，当协程放弃控制权并允许其他代码运行时，它们会标记一个点。不同于线程，协程展示了我们的代码在哪里可以被打断哪里不能被打断。<code>Glyph Lefkowitz</code>在他富有启发性的文章《Unyielding》中写道，“线程使局部推理变得困难，局部推理也许是软件开发中最重要的事情。”然而，显示的<code>yilding</code>使”通过检查例程本身而不是检查整个系统来理解例程的行为（原因与正确性）”变得可能。</p><p>本章是在<code>Python</code>和异步技术的复兴中撰写的。基于生成器的协程(你刚刚了解了它的设计)，在<code>Python3.4</code>的<code>asyncio</code>模块中，于<code>2014年3月发布</code>。在<code>2015年的9月</code>，<code>Python 3.5</code>发布了语言本身内置的协程。这些原生的协程使用新的语法<code>&quot;async def&quot;</code>声明，并替代了<code>&quot;yield from&quot;</code>，它们使用了心得<code>&quot;await&quot;</code>关键词来委托以协程或者等待<code>Future</code>。</p><p>尽管有很多改进，但核心思想仍然没变。<code>Python</code>的新的原生的协程在语法上不同于生成器但是工作方式非常相似；实际上，它们在<code>Python</code>解释器中共享实现。<code>Task,Future和事件循环</code>在<code>asyncio</code>将会继续保持规则。</p><p>现在你知道了<code>asyncio</code>是如何工作的，你很大可能会忘记细节。机械被塞在一个精巧的接口后面。但是你对基本原理的掌握使你能够在现代异步环境中正确而有效地编写代码。</p><p>[^2]: Even calls to <code>send</code> can block, if the recipient is slow to acknowledge outstanding messages and the system’s buffer of outgoing data is full<br>[^3]: 原文作者之一<br>[^4]: <a href="http://www.kegel.com/c10k.html[↩](http://aosabook.org/en/500L/a-web-crawler-with-asyncio-coroutines.html#fnref3)" target="_blank" rel="noopener">http://www.kegel.com/c10k.html[↩](http://aosabook.org/en/500L/a-web-crawler-with-asyncio-coroutines.html#fnref3)</a><br>[^ 5]: 原文叫做 <code>overlapping</code>I/O,详情请参考：<a href="https://en.wikipedia.org/wiki/Overlapped_I/O" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Overlapped_I/O</a><br>[^6]: Jesse listed indications and contraindications for using async in <a href="http://pyvideo.org/video/2565/what-is-async-how-does-it-work-and-when-should" target="_blank" rel="noopener">“What Is Async, How Does It Work, And When Should I Use It?”:</a>. Mike Bayer compared the throughput of asyncio and multithreading for different workloads in <a href="http://techspot.zzzeek.org/2015/02/15/asynchronous-python-and-databases/" target="_blank" rel="noopener">“Asynchronous Python and Databases”:</a><a href="http://aosabook.org/en/500L/a-web-crawler-with-asyncio-coroutines.html#fnref5" target="_blank" rel="noopener">↩</a><br>[^7]: 这里的中断，就是指假如该程序有 2个协程，那么协程A是不能被协程B关闭\中断（cancel）。（一个协程函数代表一个子协程）而在多线程中，同样我们假设有2个线程，线程A是可以被线程B取消掉（也就是说能在A线程中通过信号取消/中断B线程）</p><p>[^8]: For a complex solution to this problem, see <a href="http://www.tornadoweb.org/en/stable/stack_context.html[↩](http://aosabook.org/en/500L/a-web-crawler-with-asyncio-coroutines.html#fnref6)" target="_blank" rel="noopener">http://www.tornadoweb.org/en/stable/stack_context.html[↩](http://aosabook.org/en/500L/a-web-crawler-with-asyncio-coroutines.html#fnref6)</a><br>[^9]: The <code>@asyncio.coroutine</code> decorator is not magical. In fact, if it decorates a generator function and the <code>PYTHONASYNCIODEBUG</code> environment variable is not set, the decorator does practically nothing. It just sets an attribute, <code>_is_coroutine</code>, for the convenience of other parts of the framework. It is possible to use asyncio with bare generators not decorated with <code>@asyncio.coroutine</code> at all.<a href="http://aosabook.org/en/500L/a-web-crawler-with-asyncio-coroutines.html#fnref7" target="_blank" rel="noopener">↩</a><br>[^ 10]:  Python 3.5’s built-in coroutines are described in <a href="https://www.python.org/dev/peps/pep-0492/" target="_blank" rel="noopener">PEP 492</a>, “Coroutines with async and await syntax.”<a href="http://aosabook.org/en/500L/a-web-crawler-with-asyncio-coroutines.html#fnref8" target="_blank" rel="noopener">↩</a> </p><p>[^ 11]: This future has many deficiencies. For example, once this future is resolved, a coroutine that yields it should resume immediately instead of pausing, but with our code it does not. See asyncio’s Future class for a complete implementation.<a href="http://aosabook.org/en/500L/a-web-crawler-with-asyncio-coroutines.html#fnref9" target="_blank" rel="noopener">↩</a></p><p>[^12]: In fact, this is exactly how “yield from” works in CPython. A function increments its instruction pointer before executing each statement. But after the outer generator executes “yield from”, it subtracts 1 from its instruction pointer to keep itself pinned at the “yield from” statement. Then it yields to <em>its</em> caller. The cycle repeats until the inner generator throws <code>StopIteration</code>, at which point the outer generator finally allows itself to advance to the next instruction.<a href="http://aosabook.org/en/500L/a-web-crawler-with-asyncio-coroutines.html#fnref10" target="_blank" rel="noopener">↩</a><br>[^ 13]:<a href="https://docs.python.org/3/library/queue.html[↩](http://aosabook.org/en/500L/a-web-crawler-with-asyncio-coroutines.html#fnref11)" target="_blank" rel="noopener">https://docs.python.org/3/library/queue.html[↩](http://aosabook.org/en/500L/a-web-crawler-with-asyncio-coroutines.html#fnref11)</a></p><p>[^ 14]:The actual <code>asyncio.Queue</code> implementation uses an <code>asyncio.Event</code> in place of the Future shown here. The difference is an Event can be reset, whereas a Future cannot transition from resolved back to pending.<a href="#fnref14">↩</a></p>]]></content>
    
    
    <categories>
      
      <category>翻译</category>
      
      <category>advance</category>
      
      <category>网络</category>
      
      <category>异步</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>async</tag>
      
      <tag>generator</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>从requests请求重试到万能重试装饰器</title>
    <link href="/2020/04/07/%E4%BD%BF%E7%94%A8python%E5%AE%A2ae%E4%BB%8Erequests%E8%AF%B7%E6%B1%82%E9%87%8D%E8%AF%95%E5%88%B0%E4%B8%87%E8%83%BD%E9%87%8D%E8%AF%95%E8%A3%85%E9%A5%B0%E5%99%A8/"/>
    <url>/2020/04/07/%E4%BD%BF%E7%94%A8python%E5%AE%A2ae%E4%BB%8Erequests%E8%AF%B7%E6%B1%82%E9%87%8D%E8%AF%95%E5%88%B0%E4%B8%87%E8%83%BD%E9%87%8D%E8%AF%95%E8%A3%85%E9%A5%B0%E5%99%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="从requests请求重试到万能重试装饰器"><a href="#从requests请求重试到万能重试装饰器" class="headerlink" title="从requests请求重试到万能重试装饰器"></a>从requests请求重试到万能重试装饰器</h2><p>重试，在编写代码的过程中，是一个很常见的需求。<br>比如：</p><ol><li>请求重试（例如：超时）</li><li>文件占用</li><li>IO阻塞等待</li></ol><p>那么，我们如何编写重试的代码呢？<br>本文将从请求重试开始，带大家从简单的超时重试，最后编写到万能错误重试。</p><blockquote><p>主要涉及内容：</p><ul><li>requests adapter</li><li>函数装饰器</li><li>类装饰器</li></ul></blockquote><p>话不多说，start！</p><p><strong>因为我们需要从 <code>requests</code> 请求重试开始，为了方便测试请求，我们用 <code>flask</code> 编写一个简单的服务器，用于请求测试。</strong></p><h2 id="准备请求服务器"><a href="#准备请求服务器" class="headerlink" title="准备请求服务器"></a>准备请求服务器</h2><p>服务器的功能比较简单，用来查看请求次数和观察是否重试成功，<code>flask_server.py</code>代码如下：</p><pre><code class="python">from time import sleepfrom flask import Flask, jsonify, Responseapp: Flask = Flask(__name__)retry_count: int = 0  # 用于重试请求的计数@app.route(&quot;/api/retry&quot;, methods=[&quot;GET&quot;])def retry_api() -&gt; Response:    &quot;&quot;&quot;    延时 1s 的请求接口， 响应时间 &gt; 1s。    :return:    &quot;&quot;&quot;    global retry_count    retry_count += 1    print(f&quot;这是第{retry_count}次请求&quot;)    if retry_count &lt; 3:        sleep(1)    else:        retry_count = 0  # 计数清零    return jsonify({&quot;msg&quot;: &quot;已经三次了哦！&quot;})if __name__ == &#39;__main__&#39;:    app.run()</code></pre><p>代码比较简单，由于没有找到好用的<code>flask</code>上下文来完成计数需求，这里为了简单操作，就直接应用了全局变量来计数（仅用于测试，未加锁），而没有使用<code>redis</code>数据库来计数了。</p><p>编写好之后，我们运行代码即可。这样，我们用来测试重试的服务器就准备好了。</p><p>接下来，我们先来看看一般的 <code>requests</code> 超时请求如何实现。</p><h2 id="1-requests-请求重试（常见版本）"><a href="#1-requests-请求重试（常见版本）" class="headerlink" title="1.requests 请求重试（常见版本）"></a>1.<code>requests</code> 请求重试（常见版本）</h2><p>我们用 <code>try...except...</code> 语句捕捉<code>timeout</code>错误。进行循环重试即可。我们编写一个函数 <code>get_data</code>，<code>normal.py</code>代码如下：</p><pre><code class="python">from typing import Dict, Anyimport requestsBaseDictData = Dict[str, Any]def get_data(url: str, max_retry: int = 0, time_out: float = 3., **kwargs) -&gt; BaseDictData:    &quot;&quot;&quot;自动重试 timeout 错误 的方法&quot;&quot;&quot;    params: BaseDictData = kwargs.get(&quot;params&quot;, {})  # 不管你传了什么奇怪的东西， 我只收这个    headers: BaseDictData = kwargs.get(&quot;headers&quot;, {})  # 同上    for i in range(max_retry + 1):        &quot;&quot;&quot;进行最大重试次数的遍历&quot;&quot;&quot;        try:            response: requests.Response = requests.get(                url=url,                params=params,                headers=headers,                timeout=time_out,            )        except requests.ReadTimeout:            print(f&quot;第{i + 1}次请求失败，正在重试。&quot;)        else:            return response.json()  # 没有错误，直接返回    print(f&quot;{max_retry + 1} 次请求都失败了，返回空值，便于后续逻辑处理。。。&quot;)    return {}if __name__ == &#39;__main__&#39;:    print(get_data(&quot;http://localhost:5000/api/retry&quot;, max_retry=1, time_out=.01))</code></pre><p>在该函数中，我们利用 <code>requests</code> 库本身的 <code>timeout</code> 参数进行错误捕捉。整体比较简单，设计逻辑即：</p><pre><code class="mermaid">graph LRA[请求] -- 超时重试--&gt; AA --成功--&gt; B[处理成功后的数据]A--超过最大重试次数--&gt;C[返回空数据便于后续逻辑处理]</code></pre><p>如果超时，那么就会引发错误，然后继续请求，用<code>for</code>循环来处理循环重试，更加简洁。</p><p>超过最大次数，就返回空数据，成功，返回成功数据。</p><p>代码段注意要点：<br><strong><code>try...except...</code></strong> 语句 </p><pre><code class="python">try:    ...  # 需要捕捉异常的代码except xxx:    ...  # 发生异常处理逻辑else:    ...  # 如果 try 成功执行，就执行else，否则跳过elsefinally:    ...  # 一定会执行该语句块</code></pre><p>我们在 <code>try</code> 语句块中只运行了一行代码，因为这次捕捉只针对这行代码可能会引起的错误，做到<strong>精确捕捉异常</strong>。</p><p>如果 <code>try</code> 语句块中的代码太多的话（比如要做多件事情），错误调试和错误处理都比较麻烦，因为我们不知道是哪行引起的错误，需要加（<code>print</code>） 或者 （<code>debug</code>）来查看具体错误原因，并且不要担心使用<code>try...except...</code>语句，<code>python</code>中的异常处理代价是很小的，异常处理也是很常见的。</p><p>而<code>else</code>语句块，就是正常逻辑的补充处理。</p><p><strong>TIPS:</strong><br><strong>在 <code>for...in...:</code>语句中也有<code>else</code>语句块，对完成循环后进行补充。</strong></p><details>  <summary><code>for...in...</code>示例</summary>  <p>比如，我们要循环检测一个列表<code>check_data: List[Union[int, str]] = [1, 2, 3, 4]</code>是否有字符串，如果有字符串我们就不进行后续处理，如过没有字符串，我们就调用 <code>handle_data</code> 函数。 </p><p>为了满足上面的需求，通常，我们都会写一个 <code>tag/signal</code>来标注状态，例如下面的代码：</p><pre><code class="python">has_string: bool = Falsefor data in check_data:    if isinstance(data, str):        has_string = True        breakif not has_string:    # 没有字符串的情况下    handle_data() </code></pre><p>有了 <code>else</code> 我们就可以简化代码，如下：</p><pre><code class="python">for data in check_data:    if isinstance(data, str):        breakelse:    # 没有字符串的情况下    handle_data() </code></pre><p>这样逻辑就可以更清晰一些。另外， <code>while 循环</code>也支持 <code>else</code> 语句，这里就不重复演示了。</p></details><h4 id="查看效果。"><a href="#查看效果。" class="headerlink" title="查看效果。"></a>查看效果。</h4><p>我们调用 <code>print(get_data(&quot;http://localhost:5000/api/retry&quot;, max_retry=2, time_out=.01))</code><br>客户端结果:</p><pre><code>第1次请求失败，正在重试。第2次请求失败，正在重试。{&#39;msg&#39;: &#39;已经三次了哦！&#39;}</code></pre><p>服务端结果：</p><pre><code>这是第1次请求这是第2次请求这是第3次请求</code></pre><p>这里 <code>max_retry</code> 为最大<strong>重试</strong>次数，所以最大请求次数为<code>1+max_retry</code>。</p><p>我们调用<code>print(get_data(&quot;http://localhost:5000/api/retry&quot;, max_retry=1, time_out=.01))</code><br>客户端结果:</p><pre><code>第1次请求失败，正在重试。第2次请求失败，正在重试。2 次请求都失败了，返回空值，便于后续逻辑处理。。。{}</code></pre><p>服务端结果：</p><pre><code>这是第1次请求这是第2次请求</code></pre><p>可以看出，整体效果也是符合预期的，没有多大问题。<br>接下来，我们利用<code>requests</code>自带的请求重试器。</p><h2 id="2-requests-adapter-重试"><a href="#2-requests-adapter-重试" class="headerlink" title="2. requests adapter 重试"></a>2. <code>requests adapter</code> 重试</h2><p><code>requests</code> 有一个 <code>HTTPAdapter</code> 对象，看名字就有一种可以给 <code>requests</code>加特效的感觉。</p><p>不过 <code>HTTPAdapter</code> 主要可以实现：</p><blockquote><p>创建连接池，（类似线程池，进程池，连接可服用）<br>限定连接池数量（避免连接数过多（线程过多））。<br>重试请求。</p></blockquote><p><code>requests_built.py</code>代码如下：</p><pre><code class="python">import requestsfrom requests.adapters import HTTPAdapterfrom normal import BaseDictDatadef get_data(url: str, max_retry: int = 0, time_out: float = 1., **kwargs) -&gt; BaseDictData:    &quot;&quot;&quot;    自动重试 timeout 错误 的方法, 用 requests 自带轮子完成！    :param url: 请求的 url    :param max_retry: 最大重试次数    :param time_out: 超时重试时间    :param kwargs: 可选命名参数    :return: BaseDictData    &quot;&quot;&quot;    session: requests.Session = kwargs.get(&quot;session&quot;, requests.Session())  # 获取session 或者新建 session    params: BaseDictData = kwargs.get(&quot;params&quot;, {})  # 不管你传了什么奇怪的东西， 我只收这个    headers: BaseDictData = kwargs.get(&quot;headers&quot;, {})  # 同上    adapter: HTTPAdapter = HTTPAdapter(max_retries=max_retry)  # 初始自带处理额外操作的适配器    session.mount(&quot;http://127.0.0.1&quot;, adapter=adapter)  # 给我们的 session 安装上 adapter, 第一个参数为主机，代表对于哪台主机的请求需要装上适配器    try:        response: requests.Response = session.get(            url,            params=params,            headers=headers,            timeout=time_out        )    except requests.ConnectTimeout:        print(f&quot;{max_retry + 1}次请求都失败了，即将返回空值，请耐心等待...&quot;)    else:        session.close()  # 关闭 session, 源码主要是清除所有装配器        return response.json()    return {}if __name__ == &#39;__main__&#39;:    res = get_data(&quot;http://127.0.0.1:5000/api/retry&quot;, 3)    print(res)</code></pre><p>整体代码也比较简单，在常规请求之上，主要加了两行代码。就是给 <code>Session</code> 对象用 <code>mount</code> 方法给对于 <code>http://127.0.0.1</code>的主机请求加上了 <code>adapter</code>，该<code>adapter</code>对象增加了最大的重试次数。</p><p>PS：</p><ul><li>我们也可以用 <code>http://</code> 来表示对于所有<code>http请求</code>的主机都装上<code>adapter</code></li><li>我们也可以针对多个请求主机<pre><code class="python">session.mount(&quot;http://127.0.0.1&quot;, adapter=adapter)session.mount(&quot;https://github.com&quot;, adapter=adapter)</code></pre>运行结果（服务器端相似，之后的展示只展示客户端）:</li></ul><p><code>print(get_data(&quot;http://127.0.0.1:5000/api/retry&quot;, 2))</code></p><p>客户端：</p><pre><code>{&#39;msg&#39;: &#39;已经三次了哦！&#39;}</code></pre><p><code>print(get_data(&quot;http://127.0.0.1:5000/api/retry&quot;, 1))</code></p><p>客户端：</p><pre><code>2次请求都失败了，即将返回空值，请耐心等待...{}</code></pre><h2 id="3-构造请求重试装饰器"><a href="#3-构造请求重试装饰器" class="headerlink" title="3.构造请求重试装饰器"></a>3.构造请求重试装饰器</h2><p>通过前两个方法来看，我们知道主要的重试方式有两种：</p><ol><li>循环请求</li><li><code>requests</code>自带的适配器</li></ol><p>但是呢，这两种，可复用性不太强，我们升级一下，用装饰器来试试。（当然，也有其他复用方法，比如创建重试专用对象，或者加入重试调度器）</p><p>当然装饰器的写法，我们至少也可以写出两种版本。</p><details><summary>python装饰器原理速览</summary> <p>统计函数运行时间的装饰器<code>derector.py</code>：</p><pre><code class="python">import timedef count_fun_time(func):    def wrapper(*arg, **kwargs):        start_time = time.time()        res = func(*arg, **kwargs)        print(f&quot;函数总共运行了{time.time() - start_time:.2f}s&quot;)        return res    return wrapperdef my_function(time_wait: int = 3):    time.sleep(time_wait)    print(&quot;运行结束&quot;)my_function = count_fun_time(my_function)my_function()my_function(4)</code></pre><p> 上面的代码示例为原始版本，就是利用函数的<strong>闭包特性(闭包函数)</strong>，在函数内部调用函数，同时进行其他操作即可。</p><p>然后将<strong>新函数重新命名为原函数的名字</strong>。</p><p> 运行结果如下：</p><pre><code> 运行结束函数总共运行了3.00s运行结束函数总共运行了4.00s</code></pre><p> 当然，简便的python不会让你这样写，于是，语法糖便出现了。</p><p> 我们的计算运行时间的装饰器函数 <code>count_fun_time</code>不变，</p><p> 只需要在<code>my_funtion</code>上面加上糖<code>@count_fun_time</code> 即可。</p><pre><code class="python">@count_fun_timedef my_function(time_wait: int = 3):    time.sleep(time_wait)    print(&quot;运行结束&quot;)my_function()my_function(4)</code></pre><p> 从上面的代码我们也可以，装饰器函数使用语法糖之后更加的<strong>优雅和易懂。</strong></p><p> 但是在装饰器装饰元函数之后，元信息有所损坏(例如:<code>my_function.__name__</code>缺失)，需要进行改良（改良方法在下文中出现。）</p></details><h3 id="3-1-构造被装饰的函数get-data"><a href="#3-1-构造被装饰的函数get-data" class="headerlink" title="3.1 构造被装饰的函数get_data"></a>3.1 构造被装饰的函数<code>get_data</code></h3><p>既然是装饰器，那么我们先定义一个<strong>请求函数</strong>，当作被装饰的函数。</p><p>代码如下：</p><pre><code class="python">def get_data(url: str, time_out: float = 3., **kwargs) -&gt; BaseDictData:    &quot;&quot;&quot;    自动重试 timeout 错误 的方法, 用 requests 自带轮子完成！    :param url: 请求的 url    :param time_out: 超时重试时间    :param kwargs: 可选命名参数    :return: BaseDictData    &quot;&quot;&quot;    session: requests.Session = kwargs.get(&quot;session&quot;, requests.Session())  # 获取session 或者新建 session    params: BaseDictData = kwargs.get(&quot;params&quot;, {})  # 不管你传了什么奇怪的东西， 我只收这个    headers: BaseDictData = kwargs.get(&quot;headers&quot;, {})  # 同上    with session.get(url, params=params, headers=headers, timeout=time_out) as response:        return response.json()</code></pre><p>代码很简单，为了通用性（因为有两种装饰器，循环和<code>adapter</code>)，我们选择使用 <code>Session对象</code>来做请求。</p><p>好了，开始装饰器的正题。</p><h3 id="3-1-循环重试装饰器"><a href="#3-1-循环重试装饰器" class="headerlink" title="3.1  循环重试装饰器"></a>3.1  循环重试装饰器</h3><p>首先，我们先构思一下，我们的装饰器要完成什么。</p><p><code>get_data</code> 这个函数为内部函数，可能<code>timeout</code>，我们复用之前写的错误即可，然后捕捉该错误。</p><p>接下来，如果运行函数出错，我们就进行循环重试。</p><h4 id="3-1-1-基本循环重试装饰器"><a href="#3-1-1-基本循环重试装饰器" class="headerlink" title="3.1.1 基本循环重试装饰器"></a>3.1.1 基本循环重试装饰器</h4><p>整体代码如下：</p><pre><code class="python">from functools import wrapsdef retry(func):    @wraps(func)  # 保留被装饰函数的元信息    def closure(*args, **kwargs) -&gt; BaseDictData:        for i in range(3):            try:                res = func(*args, **kwargs)            except (requests.ConnectTimeout, requests.ReadTimeout):                print(f&quot;第{i + 1}次重试。&quot;)            else:                return res        return {}    return closure@retrydef get_data(...):    --skip--</code></pre><p>这里我们利用 <code>@wraps</code> 保留元函数信息。这样我们就可以看到完整的被装饰后函数的信息。例如:<code>get_data.__name__， 函数签名，函数文档等</code>。</p><p>运行结果类似，我们就不展示了，内容有点重复。<br>整体逻辑其实和<code>for...in...</code>循环的重试基本一致，但是我们封装成了一个装饰器函数，这样我们就可以到处用！简直不能太方便。<br>于此同时，我们可以看到 <code>except  (requests.ConnectTimeout, requests.ReadTimeout)</code> 这个地方！可以操作一下，假如错误类型是变量，那是不是就可以捕捉想捕捉的任意错误了。 并且，最大重试次数我们是写死的，这里肯定也能写成变量。那么，如何书写呢？</p><p><strong>再加一层闭包。</strong> 没错，我们再套一层函数即可。</p><h4 id="3-1-2-任意错误循环重试的函数装饰器"><a href="#3-1-2-任意错误循环重试的函数装饰器" class="headerlink" title="3.1.2 任意错误循环重试的函数装饰器"></a>3.1.2 任意错误循环重试的函数装饰器</h4><p><code>strong_retry</code>代码如下:</p><pre><code class="python">def strong_retry(        max_retry: int = 3,        exception: Tuple[BaseException] = (                requests.ConnectTimeout,                requests.ReadTimeout,        )):    &quot;&quot;&quot;    万能函数重试装饰器诞生！    :param max_retry: 最大重试次数    :param exception: 捕捉错误类型    :return:    &quot;&quot;&quot;    def retry(func):        @wraps(func)  # 保留被装饰函数的元信息        def closure(*args, **kwargs) -&gt; BaseDictData:            for i in range(max_retry + 1):                try:                    res = func(*args, **kwargs)                except exception:                    print(f&quot;第{i + 1}次重试。&quot;)                else:                    return res            return {}        return closure    return retry@strong_common_retry(max_retry=4, exception=(requests.ReadTimeout,))def get_data(...):    # 装饰函数，最大重试数为 4，</code></pre><p>再在外层函数帮助我们传入参数，并在原装饰器函数内部使用参数即可。</p><p>这样，我们就能针对<strong>某些错误进行重试</strong>操作了！（有一个模块 <code>retrying</code>, 也能进行错误重试，我们轻松的实现了一个简易版本！）</p><blockquote><p>例如:<br>@strong_common_retry(exception=(ValueError, NameError))  # 针对这两个错误进行捕捉<br>但是有一点需要注意，千万不要用 <code>exception=(BaseException,)</code> !!!!这样连<kbd>Ctrl/Command</kbd> + <kbd>C</kbd> 都失效了！（引发<code>KeyboardInterrupt</code>错误的方法）</p></blockquote><p>到这里完了吗？当然没有，因为我们还能再优化一下，当装饰器带有参数时，装饰器函数嵌套层数太多。影响阅读，这时候，祭出我们的装饰器神器<code>wrapt</code>。(需要 <code>pip install wrapt</code>)<br>使用后代码如下:</p><pre><code class="python">def strong_common_retry(max_retry, exception):    @wrapt.decorator  # 保留被装饰函数的元信息    def wrapper(wrapped, instance, args, kwargs) -&gt; BaseDictData:        &quot;&quot;&quot;        :param wrapped:         :param instance:如果被装饰者为普通类方法，该值为类实例                        如果被装饰者为 classmethod 类方法，该值为类                        如果被装饰者为类/函数/静态方法，该值为 None         :param args:         :param kwargs:         :return:         &quot;&quot;&quot;        for i in range(max_retry + 1):            try:                res = wrapped(*args, **kwargs)            except exception:                print(f&quot;第{i + 1}次重试。&quot;)            else:                return res        return {}    return wrapper</code></pre><p>这样快速地就<strong>减少了装饰器函数的嵌套层数</strong>，同时还能解决对类中的函数装饰器绑定对象的问题。</p><p>所以当需要编写装饰器函数的时候，不妨试试<code>wrapt</code>吧！绝对是你的好帮手！</p><p>循环重试搞定了，函数装饰器也讲的差不多了，但是我们还有适配器装饰器没有讲，怎么办！当然换点花样，类的装饰器 <strong>start</strong>。</p><h3 id="3-2-Session适配器重试"><a href="#3-2-Session适配器重试" class="headerlink" title="3.2 Session适配器重试"></a>3.2 <code>Session</code>适配器重试</h3><p>这次，我们的装饰器需要实现对原请求函数中的 <code>Session对象</code> 添加适配器，但是我们需要用类来实现。</p><p>但是类怎么实现呢？装饰器函数比较好理解，调用函数<code>func()</code>，我们就能完成原函数的替代。但是类怎么调用呢？ 这时候，就需要 python 给我们提供的魔术方法（双下方法）<code>__call__</code> 来实现了！</p><h4 id="3-2-1-类装饰器原理"><a href="#3-2-1-类装饰器原理" class="headerlink" title="3.2.1 类装饰器原理"></a>3.2.1 类装饰器原理</h4><p>其实<code>__call__</code>方法理解比较简单，就是可以让实例话的对象直接调用。Examples are as follows:</p><pre><code class="python">class MySpider:    def __call__(self):        print(f&quot;{self.__class__.__name__} is calling&quot;)MySpider()()</code></pre><p>输出结果如下：<br><code>MySpider is calling</code></p><p>这样我们就成功调用了实例化对象。</p><p>利用这个特性，我们就可以自然地写出装饰器类。</p><pre><code class="python">class MySpider:    def __init__(self, func: Callable):        self.func = func    def __call__(self, *args, **kwargs):        print(&quot;reset for on second&quot;)        time.sleep(1)        res_data = self.func(*args, **kwargs)        return res_data    def at_once_run(self, *args, **kwargs):        print(&quot;now, run the function&quot;)        return self.func(*args, **kwargs)def spider():    print(&quot;正在抓取&quot;)spider = MySpider(spider)spider()</code></pre><p>输出结果如下：</p><pre><code>reset for on second正在抓取</code></pre><p>与装饰器函数很像，核心就是 <code>__call__</code> 方法。<br>那么类的装饰器有什么好处呢？</p><blockquote><ol><li>没有复杂的函数嵌套，阅读代码时更加清晰，更加pythonic。</li><li>可以增加许多额外的属性，更好的管理装饰器对象。</li><li>可以给装饰器添加更多的功能。</li></ol></blockquote><p>功能怎么加呢？别忘了我们上个代码段还有一个函数没有使用！话不多说，直接看看怎么用。<br>原始用法：</p><pre><code class="python">spider = MySpider(spider).at_once_runspider()</code></pre><p>但是看起来并不优雅，每次也比较麻烦。<br>语法糖用法：</p><pre><code class="python">@MySpiderdef spider():    ...spider.at_once_run()</code></pre><p>运行结果如下：</p><pre><code>now, run the function正在抓取</code></pre><p>就像加了魔法一样，我们的原始函数<code>spider</code>变得异常强大，还增加了许多新的功能！</p><p>好了，把类当作装饰器的简单原理如上。接下来，我们就展示一下，用类装饰器为<code>Session</code>对象撞上翅膀！</p><h4 id="3-2-2-类装饰器实战"><a href="#3-2-2-类装饰器实战" class="headerlink" title="3.2.2 类装饰器实战"></a>3.2.2 类装饰器实战</h4><p>代码如下：</p><pre><code class="python">class RequestsRetry:    def __init__(self, max_retry: int, func: Callable) -&gt; None:        &quot;&quot;&quot;需要注意。被装饰的函数是最后传入的。&quot;&quot;&quot;        self.max_retry = max_retry        functools.wraps(func)(self)  # 保留原函数的元信息        self.func = func    def __call__(self, *args, **kwargs) -&gt; BaseDictData:        &quot;&quot;&quot;装饰器处理逻辑函数&quot;&quot;&quot;        session: requests.Session = kwargs.get(&quot;session&quot;, requests.Session())  # 获取session 或者新建 session        max_retry: requests.Session = kwargs.get(&quot;max_retry&quot;)  # 获取 max_retry        adapter: HTTPAdapter = HTTPAdapter(max_retries=max_retry)  # 初始自带处理额外操作的适配器        session.mount(&quot;http://&quot;, adapter=adapter)  # 给我们的 session 安装上 adapter, 第一个参数为前缀，代表哪种请求需要装上适配器        kwargs.update(session=session)  # 更新 session， 如果没有传session，就将带适配器的 session 传入命名参数        try:            response: BaseDictData = self.func(*args, **kwargs)        except requests.ConnectTimeout:            print(f&quot;{max_retry}次请求都超时了，即将返回空值，请耐心等待返回空值&quot;)            return {}        else:            return response    def itself(self, *args, **kwargs) -&gt; BaseDictData:        &quot;&quot;&quot;不做处理，调用本身&quot;&quot;&quot;        return self.func(*args, **kwargs)    def __get__(self, instance, owner) -&gt; object:        &quot;&quot;&quot;实现该方法后，可以将装饰器器用于类的函数的装饰。&quot;&quot;&quot;        if instance is None:            return self        return types.MethodType(self, instance)  # 如果有参数，就绑定至selfdef retry(max_retry: int = 3):    &quot;&quot;&quot;装饰器包装，增加请求重试参数。&quot;&quot;&quot;    # 此处为了避免定义额外函数，直接使用 functools.partial 帮助构造 RequestsRetry 实例    return functools.partial(RequestsRetry, max_retry)@retry(max_retry=3)def get_data(url: str, time_out: float = 3., **kwargs) -&gt; BaseDictData:    --skip--</code></pre><p><code>__init__</code>方法比较简单，接受了一个额外参数<code>max_retry</code>，然后利用<code>functools</code>保留<strong>元函数信息</strong>，和函数装饰器类似。<br>然后核心代码为<code>__call__</code>中的部分我们利用<code>kwargs</code>获取传入的<code>Session</code>对象，然后再将该对象加上<strong>适配器</strong>，然后还给<code>kwargs</code>，即可。这样就加上了最大重试次数，也就自带重试功能了。比<code>for...in...</code>更加简单，逻辑更加清晰，但是缺点就是只能针对<code>Session</code>对象的错误，不能针对万能错误进行重试。</p><p>最后<code>retry</code>函数，用了一个<code>partial</code>函数<strong>辅助构造</strong>（如果不实用该函数，为装饰器增加<code>max_retry</code>参数较为麻烦，此处不展开说明方法，感兴趣可以自己尝试，欢迎和我交流）类装饰器，顺便给装饰器换了个名字:)。</p><p>额外的东西：</p><blockquote><p>我们为了保留元函数，增加了<code>itself</code>方法，该方法就是不增加额外功能的装饰器（<strong>保持原函数逻辑调用</strong>）。<br>有一个<code>__get__</code>方法，当实例化对象调用方法时，实质就会先调用该函数<strong>获取绑定在实例化对象上的方法</strong>。类的装饰器装饰其他类中的函数时，需要补上该方法，否则类中的函数不能使用装饰器。此处我们利用该方法，<strong>重新构造绑定逻辑。</strong></p></blockquote><p>输出结果和上文中的输出一致，这里就不重复展示结果了。<br>到这里，我们的所有重试方法就讲解完毕啦，相信你一定也收获满满。<br>老规矩，我们再总结一下本文所讲内容：</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p><strong>1. <code>for...in...</code>循环实现<code>requests</code>请求重试<br>2. 利用<code>adapter</code> 实现<code>requests</code>请求重试<br>3. 装饰器函数原理<br>4. 利用函数装饰器实现<code>requests</code>请求重试到万能重试装饰器<br>5. 类装饰器简单原理<br>6. 类装饰器实战<code>requests</code>请求重试</strong></p><p><a href="https://github.com/Dustyposa/goSpider/tree/master/python_advance/requests%E8%AF%B7%E6%B1%82%E9%87%8D%E8%AF%95" target="_blank" rel="noopener">完整代码地址</a></p>]]></content>
    
    
    <categories>
      
      <category>advance</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>decorator</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>使用python客户端和服务器的功能测试实例</title>
    <link href="/2020/04/07/%E4%BD%BF%E7%94%A8python%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%8A%9F%E8%83%BD%E6%B5%8B%E8%AF%95%E5%AE%9E%E4%BE%8B/"/>
    <url>/2020/04/07/%E4%BD%BF%E7%94%A8python%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%8A%9F%E8%83%BD%E6%B5%8B%E8%AF%95%E5%AE%9E%E4%BE%8B/</url>
    
    <content type="html"><![CDATA[<blockquote><h3 id="编写功能测试的目的"><a href="#编写功能测试的目的" class="headerlink" title="编写功能测试的目的"></a>编写功能测试的目的</h3><p>验证应用的行为和期望一致的测试<br>确认异常修复的测试（增加测试覆盖率）<br>想想一个场景，因为接口需要增加一些功能，而更改了一些代码。<br>那么修改的代码会不会对之前的功能有影响呢？测试就来了。<br><strong>并且，良好的编写测试习惯，持续地写测试写文档写代码是必备的。更改代码也更加方便（重构），只用相同的测试代码即可。而且还能提升代码的可读性，测试代码也是功能的描述。</strong></p></blockquote><h4 id="测试的分类"><a href="#测试的分类" class="headerlink" title="测试的分类"></a>测试的分类</h4><ol><li>单元测试（unit test）# 主要测函数</li><li>功能测试（function test）# 主要测某些代码段完整的功能</li><li>集成测试（integration test）  # 主要在线上环境测试</li><li>负载/压力测试 （load test）  # 大家比较熟悉</li><li>端到端测试 （end-to-end test） # 完整的测试产品</li></ol><p>本文主要讲解功能测试实例的编写。</p><h2 id="在python中编写功能测试代码"><a href="#在python中编写功能测试代码" class="headerlink" title="在python中编写功能测试代码"></a>在python中编写功能测试代码</h2><p>主要分为两部分，客户端测试和服务器端测试。<br>目的都是为了检测自己写的代码是否实现了自己想要的功能。</p><blockquote><p>功能测试组要注意的点：<br><strong>功能测试都不占用网络服务资源，请求都直接模拟网络资源</strong></p></blockquote><p><strong>客户端测试可以用在哪里呢？</strong></p><blockquote><p>带有请求的地方都可以:<br><strong>爬虫</strong><br><strong>调用第三方的接口</strong>（OSS， 数据库， AI服务等）</p></blockquote><p>PS: 为了提升代码质量，所有代码都会使用静态注释,你的<code>python version</code> 需要 &gt;= 3.5<br><strong>如何实现网络资源请求的模拟呢？这时候，我们的 mock 就要出场了。</strong></p><h3 id="1-客户端测试-request-mock"><a href="#1-客户端测试-request-mock" class="headerlink" title="1. 客户端测试 request_mock"></a>1. 客户端测试 request_mock</h3><p>首先，我们编写一个简单的客户端，当作我们用来测试的客户端 <code>client.py</code>，代码如下:</p><pre><code class="python">import typingfrom urllib import parseimport requestsMyResponse = typing.Dict[str, typing.List[str]]class MySpider:    &quot;&quot;&quot;拼接返回的id&quot;&quot;&quot;    def __init__(self, url=&quot;http://example.com&quot;) -&gt; None:        self.url: str = url        self.return_base_url: str = &quot;http://shop.com/id/&quot;    def get_data(self):        try:            response: requests.Response = requests.get(self.url)        except requests.exceptions.ConnectionError:            # 链接超时            return self._handle_data()        else:            response.raise_for_status()  # 检查请求状态值200        data = response.json()        return self._handle_data(data)    def _handle_data(self, data=None) -&gt; MyResponse:        &quot;&quot;&quot;处理请求的数据&quot;&quot;&quot;        if data:            return_data: typing.List[str] = []            all_id = data.get(&quot;all_id&quot;, [])            for goods_id in all_id:                return_data.append(parse.urljoin(self.return_base_url, goods_id))            return {&quot;data&quot;: return_data}        return {&quot;data&quot;: []}</code></pre><p>客户端简单的实现了一个请求网站并处理返回数据的逻辑.<br>那么，开始测试我们的客户端吧！<br>记住：<strong>这是功能测试，与网络资源访问无关，我们只需要测试功能逻辑！其余第三方对象用模拟对象即可！</strong><br>一般的对象，<code>unittest</code> 自带的 <code>mock</code> 对象就能满足。那么如何网络模拟对象的实现呢？这时候，我们的 <code>requests_mock</code> 就要登场了。<br>它会实现对请求的拦截，以此达到我们想要的效果。<br>测试代码 <code>test_client.py</code> 如下:</p><pre><code class="python">import unittestfrom unittest import mockimport requestsimport requests_mockfrom client import MySpider, MyResponseclass TestMySpider(unittest.TestCase):    def setUp(self) -&gt; None:        self.spider: MySpider = MySpider()  # 初始化对象，首先运行这里，再运行 test_xxxxxx    def test_handle_data(self) -&gt; None:        &quot;&quot;&quot;测试处理代码的逻辑&quot;&quot;&quot;        return_data: MyResponse = {&quot;data&quot;: []}  # 返回的基础数据        self.assertEqual(self.spider._handle_data(), return_data)  # none值返回，测试是否相等        return_data.update(data=[            &quot;http://shop.com/id/23&quot;,            &quot;http://shop.com/id/32&quot;        ])  # 生成正常值        # 正常值返回, 测试是否相等        self.assertEqual(self.spider._handle_data({&quot;all_id&quot;: [&quot;23&quot;, &quot;32&quot;]}), return_data)    @requests_mock.mock()    def test_get_data(self, mocker) -&gt; None:        &quot;&quot;&quot;测试正常逻辑&quot;&quot;&quot;        shop_data: MyResponse = {&quot;all_id&quot;: [&quot;12&quot;, &quot;123&quot;, &quot;1234&quot;]}        mocker.get(requests_mock.ANY, json=shop_data)  # 截胡 requests.get        spider_data: MyResponse = self.spider.get_data()  # 获取正常返回值        response_data: MyResponse = {&#39;data&#39;: [&#39;http://shop.com/id/12&#39;, &#39;http://shop.com/id/123&#39;, &#39;http://shop.com/id/1234&#39;]}        self.assertEqual(spider_data, response_data)  # 比较是否相等        shop_data: MyResponse = {}        mocker.get(requests_mock.ANY, json=shop_data)  # 截胡 requests.get        spider_data: MyResponse = self.spider.get_data()  # 获取空返回值        response_data: MyResponse = {&#39;data&#39;: []}        self.assertEqual(spider_data, response_data)  # 比较是否相等    @mock.patch.object(requests, &quot;get&quot;, side_effect=requests.ConnectionError(&quot;No network&quot;))    def test_net_error(self, mocked) -&gt; None:        return_data: MyResponse = {&quot;data&quot;: []}        spider_data: MyResponse = self.spider.get_data()  # 获取网络错误的返回值        self.assertEqual(spider_data, return_data)if __name__ == &#39;__main__&#39;:    unittest.main()</code></pre><p>我们运行一下就能看到测试的结果。<br>整个测试代码整体也比较简单，<br><code>requests_mock</code> 作为一个装饰器，<code>reqeusts</code>进行了拦截。之后就直接进行了设定值的返回。<br>需要注意的几个函数:</p><ol><li><code>unittest</code> 为 python 标准库，可以直接导入并使用，不过后续的文章我们会升级成 <code>pytest</code> , 可定制性更强。</li><li>安装 <code>requests_mock</code> , 也比较简单，直接 <code>pip install reqeusts_mock</code> 即可，后续我们会进行 <code>requests_mock</code> 的源码分析。并且，<code>reqeusts_mock</code> 的源码对于学习静态注释也是极好的。</li><li><code>@unittest.mock.patch.object</code> 是进行对象层面的异常状态抛出，当 <code>requests</code> 对象调用 <code>get</code> 方法时，便抛出错误。<h3 id="2-测试服务器端"><a href="#2-测试服务器端" class="headerlink" title="2. 测试服务器端"></a>2. 测试服务器端</h3>其实客户端的测试比服务器端难一些。<blockquote><p>因为服务器端的测试，框架已经帮你封装好了！<br><strong>服务端功能测试用在哪？当然是测自己写的接口啦！</strong></p></blockquote></li></ol><p>测试步骤类似，编写服务器，我们用 <code>flask</code> 和 <code>starlette</code> 进行举例，分别代表<code>python</code> 同步web框架和异步web框架。</p><h4 id="flask"><a href="#flask" class="headerlink" title="flask"></a>flask</h4><p>我们编写一个简单的<code>flask_server.py</code>, 代码如下:</p><pre><code class="python">from flask import Flask, jsonifyapp = Flask(__name__)@app.route(&#39;/api&#39;, methods=[&quot;GET&quot;])def msg_api():    &quot;&quot;&quot;常规返回&quot;&quot;&quot;    return jsonify({&#39;Hello&#39;: &#39;World!&#39;})@app.route(&#39;/goods/&lt;int:goods_id&gt;&#39;, methods=[&quot;GET&quot;])def query_goods(goods_id):    &quot;&quot;&quot;带id的路由&quot;&quot;&quot;    return jsonify({&quot;name&quot;: &quot;cake&quot;, &quot;id&quot;: goods_id})@app.errorhandler(404)def error_404_handing(error):    &quot;&quot;&quot;404页面&quot;&quot;&quot;    return jsonify({&quot;msg&quot;: &quot;no route&quot;, &quot;err&quot;: str(error)}), 404if __name__ == &#39;__main__&#39;:    app.run()</code></pre><p>代表也比较简单，有3个路由</p><ol><li>常规返回的路由 <code>/api</code></li><li>路由带id <code>/goods/123123</code></li><li>404 页面<br>测试代码<code>test_flask_client.py</code> 代码如下:<pre><code class="python">import jsonimport typingimport unittest</code></pre></li></ol><p>from flask_basic import app as my_app</p><p>class TestApp(unittest.TestCase):</p><pre><code>def setUp(self) -&gt; None:    self.client = my_app.test_client()  # 初始化客户端，app 自带的测试客户端def test_msg_api(self) -&gt; None:    response = self.client.get(&quot;/api&quot;)  # 访问路由    data: typing.Dict[str, typing.Any] = json.loads(response.data.decode(&quot;u8&quot;))  # 响应数据格式化    self.assertEqual(data[&quot;Hello&quot;], &quot;World!&quot;)  # 判断结果def test_goods_api(self) -&gt; None:    response = self.client.get(&quot;/goods/123&quot;)  # 访问路由    data: typing.Dict[str, typing.Any] = json.loads(response.data.decode(&quot;u8&quot;))  # 响应数据格式化    self.assertEqual(data[&quot;name&quot;], &quot;cake&quot;)  # 判断结果    self.assertEqual(data[&quot;id&quot;], 123)  # 判断结果def test_404_page(self) -&gt; None:    response = self.client.get(&quot;/idontknow&quot;)  # 访问路由    self.assertEqual(response.status, &quot;404 NOT FOUND&quot;)  # 404 状态监测    data: typing.Dict[str, typing.Any] = json.loads(response.data.decode(&quot;u8&quot;))  # 响应数据格式化    self.assertEqual(data[&quot;msg&quot;], &quot;no route&quot;)  # 返回数据监测</code></pre><p>if <strong>name</strong> == ‘<strong>main</strong>‘:<br>    unittest.main()</p><pre><code>整个代码也就很简单清晰了，因为`flask` 自带的`app`就包含了测试客户端，只需要请求检查响应即可，整个过程可以一气呵成！#### starletee我们编写 `starletee` 的服务器文件 `starletee_server.py`,代码如下:```pythonfrom starlette.applications import Starlettefrom starlette.responses import JSONResponseapp = Starlette()@app.route(&#39;/api&#39;, methods=[&quot;GET&quot;])async def hello_api(request) -&gt; JSONResponse:    &quot;&quot;&quot;常规返回&quot;&quot;&quot;    return JSONResponse({&#39;Hello&#39;: &#39;World!&#39;})@app.route(&#39;/goods/{goods_id:int}&#39;, methods=[&quot;GET&quot;])async def query_goods(request) -&gt; JSONResponse:    &quot;&quot;&quot;带id的路由&quot;&quot;&quot;    return JSONResponse({&quot;name&quot;: &quot;cake&quot;, &quot;id&quot;: request.path_params.get(&quot;goods_id&quot;)})@app.exception_handler(404)async def not_found(request, exc) -&gt; JSONResponse:    &quot;&quot;&quot;404处理&quot;&quot;&quot;    return JSONResponse(content={&quot;msg&quot;: &quot;no route&quot;}, status_code=exc.status_code)</code></pre><p><code>starletee</code>整体代码和<code>flask</code>很相似，所以遇到新的框架不要畏惧，大体其实是差不多的，只有一些小细节不一样，例如：</p><ol><li><code>flask</code> 的 <code>request</code>对象是全局的，而 <code>starletee</code>的 <code>request</code>对象和<code>django</code>的 <code>request</code>对象相似，都是在分发在路由中。</li><li>路由中的变量获取方式不同，一个存在参数中，一个存在请求对象中。</li><li>错误状态码处理方式返回数据格式不同。</li></ol><p>下面为测试<code>starletee</code>的代码<code>test_starletee_api.py</code>:</p><pre><code class="python">import typingimport unittestfrom starlette.testclient import TestClientfrom starletee_server import app as my_appclass TestApp(unittest.TestCase):    def setUp(self) -&gt; None:        self.client = TestClient(my_app)  # 初始化客户端，app 自带的测试客户端    def test_msg_api(self) -&gt; None:        response = self.client.get(&quot;/api&quot;)  # 访问路由        data: typing.Dict[str, typing.Any] = response.json()  # 响应数据格式化        self.assertEqual(data[&quot;Hello&quot;], &quot;World!&quot;)  # 判断结果    def test_goods_api(self) -&gt; None:        response = self.client.get(&quot;/goods/123&quot;)  # 访问路由        data: typing.Dict[str, typing.Any] = response.json()  # 响应数据格式化        self.assertEqual(data[&quot;name&quot;], &quot;cake&quot;)  # 判断结果        self.assertEqual(data[&quot;id&quot;], 123)  # 判断结果    def test_404_page(self) -&gt; None:        response = self.client.get(&quot;/idontknow&quot;)  # 访问路由        self.assertEqual(response.status_code, 404)  # 404 状态监测        data: typing.Dict[str, typing.Any] = response.json()  # 响应数据格式化        self.assertEqual(data[&quot;msg&quot;], &quot;no route&quot;)  # 返回数据监测if __name__ == &#39;__main__&#39;:    unittest.main()</code></pre><p>除了响应数据的解析方式不同外，其他都一模一样。<br>对了，有一点不一样，就是客户端的初始化不一样。<code>TestClient(my_app)</code><br>当然，这只是示例，用的自带的<code>TestClien</code>,并且明显比<code>flask</code>自带的好用。之后的文章我们会讲解 <code>WebTest</code>这个专门设计来作为测试客户端（<code>flask</code>中有 <code>flask_webtest</code>）</p><h3 id="3-总结"><a href="#3-总结" class="headerlink" title="3.总结"></a>3.总结</h3><p>服务器的功能测试其实很类似，我们可以看到，测试代码几乎不用更改就能使用，那我们思考一下，这样有什么好处呢？<br>dangdangdang，答案就是：<br><strong>在写测试demo时，可以很方便的更换框架来继续进行测试，而不用更改测试代码，所以我们可以选择最适合当前业务的框架来使用！（特别对于微服务来说，针对当前业务，选择最合适的后端。）</strong></p><p><strong>python客户端和服务器的功能测试流程大题如上文所述，我们需要记住以下几个要点：</strong></p><ol><li>功能测试（及单元测试）不依赖网络资源，IO等，一般使用<code>MOCK</code>对象来模拟返回数据。</li><li>客户端请求我们可以使用<code>requests_mock</code>来模拟，测试自己客户端处理响应的逻辑。</li><li>服务器端基本上所有框架都自带有 <code>test_client</code> 作为服务器测试客户端（不同框架名字可能不一样，具体参考文档）</li></ol><p><a href="https://github.com/Dustyposa/goSpider/tree/master/python_advance/%E4%BD%BF%E7%94%A8python%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%8A%9F%E8%83%BD%E6%B5%8B%E8%AF%95%E5%AE%9E%E4%BE%8B" target="_blank" rel="noopener">完整代码地址</a></p>]]></content>
    
    
    <categories>
      
      <category>advance</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>tests</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python requests 代理和重定向信息</title>
    <link href="/2020/04/07/python_requests_%E4%BB%A3%E7%90%86%E5%92%8C%E9%87%8D%E5%AE%9A%E5%90%91%E4%BF%A1%E6%81%AF/"/>
    <url>/2020/04/07/python_requests_%E4%BB%A3%E7%90%86%E5%92%8C%E9%87%8D%E5%AE%9A%E5%90%91%E4%BF%A1%E6%81%AF/</url>
    
    <content type="html"><![CDATA[<p>在使用 <code>requests</code>的途中，我们经常会有使用代理的需求。那么如何使用代理呢？<br>使用起来是和简单的，话不多说，直接上代码：</p><h4 id="1-http-代理"><a href="#1-http-代理" class="headerlink" title="1. http 代理"></a>1. http 代理</h4><p>代理只需要一个字典，一般格式如下：<br><code>{&quot;http&quot;: &quot;http://user:pass@10.10.1.10:3128/&quot;}</code><br>需要注意的是，该方式值是针对<code>HTTP Basic Auth</code><br>我们测试网址使用<code>http://httpbin.org/get</code><br>完整代码如下：</p><pre><code class="python">import requestsfrom pprint import pprinturl = &#39;http://httpbin.org/get&#39;proxies = {&quot;http&quot;: &quot;http://111.111.90.238:8888&quot;, &quot;https&quot;: &quot;http://111.111.90.238:8888&quot;}response = requests.get(url, proxies=proxies).json()pprint(response)</code></pre><p>输入如下：</p><pre><code>{&#39;args&#39;: {}, &#39;headers&#39;: {&#39;Accept&#39;: &#39;*/*&#39;,             &#39;Accept-Encoding&#39;: &#39;gzip, deflate&#39;,             &#39;Host&#39;: &#39;httpbin.org&#39;,             &#39;User-Agent&#39;: &#39;python-requests/2.22.0&#39;}, &#39;origin&#39;: &#39;111.111.90.238, 111.111.90.238&#39;, &#39;url&#39;: &#39;https://httpbin.org/get&#39;}</code></pre><p> 可以看到<code>origin</code>字段变成你使用的<strong>代理的ip</strong>，代理就成功啦。<br> 是不是很简单？不过需要注意的是，我们使用的代理没<strong>有认证的用户名和密码，就没有添加</strong>，如果有的话，需要按照格式填写哦。<br><strong>还有一点：</strong> <code>http 和 https</code>设置了两个，两种请求方式可以用不同的代理。</p><h4 id="2-socks-代理"><a href="#2-socks-代理" class="headerlink" title="2. socks 代理"></a>2. socks 代理</h4><p>和<code>http</code>代理类似，代码也很简单，基本格式如下：<br><code>&#39;http&#39;: &#39;socks5://user:pass@host:port&#39;</code>,也就是<code>scheme</code>不一样。<br>代码如下：</p><pre><code class="python">import requestsfrom pprint import pprinturl = &#39;http://httpbin.org/get&#39;proxies = {&quot;http&quot;: &quot;socks5://127.0.0.1:1080&quot;, &quot;https&quot;: &quot;socks5://127.0.0.1:1080&quot;}response = requests.get(url, proxies=proxies).json()pprint(response)</code></pre><p>一般我们的<code>socks</code>代理在本地，所以用的<code>127.0.0.1</code><br>代码很简单，我们就不重述了。<br><strong>接下来，我们看看如何实现重定向请求的获取：</strong></p><h4 id="3-重定向历史请求获取（history-属性）"><a href="#3-重定向历史请求获取（history-属性）" class="headerlink" title="3. 重定向历史请求获取（history 属性）"></a>3. 重定向历史请求获取（history 属性）</h4><p>要获取重定向请求~我们得先找到有重定向的网址。<br>我们用<code>url = &#39;https://dwz.cn/Qk6kP0DS&#39;</code>（这是定制的短链接，会跳转到百度）<br>好了,话不多说，上代码：</p><pre><code class="python">import requestsheaders = {    &#39;user-agent&#39;: &#39;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36&#39;,}url = &#39;https://dwz.cn/Qk6kP0DS&#39;response = requests.get(url, headers=headers)redirect_responses = response.historyfor resp in redirect_responses:    print(f&#39;redirect url: {resp.url}&#39;)</code></pre><p>输出如下：</p><pre><code>redirect url: https://dwz.cn/Qk6kP0DS</code></pre><p>今天的<code>TIPS</code>就到这里~希望你能有所收获</p>]]></content>
    
    
    <categories>
      
      <category>tips</category>
      
      <category>advance</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>requests</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python向文本中插入文字</title>
    <link href="/2020/04/07/python%E5%90%91%E6%96%87%E6%9C%AC%E4%B8%AD%E6%8F%92%E5%85%A5%E6%96%87%E5%AD%97/"/>
    <url>/2020/04/07/python%E5%90%91%E6%96%87%E6%9C%AC%E4%B8%AD%E6%8F%92%E5%85%A5%E6%96%87%E5%AD%97/</url>
    
    <content type="html"><![CDATA[<h2 id="使用python向文本中插入文字"><a href="#使用python向文本中插入文字" class="headerlink" title="使用python向文本中插入文字"></a>使用python向文本中插入文字</h2><blockquote><p>本文只记录方法，希望对你能有所帮助！</p></blockquote><h3 id="第一种-原生："><a href="#第一种-原生：" class="headerlink" title="第一种-原生："></a>第一种-原生：</h3><h4 id="1-首行插入"><a href="#1-首行插入" class="headerlink" title="1. 首行插入"></a>1. 首行插入</h4><p>主要利用文件读取和写入。</p><pre><code class="python">def write_data_to_file(file: str, data: str) -&gt; None:    &quot;&quot;&quot;    读取文件，并将数据插入第一行    :param file: 读取文件路径    :param data: 插入数据    :return:    &quot;&quot;&quot;    with open(file, &quot;r+&quot;, encoding=&quot;u8&quot;) as fp:        tmp_data = fp.read()  # 读取所有文件, 文件太大时不用使用此方法        fp.seek(0)  # 移动游标        fp.write(data + &quot;\n&quot; + tmp_data)</code></pre><p>行数很少，原理也很简单。<br><strong>如果我们要判断数据是否存在，不存在就插入，该怎么写？</strong><br>简单更改一下即可：</p><h4 id="2-数据不存在再插入"><a href="#2-数据不存在再插入" class="headerlink" title="2. 数据不存在再插入"></a>2. 数据不存在再插入</h4><pre><code class="python">def write_data_to_file(file: str, data: str) -&gt; None:    &quot;&quot;&quot;    读取文件，并判断每行数据，如果和要插入的数据存在，就不插入,不存在，则插入第一行。    :param file: 读取文件路径    :param data: 插入数据    :return:    &quot;&quot;&quot;    with open(file, &quot;r+&quot;, encoding=&quot;u8&quot;) as fp:        # 遍历每行数据进行判断        for d in fp.readlines():            if data in d:                break  # 存在就跳出        else:            fp.seek(0)            tmp_data = fp.read()  # 读取所有文件, 文件太大时不用使用此方法            fp.seek(0)  # 移动游标            fp.write(data + &quot;\n&quot; + tmp_data)</code></pre><p>利用一个读取文件行做了一个判断，也比较简单。<br><strong>升级一下，在某一行进行插入。</strong></p><h4 id="3-任意行插入"><a href="#3-任意行插入" class="headerlink" title="3. 任意行插入"></a>3. 任意行插入</h4><pre><code class="python">def write_data_to_file(file: str, data: str, row: int = 1) -&gt; None:    &quot;&quot;&quot;    读取文件，在某一行插入。    :param file: 读取文件路径    :param data: 插入数据    :param row: 插入行    :return:    &quot;&quot;&quot;    front_data = &quot;&quot;  # 前半部分存储    after_data = &quot;&quot;  # 后半部分存储    with open(file, &quot;r+&quot;, encoding=&quot;u8&quot;) as fp:        # 遍历每行数据进行判断行数,利用 enumerate 辅助计数        for i, d in enumerate(fp.readlines(), start=1):            if i &gt;= row:                after_data += d            else:                front_data += d        fp.seek(0)  # 回到初始点        fp.write(front_data)        fp.write(data + &quot;\n&quot;)        fp.write(after_data)</code></pre><p>同样代码也比较简单，利用前后分割，做的拼接。<br>这就是原生办法。<br>接下来我们介绍一个内置库<code>fileinput</code></p><h3 id="第二种-fileinput实现行数据插入"><a href="#第二种-fileinput实现行数据插入" class="headerlink" title="第二种-fileinput实现行数据插入"></a>第二种-<code>fileinput</code>实现行数据插入</h3><p>使用内置的<code>fileinput</code>实现，代码更简单:</p><h4 id="1-第一行插入"><a href="#1-第一行插入" class="headerlink" title="1. 第一行插入"></a>1. 第一行插入</h4><pre><code class="python">def replace_file_data(file_path: str, data: str) -&gt; None:    &quot;&quot;&quot;    在第一行插入数据    :param file_path: file 路径    :param data: 插入的数据    :return:    &quot;&quot;&quot;    with fileinput.input(files=file_path, inplace=True) as fp:        for d in fp:            if fp.filelineno() == 1:                # 如果行数为 1 则进行插入                print(data)            print(d, end=&quot;&quot;)</code></pre><p>需要注意<code>inplace</code>必须为<code>true</code>，他会捕捉当前的<code>stdout</code>,然后加入文件，我们为了简单，就直接使用<code>print</code>，所有也可以做<strong>删除操作</strong>，当行数等于某行时，就不<code>print</code>即可。<br>我们再介绍一个小方法，数据读取，一次性读取多个文件。代码如下:</p><h4 id="2-批量读取文件"><a href="#2-批量读取文件" class="headerlink" title="2. 批量读取文件"></a>2. 批量读取文件</h4><pre><code class="python">def read_all_text(files: Iterable) -&gt; None:    &quot;&quot;&quot;    读取所有文件数据    :param files: 数据组    :return:    &quot;&quot;&quot;    with fileinput.input(files=files) as f:        for line in f:            print(line, end=&quot;&quot;)</code></pre><p>只需要调用函数即可。</p><p><code>read_all_text([&quot;a.txt&quot;, &quot;b.txt&quot;])</code></p><p>好了，今天的小技巧就到这里，希望你能有所收获。</p><blockquote><p>相关文件及代码:<a href="https://github.com/Dustyposa/goSpider/tree/master/python_advance/python-tips/%E5%90%91%E6%96%87%E6%9C%AC%E4%B8%AD%E6%8F%92%E5%85%A5%E6%96%87%E5%AD%97" target="_blank" rel="noopener">点击这里</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>tips</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>file</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>奇妙的对象模型及存储数据模型的技巧</title>
    <link href="/2020/04/07/data-class/"/>
    <url>/2020/04/07/data-class/</url>
    
    <content type="html"><![CDATA[<h3 id="方便的数据结构之"><a href="#方便的数据结构之" class="headerlink" title="方便的数据结构之"></a>方便的数据结构之</h3><h2 id="namedtuple-与-dataclass-以及-类结构进阶的基本使用"><a href="#namedtuple-与-dataclass-以及-类结构进阶的基本使用" class="headerlink" title="namedtuple 与 dataclass 以及 类结构进阶的基本使用"></a>namedtuple 与 dataclass 以及 类结构进阶的基本使用</h2><h4 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h4><ul><li><a href="#namedtuple">namedtuple</a></li><li><a href="#dataclass">dataclass</a></li><li><a href="#Python对象模型">Python对象模型</a></li><li><a href="#一些额外的补充">补充</a></li></ul><p>其中，<code>nametuple</code> 和 <code>dataclasses</code> 个人觉得比较相似，这两个都是用来保存数据的，我们一起来看看区别吧。</p><p>在python内置模块 <code>collections</code> 中，有一个类为 <code>nametuple</code> 看名字我们可以大概猜出意思，有名字的元组。那么，这个 namedtuple 到底能做什么呢？<br>我们通过代码来看一下,</p><h2 id="namedtuple"><a href="#namedtuple" class="headerlink" title="namedtuple"></a>namedtuple</h2><pre><code class="python">from collections import namedtuple  # 导入模块</code></pre><pre><code class="python">food = namedtuple(&quot;Foods&quot;, [&quot;fruit&quot;, &quot;price&quot;])  # 初始化一个对象，但是并不能直接使用。我们需要向其中加入数据。food</code></pre><pre><code>__main__.Foods</code></pre><pre><code class="python">data_1 = food(fruit=&quot;apple&quot;, price=123)data_1</code></pre><pre><code>Foods(fruit=&#39;apple&#39;, price=123)</code></pre><pre><code class="python"># 访问数据print(data_1.fruit)print(data_1.price)</code></pre><pre><code>apple123</code></pre><pre><code class="python"># 尝试更改数据data_1.fruit = &quot;banana&quot;</code></pre><pre><code>---------------------------------------------------------------------------AttributeError                            Traceback (most recent call last)&lt;ipython-input-5-acfec753951a&gt; in &lt;module&gt;      1 # 尝试更改数据----&gt; 2 data_1.fruit = &quot;banana&quot;AttributeError: can&#39;t set attribute</code></pre><h4 id="基本操作就是如上，可以看到我们通过-namedtuple-可以获得一个对象，并且可以通过属性访问"><a href="#基本操作就是如上，可以看到我们通过-namedtuple-可以获得一个对象，并且可以通过属性访问" class="headerlink" title="基本操作就是如上，可以看到我们通过 namedtuple 可以获得一个对象，并且可以通过属性访问."></a>基本操作就是如上，可以看到我们通过 <code>namedtuple</code> 可以获得一个对象，并且可以通过属性访问.</h4><h4 id="并且与元组-tuple-相同，不能更改属性，也就是对象一旦创立，遍不能更改，即不可变性依然保持着。"><a href="#并且与元组-tuple-相同，不能更改属性，也就是对象一旦创立，遍不能更改，即不可变性依然保持着。" class="headerlink" title="并且与元组 tuple 相同，不能更改属性，也就是对象一旦创立，遍不能更改，即不可变性依然保持着。"></a>并且与元组 <code>tuple</code> 相同，不能更改属性，也就是对象一旦创立，遍不能更改，即不可变性依然保持着。</h4><blockquote><p>那么问题来了，这玩意创建步骤也比较麻烦。到底有什么用呢？ </p></blockquote><h4 id="提高代码可读性！！！"><a href="#提高代码可读性！！！" class="headerlink" title="提高代码可读性！！！"></a><strong>提高代码可读性！！！</strong></h4><p>你没看错，就是提高代码可读性。<br>举个栗子：<br>你需要用一个数据结构保存不会变的东西，我们假设这个东西是水果。这个东西需要保存两个值，假设值分别为: apple 13。<br>我们看看元组怎么做：</p><pre><code class="python">data = (&quot;apple&quot;, 13)data</code></pre><pre><code>(&#39;apple&#39;, 13)</code></pre><p>emmm….对，很简单！一步就初始化出来了，但是我们要访问怎么办呢？这时候就只能用索引或者遍历了，如下：</p><pre><code class="python">print(data[0])print(data[1])for d in data:    print(d)</code></pre><pre><code>apple13apple13</code></pre><p><strong>这时候就有问题了，如果这是你自己写的代码还好，知道数据在哪个位置(但是数据多了，有时也会忘记)，但是如果是别人来看的话，可能就比较懵逼了，需要不断的查看代码段。</strong><br>别怕，我们有 <code>namedtuple</code> ，来，我们看看 <code>namedtuple</code> 有什么特效。<br>数据，两个值，那么 这两个值肯定有含义的对吧， 对吧？（不要抬杠哦！）， 我们假设含义是 水果种类 和 价格<br>那么我们就可以取两个名字，为了方便认识，我们就叫 <code>fruit</code> 和 <code>name</code>吧。（不要告诉我你要用 a，b 命名。。如果打算这样命名，还是直接用元组吧。）  </p><pre><code class="python"># 首先呢，我们创建一个不可变的容器，这容器就叫 Fruit 吧，这个 Fruit 就保存两个值，取名如上super_fruit = namedtuple(&quot;Fruit&quot;, [&quot;name&quot;, &quot;price&quot;])  # 创建容器# 保存数据 gogogodata = super_fruit(name=&quot;apple&quot;, price=13)# 一个不够，再来一个data2 = super_fruit(name=&quot;big apple&quot;, price=26)# 继续访问数据print(data.name, data.price)print(data2.name, data2.price)</code></pre><pre><code>apple 13big apple 26</code></pre><h4 id="划重点-namedtuple"><a href="#划重点-namedtuple" class="headerlink" title="划重点 (namedtuple)"></a>划重点 (namedtuple)</h4><p>通过 namedtuple 我们也能得到不可变的数据结构，并且可以通过属性来进行访问，大大提高了代码的可读性，并且更加 pythonic 。<br>如有元组的情况，如果结构比较复杂的话，强烈推荐使用哦！<br><a href="#namedtuple_advance">namedtuple 进阶</a></p><h3 id="这个特殊的东西我们就先打住，我们换一个新东西-3-6-中的新模块-dataclasses-中的-dataclass-没错，这个也是用来保存数据的，并且可以数据可变-。"><a href="#这个特殊的东西我们就先打住，我们换一个新东西-3-6-中的新模块-dataclasses-中的-dataclass-没错，这个也是用来保存数据的，并且可以数据可变-。" class="headerlink" title="这个特殊的东西我们就先打住，我们换一个新东西 3.6 中的新模块 dataclasses 中的 dataclass(没错，这个也是用来保存数据的，并且可以数据可变)。"></a>这个特殊的东西我们就先打住，我们换一个新东西 3.6 中的新模块 dataclasses 中的 dataclass(没错，这个也是用来保存数据的，并且可以数据可变)。</h3><p><code>dataclass</code> 用来干什么， 老规矩，我们先设想一个场景-用类来保存属性，通过属性来访问值，我们用正常的代码来看看。</p><h3 id="dataclass"><a href="#dataclass" class="headerlink" title="dataclass"></a>dataclass</h3><pre><code class="python"># 假设需要一个对象类，代表测试环境数据库的连接，我们需要给一堆属性用于配置, 并添加默认参数class TestEnv:    def __init__(self, port=3306, host=&quot;localhost&quot;, db=&quot;test_database&quot;, tb_name=&quot;table_name&quot;):        self.port = port        self.host = host        self.db = db        self.tb_name = tb_name&quot;&quot;&quot;当然，你也可以这样写：class TestEnv:    def __init__(self):        self.port = 3306        self.host = &quot;localhost&quot;        self.db = &quot;test_database&quot;        self.tb_name = &quot;table_name&quot;&quot;&quot;&quot;# 我们来点 pythonic 的写法，加上类型注释class PythonicTestEnv:    def __init__(self, port: int=3306, host: str=&quot;localhost&quot;, db: str=&quot;test_database&quot;, tb_name: str=&quot;table_name&quot;):        self.port = port        self.host = host        self.db = db        self.tb_name = tb_name</code></pre><p>我们实例化对象后查看一下属性</p><pre><code class="python">env = TestEnv()print(env.port)print(env.tb_name)env = PythonicTestEnv()print(env.port)print(env.tb_name)</code></pre><pre><code>3306table_name3306table_name</code></pre><p>当然，属性与 <code>namedtuple</code> 不同，是可以改变的。</p><pre><code class="python">env.port = 3308print(env.port)env</code></pre><pre><code>3308&gt;&gt;&gt; &lt;__main__.PythonicTestEnv at 0x104092be0&gt;</code></pre><p>所有要保证数据的不可变性的话，还是推荐使用 <code>namedtuple</code>, 但是对于这种纯数据的对象这样写比较繁琐，所以，何不试试新方法～ go！</p><pre><code class="python">from dataclasses import dataclass</code></pre><pre><code class="python">@dataclassclass DCTestEnv:    port: int=3306    host: str=&quot;localhost&quot;    db: str=&quot;test_database&quot;    tb_name: str=&quot;table_name&quot;</code></pre><pre><code class="python">env = DCTestEnv()print(env.port)print(env.tb_name)env</code></pre><pre><code>3306table_name&gt;&gt;&gt;  DCTestEnv(port=3306, host=&#39;localhost&#39;, db=&#39;test_database&#39;, tb_name=&#39;table_name&#39;)</code></pre><p><strong>看，是不是一气呵成，简单方便。</strong><br>细心的同学可能会发现，当对象在交互模式出现时，<strong>输出的结果不一样！</strong><br>没错 <code>dataclass</code> 还帮我们把 <code>__repr__</code> 也重写好了(<strong>划重点</strong>)！是不是很方便！没错 dataclass 最重要的就是 省代码！省代码！省代码！ 重要的事说三遍！方便快捷，选他没错！</p><blockquote><p>但其实不止这些方法，<code>dataclass</code> 还帮我们重写了 __eq__ 什么的，我们也可以重写这些方法。</p></blockquote><p><strong>好了，小技巧引入完了，我们来进入正题，面向对象知识的进阶！</strong></p><h2 id="Python对象模型"><a href="#Python对象模型" class="headerlink" title="Python对象模型"></a>Python对象模型</h2><p>这里我们通过两个对象来引入：</p><ul><li>卡牌</li><li>向量</li></ul><h4 id="卡牌对象-FrenchDeck"><a href="#卡牌对象-FrenchDeck" class="headerlink" title="卡牌对象(FrenchDeck)"></a>卡牌对象(FrenchDeck)</h4><p>这是一副扑克，记录了扑克的所有卡牌。</p><ul><li>有一个 _cards 属性保存了所有的卡牌，每一张卡牌只有花色和卡牌大小</li></ul><p>要是你会怎么设计这个对象呢？<br>我们来看看常规思路。</p><ul><li>因为卡牌比较多，所以这个 _cards 肯定是循环生成的。</li><li>因为每张卡牌固定有两个属性，所以我们用不可变对象来保存能更节省空间。</li><li>不可变对象，要保存花色和卡牌，我们可以用字符串或者元组来实现。</li><li>但是字符串肯定不太合适，花色和大小相关度不是很高，也不便于维护。</li><li>所以我们用元组来实现。  </li></ul><p>代码如下：</p><pre><code class="python">class FrenchDeck:    ranks = [str(i) for i in range(2, 11)] + list(&#39;JDKA&#39;)    suits = [&quot;黑桃&quot;, &quot;方块&quot;, &quot;梅花&quot;, &quot;红桃&quot;]    def __init__(self):        self._cards = [(suit, rank) for suit in self.suits                     for rank in self.ranks]</code></pre><p><strong>我们实例化对象看看效果</strong></p><pre><code class="python">puke_cards = FrenchDeck()puke_cards._cards</code></pre><pre><code>[(&#39;黑桃&#39;, &#39;2&#39;), (&#39;黑桃&#39;, &#39;3&#39;), (&#39;黑桃&#39;, &#39;4&#39;), (&#39;黑桃&#39;, &#39;5&#39;), (&#39;黑桃&#39;, &#39;6&#39;), (&#39;黑桃&#39;, &#39;7&#39;), (&#39;黑桃&#39;, &#39;8&#39;), (&#39;黑桃&#39;, &#39;9&#39;), (&#39;黑桃&#39;, &#39;10&#39;), (&#39;黑桃&#39;, &#39;J&#39;), (&#39;黑桃&#39;, &#39;D&#39;), (&#39;黑桃&#39;, &#39;K&#39;), (&#39;黑桃&#39;, &#39;A&#39;), (&#39;方块&#39;, &#39;2&#39;), (&#39;方块&#39;, &#39;3&#39;), (&#39;方块&#39;, &#39;4&#39;), (&#39;方块&#39;, &#39;5&#39;), (&#39;方块&#39;, &#39;6&#39;), (&#39;方块&#39;, &#39;7&#39;), (&#39;方块&#39;, &#39;8&#39;), (&#39;方块&#39;, &#39;9&#39;), (&#39;方块&#39;, &#39;10&#39;), (&#39;方块&#39;, &#39;J&#39;), (&#39;方块&#39;, &#39;D&#39;), (&#39;方块&#39;, &#39;K&#39;), (&#39;方块&#39;, &#39;A&#39;), (&#39;梅花&#39;, &#39;2&#39;), (&#39;梅花&#39;, &#39;3&#39;), (&#39;梅花&#39;, &#39;4&#39;), (&#39;梅花&#39;, &#39;5&#39;), (&#39;梅花&#39;, &#39;6&#39;), (&#39;梅花&#39;, &#39;7&#39;), (&#39;梅花&#39;, &#39;8&#39;), (&#39;梅花&#39;, &#39;9&#39;), (&#39;梅花&#39;, &#39;10&#39;), (&#39;梅花&#39;, &#39;J&#39;), (&#39;梅花&#39;, &#39;D&#39;), (&#39;梅花&#39;, &#39;K&#39;), (&#39;梅花&#39;, &#39;A&#39;), (&#39;红桃&#39;, &#39;2&#39;), (&#39;红桃&#39;, &#39;3&#39;), (&#39;红桃&#39;, &#39;4&#39;), (&#39;红桃&#39;, &#39;5&#39;), (&#39;红桃&#39;, &#39;6&#39;), (&#39;红桃&#39;, &#39;7&#39;), (&#39;红桃&#39;, &#39;8&#39;), (&#39;红桃&#39;, &#39;9&#39;), (&#39;红桃&#39;, &#39;10&#39;), (&#39;红桃&#39;, &#39;J&#39;), (&#39;红桃&#39;, &#39;D&#39;), (&#39;红桃&#39;, &#39;K&#39;), (&#39;红桃&#39;, &#39;A&#39;)]</code></pre><p>emmmm..有点感觉，我们试着随机访问几个元素看看</p><pre><code class="python">from random import randintfor i in range(3):    card = puke_cards._cards[randint(0, 53)]    print(card, card[0], card[1])</code></pre><pre><code>(&#39;梅花&#39;, &#39;7&#39;) 梅花 7(&#39;梅花&#39;, &#39;J&#39;) 梅花 J(&#39;方块&#39;, &#39;J&#39;) 方块 J</code></pre><blockquote><p>元素比较少，还能勉强猜出意思。我们用刚学的 nametuple 来看看。</p></blockquote><h4 id="nametuple-参与创建卡牌"><a href="#nametuple-参与创建卡牌" class="headerlink" title="nametuple 参与创建卡牌"></a>nametuple 参与创建卡牌</h4><pre><code class="python">import collectionsCard = collections.namedtuple(&#39;Card&#39;, [&#39;rank&#39;, &#39;suit&#39;])class FrenchDeck:    ranks = [str(n) for n in range(2, 11)] + list(&#39;JQKA&#39;)    suits = &#39;黑桃 方块 梅花 红桃&#39;.split()    def __init__(self):        self._cards = [Card(rank, suit) for suit in self.suits                       for rank in self.ranks]    def __len__(self):        return len(self._cards)    def __getitem__(self, position):        return self._cards[position]</code></pre><pre><code class="python">print(FrenchDeck.ranks)  # 生成需要的卡牌列表FrenchDeck.suits  # 卡牌花色</code></pre><pre><code> [&#39;2&#39;, &#39;3&#39;, &#39;4&#39;, &#39;5&#39;, &#39;6&#39;, &#39;7&#39;, &#39;8&#39;, &#39;9&#39;, &#39;10&#39;, &#39;J&#39;, &#39;Q&#39;, &#39;K&#39;, &#39;A&#39;] &gt;&gt;&gt; [&#39;黑桃&#39;, &#39;方块&#39;, &#39;梅花&#39;, &#39;红桃&#39;]</code></pre><pre><code class="python">fcards = FrenchDeck()  # 实例化对象fcards._cards  # 查看以下 nametuple 的出来的卡牌，是不是更加直观好看</code></pre><pre><code>[Card(rank=&#39;2&#39;, suit=&#39;黑桃&#39;), Card(rank=&#39;3&#39;, suit=&#39;黑桃&#39;), Card(rank=&#39;4&#39;, suit=&#39;黑桃&#39;), Card(rank=&#39;5&#39;, suit=&#39;黑桃&#39;), Card(rank=&#39;6&#39;, suit=&#39;黑桃&#39;), Card(rank=&#39;7&#39;, suit=&#39;黑桃&#39;), Card(rank=&#39;8&#39;, suit=&#39;黑桃&#39;), Card(rank=&#39;9&#39;, suit=&#39;黑桃&#39;), Card(rank=&#39;10&#39;, suit=&#39;黑桃&#39;), Card(rank=&#39;J&#39;, suit=&#39;黑桃&#39;), Card(rank=&#39;Q&#39;, suit=&#39;黑桃&#39;), Card(rank=&#39;K&#39;, suit=&#39;黑桃&#39;), Card(rank=&#39;A&#39;, suit=&#39;黑桃&#39;), Card(rank=&#39;2&#39;, suit=&#39;方块&#39;), Card(rank=&#39;3&#39;, suit=&#39;方块&#39;), Card(rank=&#39;4&#39;, suit=&#39;方块&#39;), Card(rank=&#39;5&#39;, suit=&#39;方块&#39;), Card(rank=&#39;6&#39;, suit=&#39;方块&#39;), Card(rank=&#39;7&#39;, suit=&#39;方块&#39;), Card(rank=&#39;8&#39;, suit=&#39;方块&#39;), Card(rank=&#39;9&#39;, suit=&#39;方块&#39;), Card(rank=&#39;10&#39;, suit=&#39;方块&#39;), Card(rank=&#39;J&#39;, suit=&#39;方块&#39;), Card(rank=&#39;Q&#39;, suit=&#39;方块&#39;), Card(rank=&#39;K&#39;, suit=&#39;方块&#39;), Card(rank=&#39;A&#39;, suit=&#39;方块&#39;), Card(rank=&#39;2&#39;, suit=&#39;梅花&#39;), Card(rank=&#39;3&#39;, suit=&#39;梅花&#39;), Card(rank=&#39;4&#39;, suit=&#39;梅花&#39;), Card(rank=&#39;5&#39;, suit=&#39;梅花&#39;), Card(rank=&#39;6&#39;, suit=&#39;梅花&#39;), Card(rank=&#39;7&#39;, suit=&#39;梅花&#39;), Card(rank=&#39;8&#39;, suit=&#39;梅花&#39;), Card(rank=&#39;9&#39;, suit=&#39;梅花&#39;), Card(rank=&#39;10&#39;, suit=&#39;梅花&#39;), Card(rank=&#39;J&#39;, suit=&#39;梅花&#39;), Card(rank=&#39;Q&#39;, suit=&#39;梅花&#39;), Card(rank=&#39;K&#39;, suit=&#39;梅花&#39;), Card(rank=&#39;A&#39;, suit=&#39;梅花&#39;), Card(rank=&#39;2&#39;, suit=&#39;红桃&#39;), Card(rank=&#39;3&#39;, suit=&#39;红桃&#39;), Card(rank=&#39;4&#39;, suit=&#39;红桃&#39;), Card(rank=&#39;5&#39;, suit=&#39;红桃&#39;), Card(rank=&#39;6&#39;, suit=&#39;红桃&#39;), Card(rank=&#39;7&#39;, suit=&#39;红桃&#39;), Card(rank=&#39;8&#39;, suit=&#39;红桃&#39;), Card(rank=&#39;9&#39;, suit=&#39;红桃&#39;), Card(rank=&#39;10&#39;, suit=&#39;红桃&#39;), Card(rank=&#39;J&#39;, suit=&#39;红桃&#39;), Card(rank=&#39;Q&#39;, suit=&#39;红桃&#39;), Card(rank=&#39;K&#39;, suit=&#39;红桃&#39;), Card(rank=&#39;A&#39;, suit=&#39;红桃&#39;)]</code></pre><p>同样我们访问元素看看</p><pre><code class="python">for i in range(3):    card = fcards._cards[randint(0, 53)]    print(card, card.rank, card.suit)</code></pre><pre><code>Card(rank=&#39;5&#39;, suit=&#39;方块&#39;) 5 方块Card(rank=&#39;5&#39;, suit=&#39;黑桃&#39;) 5 黑桃Card(rank=&#39;J&#39;, suit=&#39;红桃&#39;) J 红桃</code></pre><blockquote><p>通过属性访问，是不是可读性提高很多了呢？</p></blockquote><h3 id="奇妙的对象模型"><a href="#奇妙的对象模型" class="headerlink" title="奇妙的对象模型"></a>奇妙的对象模型</h3><h4 id="神奇的魔术方法（magic-mthod）-或者-双下方法（dunder-method）"><a href="#神奇的魔术方法（magic-mthod）-或者-双下方法（dunder-method）" class="headerlink" title="神奇的魔术方法（magic mthod） 或者 双下方法（dunder method）"></a>神奇的魔术方法（magic mthod） 或者 双下方法（dunder method）</h4><p>今天我们介绍两个简单的魔术方法，因为魔术方法很多以后会慢慢添加。</p><ul><li><code>__len__</code></li><li><code>__getitem__</code></li></ul><p>可以看名字直接猜猜意思哦！</p><h4 id="len"><a href="#len" class="headerlink" title="__len__"></a><code>__len__</code></h4><pre><code class="python"># len:class A:    def __len__(self):        print(&quot;Attention __len__ is called!!!&quot;)        return 12</code></pre><p>其实看名字我们就能猜出个八九不离十，肯定和长度有关嘛。首先随便定义一个类，看看有什么神奇的效果！</p><pre><code class="python">test_len = A()len(test_len)</code></pre><pre><code>Attention __len__ is called!!!&gt;&gt;&gt;  12</code></pre><p>没错，其实 <code>len(object)</code> 时，就是重载了 <code>object.__len__</code>方法，不过用 <code>len(obj)</code> 看起来更加优雅哦。<br>next one！</p><h4 id="getitem"><a href="#getitem" class="headerlink" title="__getitem__"></a><code>__getitem__</code></h4><pre><code class="python">class B:    def __getitem__(self, item):        print(item)        return &quot;Attention item is calling&quot;</code></pre><pre><code class="python">B()[0]</code></pre><pre><code>0&gt;&gt;&gt; &#39;Attention item is calling&#39;</code></pre><p>没错 <code>__getitem__</code> 就是当索引对象时重载的方法。<br>当然，我们也可以传一些奇怪的索引给对象！</p><pre><code class="python">B()[&quot;pythonic!&quot;]</code></pre><pre><code>pythonic!&gt;&gt;&gt;  &#39;Attention item is calling&#39;</code></pre><blockquote><p>!没错！这就变成字典的索引！是不是很神奇呢？<br>但是有些时候重写这两个方法也不是一件容易的事，但是我们可以偷偷懒。<br>如同定义 FrenchDeck 的操作。<br>利用原对象的特性！我们让 FrenchDeck 也具有了长度和索引的技能！</p></blockquote><pre><code class="python">len(fcards)</code></pre><pre><code>52</code></pre><pre><code class="python">fcards[randint(0, 53)]</code></pre><pre><code>Card(rank=&#39;J&#39;, suit=&#39;红桃&#39;)</code></pre><p><strong>如果自定义对象也需要这两个方法的时候，可以重点研究尝试一下！</strong></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>学到哪，总结到哪！我们简单回顾一下我们学的：</p><ul><li><a href="#namedtuple">神奇的元组（namedtuple）</a>  <ul><li>用对象属性访问值的元组！更加 pythonic ！</li></ul></li><li><a href="#dataclass">简便的数据模型 （dataclass）</a><ul><li>几行代码创建一个数据模型类！方便快捷！</li></ul></li><li><a href="#奇妙的对象模型">奇妙的对象模型</a><ul><li><a href="#`__len__`"><code>__len__</code></a></li><li><a href="#`__getitem__`"><code>__getitem__</code></a></li></ul></li></ul><h3 id="一些额外的补充"><a href="#一些额外的补充" class="headerlink" title="一些额外的补充"></a>一些额外的补充</h3><ul><li><h4 id="一些常见的运算魔术方法。"><a href="#一些常见的运算魔术方法。" class="headerlink" title="一些常见的运算魔术方法。"></a>一些常见的运算魔术方法。</h4></li><li><h4 id="namedtuple-的高阶使用。"><a href="#namedtuple-的高阶使用。" class="headerlink" title="namedtuple 的高阶使用。"></a>namedtuple 的高阶使用。</h4></li></ul>]]></content>
    
    
    <categories>
      
      <category>数据结构</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>advance</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python 请求分析及多提取器 提取数据</title>
    <link href="/2020/04/07/spider-parser/"/>
    <url>/2020/04/07/spider-parser/</url>
    
    <content type="html"><![CDATA[<h1 id="豆瓣电影的多方法解析"><a href="#豆瓣电影的多方法解析" class="headerlink" title="豆瓣电影的多方法解析"></a>豆瓣电影的多方法解析</h1><p><a href="https://movie.douban.com/tag/Top100" target="_blank" rel="noopener">豆瓣top100</a></p><p>本项目主要是数据提取的练习,提供了5种数据提取的方式.</p><h3 id="1-分析网页-需要的数据请求地址分析"><a href="#1-分析网页-需要的数据请求地址分析" class="headerlink" title="1. 分析网页  # 需要的数据请求地址分析"></a>1. <a href="#1-分析网页确认爬取目标的数据类型">分析网页</a>  # 需要的数据请求地址分析</h3><h3 id="2-正则提取-正则提取所须数据"><a href="#2-正则提取-正则提取所须数据" class="headerlink" title="2. 正则提取  # 正则提取所须数据"></a>2. <a href="#1-正则提取">正则提取</a>  # 正则提取所须数据</h3><h3 id="3-Css选择器提取-利用BeautifulSoup4-进行提取"><a href="#3-Css选择器提取-利用BeautifulSoup4-进行提取" class="headerlink" title="3. Css选择器提取  # 利用BeautifulSoup4 进行提取"></a>3. <a href="#2-beautifulsoup-css选择器-提取">Css选择器提取</a>  # 利用BeautifulSoup4 进行提取</h3><h3 id="4-Xpath选择器提取-利用lxml的etree模块进行xpath提取"><a href="#4-Xpath选择器提取-利用lxml的etree模块进行xpath提取" class="headerlink" title="4. Xpath选择器提取  # 利用lxml的etree模块进行xpath提取"></a>4. <a href="#3-xpath-提取">Xpath选择器提取</a>  # 利用lxml的etree模块进行xpath提取</h3><h3 id="5-jQuery提取-有前端的知识的朋友应该很熟悉-利用的是pyquery模块-节点选择语法与jQuery一致"><a href="#5-jQuery提取-有前端的知识的朋友应该很熟悉-利用的是pyquery模块-节点选择语法与jQuery一致" class="headerlink" title="5. jQuery提取  # 有前端的知识的朋友应该很熟悉,利用的是pyquery模块,节点选择语法与jQuery一致"></a>5. <a href="#4-pyquery-的数据提取">jQuery提取</a>  # 有前端的知识的朋友应该很熟悉,利用的是pyquery模块,节点选择语法与jQuery一致</h3><h3 id="6-Scrapy-parsel-混合提取器-利用scrapy的Selector模块进行混合提取"><a href="#6-Scrapy-parsel-混合提取器-利用scrapy的Selector模块进行混合提取" class="headerlink" title="6. Scrapy/parsel 混合提取器  # 利用scrapy的Selector模块进行混合提取"></a>6. <a href="#5-scrapy-混合提取">Scrapy/parsel 混合提取器</a>  # 利用scrapy的Selector模块进行混合提取</h3><h3 id="7-总结"><a href="#7-总结" class="headerlink" title="7. 总结"></a>7. <a href="#总结">总结</a></h3><h4 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a><a href="./douban_spider.ipynb">完整代码</a></h4><h3 id="1-分析网页，确认爬取目标的数据类型。"><a href="#1-分析网页，确认爬取目标的数据类型。" class="headerlink" title="1. 分析网页，确认爬取目标的数据类型。"></a>1. 分析网页，确认爬取目标的数据类型。</h3><ul><li><h4 id="打开-目标url-定位数据位置"><a href="#打开-目标url-定位数据位置" class="headerlink" title="打开 目标url, 定位数据位置"></a>打开 <a href="https://movie.douban.com/tag/Top100" target="_blank" rel="noopener">目标url</a>, 定位数据位置</h4><img src="https://img-blog.csdnimg.cn/2019090309464243.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2R1c3R5cG9zYQ==,size_16,color_FFFFFF,t_70" srcset="/img/loading.gif" alt="首页"></li><li><h4 id="定位需要的数据位置，查看爬取目标。"><a href="#定位需要的数据位置，查看爬取目标。" class="headerlink" title="定位需要的数据位置，查看爬取目标。"></a>定位需要的数据位置，查看爬取目标。</h4> <img src="https://img-blog.csdnimg.cn/20190903094719997.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2R1c3R5cG9zYQ==,size_16,color_FFFFFF,t_70" srcset="/img/loading.gif" alt="数据源"><br> 由图可得，我们需要的数据分别为，[‘海报’, ‘电影名’, ‘上映日期’, ‘演员’, ‘评分’, ‘评价人数’]</li><li><h4 id="查看请求，分析数据来源请求（F12-gt-gt-network-打开请求界面，如下图）"><a href="#查看请求，分析数据来源请求（F12-gt-gt-network-打开请求界面，如下图）" class="headerlink" title="查看请求，分析数据来源请求（F12 &gt;&gt; network 打开请求界面，如下图）"></a>查看请求，分析数据来源请求（F12 &gt;&gt; network 打开请求界面，如下图）</h4><img src="https://img-blog.csdnimg.cn/20190903094745651.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2R1c3R5cG9zYQ==,size_16,color_FFFFFF,t_70" srcset="/img/loading.gif" alt="抓包"> </li><li><h4 id="确认数据请求来源-Ctrl-F-搜索-辛德勒"><a href="#确认数据请求来源-Ctrl-F-搜索-辛德勒" class="headerlink" title="确认数据请求来源(Ctrl + F 搜索: 辛德勒)"></a>确认数据请求来源(Ctrl + F 搜索: 辛德勒)</h4> <img src="https://img-blog.csdnimg.cn/20190903094815715.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2R1c3R5cG9zYQ==,size_16,color_FFFFFF,t_70" srcset="/img/loading.gif" alt="定位请求"><br> 上图可知，该请求只有一个，所以就能轻松的确定来源拉！ </li><li><h4 id="查看headers，分析请求报文"><a href="#查看headers，分析请求报文" class="headerlink" title="查看headers，分析请求报文"></a>查看headers，分析请求报文</h4><img src="https://img-blog.csdnimg.cn/2019090309491356.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2R1c3R5cG9zYQ==,size_16,color_FFFFFF,t_70" srcset="/img/loading.gif" alt="在这里插入图片描述"><br> 分析结果如图，所以我们可以得出以下结论：  </li></ul><table><thead><tr><th align="left">信息</th><th>结果</th></tr></thead><tbody><tr><td align="left">请求地址</td><td><a href="https://movie.douban.com/tag/Top100" target="_blank" rel="noopener">https://movie.douban.com/tag/Top100</a></td></tr><tr><td align="left">请求方法</td><td>Get</td></tr><tr><td align="left">响应格式</td><td>text 文本</td></tr><tr><td align="left">编码</td><td>UTF-8</td></tr></tbody></table><h2 id="2-利用requests进行请求测试"><a href="#2-利用requests进行请求测试" class="headerlink" title="2. 利用requests进行请求测试"></a>2. 利用requests进行请求测试</h2><p><code>requests.get</code><br>定义请求函数，<code>get_data</code><br>返回<code>text</code>数据  </p><p>模块导入</p><pre><code class="python">&gt;&gt;&gt; import requests&gt;&gt;&gt; from requests.exceptions import HTTPError</code></pre><pre><code class="python">def get_data(url):    response = requests.get(url)    if response.status_code == requests.codes.ok:  # 检测状态码        return response.text  # 返回响应的文本信息    else:        response.raise_for_status()  # 4xx 5xx 时,引出错误 代替 raise requests.exception.HTTPError url = &quot;https://movie.douban.com/tag/Top100&quot;data = get_data(url)  # 获取数据data_res = {}  # 存储数据的初始化字典data # 查看数据</code></pre><pre><code>&lt;!DOCTYPE html&gt;&lt;html lang=&quot;zh-cmn-Hans&quot; class=&quot;ua-windows ua-webkit&quot;&gt;&lt;head&gt;    &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=utf-8&quot;&gt;......</code></pre><h2 id="3-提取数据"><a href="#3-提取数据" class="headerlink" title="3. 提取数据"></a>3. 提取数据</h2><ul><li>正则提取</li><li>BeautifulSoup 提取</li><li>Xpath 提取</li><li>pyquery 提取</li><li>scrapy 混合提取</li></ul><h3 id="1-正则提取"><a href="#1-正则提取" class="headerlink" title="1. 正则提取"></a>1. 正则提取</h3><ul><li>观察数据位置<br><img src="https://img-blog.csdnimg.cn/20190903094936617.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2R1c3R5cG9zYQ==,size_16,color_FFFFFF,t_70" srcset="/img/loading.gif" alt="正则数据位置"></li></ul><p>导入模块</p><pre><code class="python">&gt;&gt;&gt; import re</code></pre><h3 id="提取-海报地址以及电影名称"><a href="#提取-海报地址以及电影名称" class="headerlink" title="提取 海报地址以及电影名称"></a>提取 海报地址以及电影名称</h3><p><strong>通过查看该请求的响应内容快速进行复制匹配,如下图搜索:</strong><br><img src="https://img-blog.csdnimg.cn/20190903094959517.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2R1c3R5cG9zYQ==,size_16,color_FFFFFF,t_70" srcset="/img/loading.gif" alt="正则获取数据"><br>用到的匹配规则提示:</p><ul><li>“.” 表示任意非空格换行等字符</li><li>“.*?”  表示贪婪匹配,最少匹配一次</li><li>“()”  表示提取()中的内容</li><li>“\w” 表示正常字符,比如英文字母,中文等常见文字</li><li>“.+”  表示至少匹配一次任意字符</li></ul><pre><code class="python">&gt;&gt;&gt; # 设置提取表达式 &gt;&gt;&gt; poster_pattern = re.compile(r&quot;&quot;&quot;&lt;a class=&quot;nbg&quot; href=&quot;.*?&quot;  title=&quot;.*?&quot;&gt;.*?&lt;img src=&quot;(.*?)&quot; width=&quot;75&quot; alt=&quot;(.*?)&quot; class=&quot;&quot;/&gt;.*?&lt;/a&gt;&quot;&quot;&quot;, re.S)  # 海报的正则表达式&gt;&gt;&gt; movie_name_pattern = re.compile(r&quot;&quot;&quot; &lt;div class=&quot;pl2&quot;&gt;.*? &lt;a href=&quot;.*?&quot;  class=&quot;&quot;&gt;.*?(\w+).*?&lt;span style=&quot;font-size:13px;&quot;&gt;(.*?)&lt;/span&gt;.*?&lt;/a&gt;&quot;&quot;&quot;, re.S)  # 电影名正则表达式&gt;&gt;&gt; poster_res = re.findall(poster_pattern, data)  # 获取所有匹配结果&gt;&gt;&gt; movie_name_res = re.findall(movie_name_pattern, data)&gt;&gt;&gt; poster_res, movie_name_res......(&#39;https://img3.doubanio.com/view/photo/s_ratio_poster/public/p1910902213.jpg&#39;,&#39;低俗小说&#39;),(&#39;https://img3.doubanio.com/view/photo/s_ratio_poster/public/p1665997400.jpg&#39;,&#39;美丽心灵&#39;)],[(&#39;辛德勒的名单&#39;, &#39;舒特拉的名单(港) / 辛德勒名单&#39;),(&#39;狩猎&#39;, &#39;谎言的烙印(台) / 诬网(港)&#39;),(&#39;美国往事&#39;, &#39;四海兄弟(台) / 义薄云天(港)&#39;),......</code></pre><p><strong>查看结果好像没什么问题, 我们用长度比较来看看数量是否一致</strong></p><pre><code class="python">&gt;&gt;&gt; len(poster_res) == len(movie_name_res)True</code></pre><p><strong>长度一致,看来匹配规则在这里没问题</strong><br>我们将提取到的数据存储到我们的数据结构<code>data_res</code>中</p><pre><code class="python">for poster, movie_name in zip(poster_res, movie_name_res):  # 压缩遍历    # 进行名称验证，是否对应,    name1 = poster[1]    name2 = movie_name[0]    if name1 == name2:        tmp_dict = data_res.get(name1, {})  # 初始化字典        tmp_dict.update({&quot;poster&quot;: poster[0]})  # 字典更新        tmp_dict.update({&quot;else_name&quot;: movie_name[1]})  # 字典更新        data_res[name1] = tmp_dictdata_res</code></pre><pre><code>{&#39;辛德勒的名单&#39;: {&#39;poster&#39;: &#39;https://img3.doubanio.com/view/photo/s_ratio_poster/public/p492406163.jpg&#39;,  &#39;else_name&#39;: &#39;舒特拉的名单(港) / 辛德勒名单&#39;}, &#39;狩猎&#39;: {&#39;poster&#39;: &#39;https://img1.doubanio.com/view/photo/s_ratio_poster/public/p1546987967.jpg&#39;,  &#39;else_name&#39;: &#39;谎言的烙印(台) / 诬网(港)&#39;}, &#39;美国往事&#39;: {&#39;poster&#39;: &#39;https://img1.doubanio.com/view/photo/s_ratio_poster/public/p477229647.jpg&#39;,  &#39;else_name&#39;: &#39;四海兄弟(台) / 义薄云天(港)&#39;}, &#39;十二怒汉&#39;: {&#39;poster&#39;: &#39;https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2173577632.jpg&#39;, ...... }</code></pre><p><strong>我们用同样的方法,提取其他需要的数据</strong><br><strong><em>这里有个小技巧,用额外的字段来得到唯一匹配, 如下图:</em></strong><br>需要的数据:<br><img src="https://img-blog.csdnimg.cn/20190903095020573.png" srcset="/img/loading.gif" alt="unique1"><br>额外数据匹配:<br><img src="https://img-blog.csdnimg.cn/20190903095034683.png" srcset="/img/loading.gif" alt="unique2"></p><h4 id="整体提取"><a href="#整体提取" class="headerlink" title="整体提取"></a>整体提取</h4><p><strong>由于所有数据都集中在一个块，如下图：</strong><br><img src="https://img-blog.csdnimg.cn/20190903095100811.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2R1c3R5cG9zYQ==,size_16,color_FFFFFF,t_70" srcset="/img/loading.gif" alt="在这里插入图片描述"><br>所有我们就一次性全部提取，方便数据的收集.<br>由于有些是电影值有一个年份，所以匹配不好匹配，我们匹配整体后利用”/“进行分割再挑选.<br><em>PS: 其实正则匹配这种很多字段的容易出错，换行之类的字符容易忘记替代，所以建议一点一点的增加匹配表达式的长度.</em></p><pre><code class="python">&gt;&gt;&gt; total_pattern = re.compile(&quot;&quot;&quot;&lt;p class=&quot;ul&quot;&gt;.*?&lt;a class=&quot;nbg&quot; href=&quot;.*?&quot;  title=&quot;(.*?)&quot;&gt;.*?&lt;img src=&quot;(.*?)&quot; width=&quot;75&quot;.*?&lt;div class=&quot;pl2&quot;&gt;.*?&lt;a href=&quot;.*?&quot;  class=&quot;&quot;&gt;.*?(\w+).*?style=&quot;font-size:13px;&quot;&gt;(.*?)&lt;/span&gt;.*?class=&quot;pl&quot;&gt;(.*?)&lt;/p&gt;.*?class=&quot;star clearfix&quot;&gt;.*?&quot;allstar45&quot;&gt;&lt;/span&gt;.*?&quot;rating_nums&quot;&gt;(.*?)&lt;/span&gt;.*?&lt;span class=&quot;pl&quot;&gt;\((.*?)\)&lt;/span&gt;.*?&lt;div id=&quot;.*?&quot;&gt;&lt;/div&gt;&quot;&quot;&quot;, re.S)&gt;&gt;&gt; res = re.findall(total_pattern, data)&gt;&gt;&gt; res</code></pre><pre><code>[(&#39;狩猎&#39;,  &#39;https://img1.doubanio.com/view/photo/s_ratio_poster/public/p1546987967.jpg&#39;,  &#39;狩猎&#39;,  &#39;谎言的烙印(台) / 诬网(港)&#39;,  &#39;2012-05-20(戛纳电影节) / 2013-01-10(丹麦) / 麦斯·米科尔森 / 托玛斯·博·拉森 / 安妮卡·韦德科普 / 拉丝·弗格斯托姆 / 苏西·沃德 / 安妮·路易丝·哈辛 / 拉斯·兰特 / 亚历山德拉·拉帕波特 / 拉斯穆斯·林德·鲁宾 / 丹麦 / 瑞典 / 托马斯·温特伯格...&#39;,  &#39;9.1&#39;,  &#39;184560人评价&#39;), (&#39;美国往事&#39;,  &#39;https://img1.doubanio.com/view/photo/s_ratio_poster/public/p477229647.jpg&#39;,  &#39;美国往事&#39;,......]</code></pre><h4 id="观察整体数据情况，提取数据"><a href="#观察整体数据情况，提取数据" class="headerlink" title="观察整体数据情况，提取数据"></a>观察整体数据情况，提取数据</h4><p><img src="https://img-blog.csdnimg.cn/20190903095121985.png" srcset="/img/loading.gif" alt="处理时间"></p><pre><code class="python">def get_time_actor(data):    &quot;&quot;&quot;    获取处理后的时间和演员数据    :param data:     :return:     &quot;&quot;&quot;    tmp_data = data.split(&quot; / &quot;)    ind = 1    for i, v in enumerate(tmp_data):        if v[:4].isdigit():  # 判断是否为数字            ind += 1        else:            break        return tmp_data[:ind], tmp_data[ind:]</code></pre><pre><code class="python">for tmp_data in res:    tmp = data_res.get(tmp_data[0], {})  # 获取原来的字典数据    if tmp_data[0] == tmp_data[2]:  # 检测数据是否对齐        tmp.update({&quot;movie_name&quot;: tmp_data[0], &quot;poster_url&quot;: tmp_data[1], &quot;other_name&quot;: tmp_data[3], &quot;score&quot;: float(tmp_data[-2]), &quot;comment_people&quot;: tmp_data[-1].replace(&quot;人评价&quot;, &quot;&quot;)})  # 更新数据        time_data, actor = get_time_actor(tmp_data[-3])        tmp.update({&quot;release_time&quot;: time_data, &quot;actor&quot;: actor})        data_res[tmp_data[0]] = tmp    else:        print(&quot;数据有误&quot;)print(data_res)</code></pre><pre><code>    {    &#39;辛德勒的名单&#39;: {&#39;poster&#39;: &#39;https://img3.doubanio.com/view/photo/s_ratio_poster/public/p492406163.jpg&#39;, &#39;else_name&#39;: &#39;舒特拉的名单(港) / 辛德勒名单&#39;}, &#39;狩猎&#39;: {&#39;poster&#39;: &#39;https://img1.doubanio.com/view/photo/s_ratio_poster/public/p1546987967.jpg&#39;, &#39;else_name&#39;: &#39;谎言的烙印(台) / 诬网(港)&#39;, &#39;movie_name&#39;: &#39;狩猎&#39;, &#39;poster_url&#39;: &#39;https://img1.doubanio.com/view/photo/s_ratio_poster/public/p1546987967.jpg&#39;, &#39;other_name&#39;: &#39;谎言的烙印(台) / 诬网(港)&#39;,    .....    }</code></pre><h2 id="2-BeautifulSoup-（css选择器）-提取"><a href="#2-BeautifulSoup-（css选择器）-提取" class="headerlink" title="2. BeautifulSoup （css选择器） 提取"></a>2. BeautifulSoup （css选择器） 提取</h2><p>导入模块</p><pre><code class="python">&gt;&gt;&gt; from bs4 import BeautifulSoup</code></pre><pre><code class="python">&gt;&gt;&gt; soup = BeautifulSoup(data, &quot;lxml&quot;)  # 初始化soup对象</code></pre><h4 id="利用css选择器逐一获取数据"><a href="#利用css选择器逐一获取数据" class="headerlink" title="利用css选择器逐一获取数据"></a>利用css选择器逐一获取数据</h4><p><strong>poster</strong>: <code>&quot;.nbg img&quot;</code><br><strong>movie_name</strong>: <code>&quot;.pl2 a&quot;</code><br><strong>time_actor</strong>: <code>&quot;.pl2 p.pl&quot;</code><br><strong>score</strong>: <code>&quot;.rating_nums&quot;</code><br><strong>comment_people</strong>: <code>&quot;.star.clearfix .pl&quot;</code>   </p><p><strong><em>PS:</em></strong>  </p><ul><li>“.” 表示class </li><li>“ “表示子孙节点  </li><li>img 就是img节点  </li><li>a 就是a节点</li><li>“#abd” 表示 id=”abc”的节点</li></ul><pre><code class="python">&gt;&gt;&gt; poster = soup.select(&quot;.nbg img&quot;)  # 海报&gt;&gt;&gt; movie_name = soup.select(&quot;.pl2 a&quot;)  # 电影名称&gt;&gt;&gt; time_actor = soup.select(&quot;.pl2 p.pl&quot;)  # 上映时间及演员&gt;&gt;&gt; score = soup.select(&quot;.rating_nums&quot;)  # 电影评分&gt;&gt;&gt; comment_people = soup.select(&quot;.star.clearfix .pl&quot;)  # 评分人数&gt;&gt;&gt; movie_data = {}  # 存储结构</code></pre><h4 id="批量获取数据"><a href="#批量获取数据" class="headerlink" title="批量获取数据"></a>批量获取数据</h4><pre><code class="python">for p, m, t, s, c in zip(poster, movie_name, time_actor, score, comment_people):    pos = p.get(&quot;src&quot;)  # 海报地址    mov = m.get_text().replace(m.select(&quot;span&quot;)[0].get_text(), &quot;&quot;)  # 电影名称    mov = mov.replace(&quot;/&quot;, &quot;&quot;).strip()  # 去掉不需要的字符    other_name = m.select(&quot;span&quot;)[0].get_text()  # 额外名字    release_time, actor = get_time_actor(t.get_text())    sco = s.get_text()    comment = c.get_text()    movie_data.update({mov: {&quot;poster&quot;: pos, &quot;movie_name&quot;: mov, &quot;other_name&quot;: other_name, &quot;release_time&quot;: release_time, &quot;actor&quot;: actor, &quot;score&quot;: sco, &quot;comment&quot;: comment}})print(movie_data)</code></pre><pre><code>    {    &#39;辛德勒的名单&#39;: {&#39;poster&#39;: &#39;https://img3.doubanio.com/view/photo/s_ratio_poster/public/p492406163.jpg&#39;, &#39;movie_name&#39;: &#39;辛德勒的名单&#39;, &#39;other_name&#39;: &#39;舒特拉的名单(港) / 辛德勒名单&#39;, &#39;release_time&#39;: [&#39;1993-11-30(华盛顿首映)&#39;, &#39;1994-02-04(美国)&#39;], &#39;actor&#39;: [&#39;连姆·尼森&#39;, &#39;本·金斯利&#39;, &#39;拉尔夫·费因斯&#39;, &#39;卡罗琳·古多尔&#39;, &#39;乔纳森·萨加尔&#39;, &#39;艾伯丝·戴维兹&#39;, &#39;马尔戈萨·格贝尔&#39;, &#39;马克·伊瓦涅&#39;, &#39;碧翠斯·马科拉&#39;, &#39;安德烈·瑟韦林&#39;, &#39;弗里德里希·冯·图恩&#39;, &#39;克齐斯茨托夫·拉夫特...&#39;], &#39;score&#39;: &#39;9.5&#39;, &#39;comment&#39;: &#39;(571888人评价)&#39;}, &#39;狩猎&#39;: {&#39;poster&#39;: &#39;https://img1.doubanio    ......    }</code></pre><h2 id="3-Xpath-提取"><a href="#3-Xpath-提取" class="headerlink" title="3. Xpath 提取"></a>3. Xpath 提取</h2><pre><code class="python">&gt;&gt;&gt; from lxml import etree  # 导入xpath模块</code></pre><pre><code class="python">&gt;&gt;&gt; xpath_data = etree.HTML(data)  # 初始化xpath结构</code></pre><p>可以直接在浏览器中试xpath表达式,如下图:<br>[外链图片转存失败(img-y8TSyP0X-1567474955837)(./images/xpath1.png)]<br><strong>下例用到的xpath语法解释:</strong>  </p><ul><li>“//“  # 代表从根节点搜索</li><li>“//a”  # 搜索根节点的所有a标签</li><li>“//a[@class=”nbg]”  # 搜索class=”nbg”的a标签</li><li>“…/a”  # 搜索从…节点开始的子a标签</li><li>“…/img/@src”  # 获取当前img标签的src属性</li><li>“…/p/text()”  # 获取当前p标签下的文本</li><li>“…/p//text()”  # 获取当前p标签后的所有文本(子孙文本)</li></ul><pre><code class="python">&gt;&gt;&gt; poster = xpath_data.xpath(&#39;//a[@class=&quot;nbg&quot;]/img/@src&#39;)  # 获取海报&gt;&gt;&gt; movie_name = xpath_data.xpath(&#39;//div[@class=&quot;pl2&quot;]/a/text()&#39;)  # 获取电影名&gt;&gt;&gt; other_name = xpath_data.xpath(&#39;//div[@class=&quot;pl2&quot;]/a/span/text()&#39;)  # 获取电影别名&gt;&gt;&gt; time_actor = xpath_data.xpath(&#39;//div[@class=&quot;pl2&quot;]/p/text()&#39;)  # 获取时间和演员&gt;&gt;&gt; score = xpath_data.xpath(&#39;//span[@class=&quot;rating_nums&quot;]/text()&#39;)  # 获取评分&gt;&gt;&gt; comment_people = xpath_data.xpath(&#39;//span[@class=&quot;pl&quot;]/text()&#39;)  # 评分人数&gt;&gt;&gt; movie_data = {}</code></pre><h4 id="同样进行数据收集"><a href="#同样进行数据收集" class="headerlink" title="同样进行数据收集"></a>同样进行数据收集</h4><pre><code class="python">for p, m, o, t, s, c in zip(poster, movie_name, other_name, time_actor, score, comment_people):    m = m.replace(&quot;/&quot;, &quot;&quot;).strip()    release_time, actor = get_time_actor(t)    movie_data.update({m: {&quot;poster&quot;: p, &quot;movie_name&quot;: m, &quot;other_name&quot;: t, &quot;release_time&quot;: release_time, &quot;actor&quot;: actor, &quot;score&quot;: s, &quot;comment&quot;: c}})print(movie_data)</code></pre><pre><code>    {    &#39;辛德勒的名单&#39;: {&#39;poster&#39;: &#39;https://img3.doubanio.com/view/photo/s_ratio_poster/public/p492406163.jpg&#39;, &#39;movie_name&#39;: &#39;辛德勒的名单&#39;, &#39;other_name&#39;: &#39;1993-11-30(华盛顿首映) / 1994-02-04(美国) / 连姆·尼森 / 本·金斯利 / 拉尔夫·费因斯 / 卡罗琳·古多尔 /    ......    }</code></pre><h2 id="4-Pyquery-的数据提取"><a href="#4-Pyquery-的数据提取" class="headerlink" title="4. Pyquery 的数据提取"></a>4. Pyquery 的数据提取</h2><p>主要利用jquery的定位方式，<br>如 “.name” 表示 class=”name”<br>“#name” 表示 id=”name”<br>以下例子中:</p><ul><li>“a.nbg”  # 表示 a class=”nbg”</li><li>“a img”  # 表示 a标签的子孙img标签</li><li>.remove()  # 表示移除该节点</li><li>.items()  # 当选中多个节点时,需要使用.items() 生成可遍历对象再进行提取</li><li>.attr()  # 表示获取标签</li><li>.text()  # 表示获取文本</li></ul><pre><code class="python">&gt;&gt;&gt; from pyquery import PyQuery as pq</code></pre><pre><code class="python">&gt;&gt;&gt; query_data = pq(data[:])  # 因为为了便于提取,需要删除节点,避免破坏元数据,拷贝一份</code></pre><pre><code class="python">&gt;&gt;&gt; poster = (i.attr[&quot;src&quot;] for i in query_data(&quot;a.nbg img&quot;).items())  # 获取海报&gt;&gt;&gt; other_name = [i.text() for i in query_data(&quot;div.pl2 a span&quot;).items()]  # 获取别名&gt;&gt;&gt; query_data(&quot;div.pl2 a span&quot;).remove()  # 移除别名节点&gt;&gt;&gt; movie_name = (i.text().strip(&quot;/&quot;).strip() for i in query_data(&quot;div.pl2 a&quot;).items())  # 获取电影名&gt;&gt;&gt; time_actor =  (i.text() for i in query_data(&quot;div.pl2 p&quot;).items())  # 获取上映时间和演员&gt;&gt;&gt; score = (i.text() for i in query_data(&quot;span.rating_nums&quot;).items())  # 获取评分&gt;&gt;&gt; comment_people = (i.text() for i in query_data(&quot;span.pl&quot;).items())  # 获取评价人数&gt;&gt;&gt; movie_data = {}</code></pre><pre><code class="python">for p, m, o, t, s, c in zip(poster, movie_name, other_name, time_actor, score, comment_people):    release_time, actor = get_time_actor(t)    movie_data.update({m: {&quot;poster&quot;: p, &quot;movie_name&quot;: m, &quot;other_name&quot;: t, &quot;release_time&quot;: release_time, &quot;actor&quot;: actor, &quot;score&quot;: s, &quot;comment&quot;: c}})print(movie_data)</code></pre><pre><code>    {    &#39;辛德勒的名单&#39;: {&#39;poster&#39;: &#39;https://img3.doubanio.com/view/photo/s_ratio_poster/public/p492406163.jpg&#39;, &#39;movie_name&#39;: &#39;辛德勒的名单&#39;, &#39;other_name&#39;: &#39;1993-11-30(华盛顿首映) / 1994-02-04(美国) / 连姆·尼森 / 本·金斯利 / 拉尔夫·费因斯 / 卡罗琳·古多尔 / 乔纳森·萨加尔 / 艾伯丝·戴维兹 / 马尔戈萨·格贝尔 / 马克·伊瓦涅 / 碧翠斯·马科拉 / 安德烈·瑟韦林 / 弗里德里希·冯·图恩 / 克齐斯茨托夫·拉夫特...&#39;, &#39;release_time&#39;:    ......    }</code></pre><h2 id="5-scrapy-parsel-混合提取"><a href="#5-scrapy-parsel-混合提取" class="headerlink" title="5. scrapy/parsel 混合提取"></a>5. scrapy/parsel 混合提取</h2><blockquote><p>parsel已经分离出来，可以直接 pip install 效果一样。</p></blockquote><pre><code class="python">&gt;&gt;&gt; from scrapy import Selector  # 导入scrapy的选择器&gt;&gt;&gt; # from parsel import Selector</code></pre><pre><code class="python">&gt;&gt;&gt; se = Selector(text=data)</code></pre><h4 id="提取规则说明-从下方案例可以看出-scrapy的提取器-css和xpath-以及正则提取都是支持的-我们可以混用"><a href="#提取规则说明-从下方案例可以看出-scrapy的提取器-css和xpath-以及正则提取都是支持的-我们可以混用" class="headerlink" title="提取规则说明 从下方案例可以看出,scrapy的提取器,css和xpath,以及正则提取都是支持的,我们可以混用"></a>提取规则说明 从下方案例可以看出,scrapy的提取器,css和xpath,以及正则提取都是支持的,我们可以混用</h4><ul><li>.css()  # 就是css规则的提取</li><li>.xpath()  # 就是xpath规则的提取,需要注意的是,因为scrapy的Selector支持混用,如果xpath是在某个提取器之后,那么必须使用”./“来跟进上个提取器的提取点,不能使用”//“, 因为Selector 的xapth提取器的”//“永远代表根节点<ul><li>response.css(“#id”).xpath(“./a”)  # 该规则表示id=”id” 的节点<strong>之后</strong>的所有a标签节点</li><li>response.css(“#id”).xpath(“//a”)  # 改规则就变成了提取所有的a标签节点,前面的css选择器的结果失效.</li></ul></li><li>.re()  # 就是正则的提取, 正则提取后,不需要用extract()来转化成str类型</li><li>extract()  # 将当前的选择结果转化成str类型  </li></ul><pre><code class="python">&gt;&gt;&gt; poster = se.css(&quot;.nbg img&quot;).xpath(&quot;./@src&quot;).extract()  # 获取海报&gt;&gt;&gt; movie_name = se.css(&quot;div.pl2&quot;).xpath(&quot;./a/text()&quot;).re(&quot;\w+&quot;)  # 获取电影名&gt;&gt;&gt; other_name = se.css(&quot;div.pl2&quot;).xpath(&quot;./a/span/text()&quot;).extract()  # 获取电影别名&gt;&gt;&gt; time_actor = se.css(&quot;div.pl2&quot;).xpath(&quot;./p/text()&quot;).extract()  # 获取上映日期和演员&gt;&gt;&gt; score = se.css(&quot;span.rating_nums::text&quot;).extract()  # 获取评分&gt;&gt;&gt; comment_people = se.xpath(&#39;//span[@class=&quot;pl&quot;]/text()&#39;).extract()  # 获取评分人数&gt;&gt;&gt; movie_data = {}</code></pre><pre><code class="python">for p, m, o, t, s, c in zip(poster, movie_name, other_name, time_actor, score, comment_people):    release_time, actor = get_time_actor(t)    movie_data.update({m: {&quot;poster&quot;: p, &quot;movie_name&quot;: m, &quot;other_name&quot;: t, &quot;release_time&quot;: release_time, &quot;actor&quot;: actor, &quot;score&quot;: s, &quot;comment&quot;: c}})print(movie_data)</code></pre><pre><code>    {    &#39;辛德勒的名单&#39;: {&#39;poster&#39;: &#39;https://img3.doubanio.com/view/photo/s_ratio_poster/public/p492406163.jpg&#39;, &#39;movie_name&#39;: &#39;辛德勒的名单&#39;, &#39;other_name&#39;: &#39;1993-11-30(华盛顿首映) / 1994-02-04(美国) / 连姆·尼森 / 本·金斯利 / 拉尔夫·费因斯 / 卡罗琳·古多尔 / 乔纳森·萨加尔 / 艾伯丝·戴维兹 / 马尔戈萨·格贝尔 / 马克·伊瓦涅 / 碧翠斯·马科拉 / 安德烈·瑟韦林 / 弗里德里希·冯·图恩 / 克齐斯茨托夫·拉夫特...&#39;, &#39;release_time&#39;: [&#39;1993-11-30(华盛顿首映)&#39;, &#39;1994-02-04(美国)&#39;], &#39;actor&#39;: [&#39;连姆·尼森&#39;, &#39;本·金斯利&#39;, &#39;拉尔夫·费因斯&#39;,    ......    }</code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>以上就是我们该次提取练习的所有内容,以豆瓣电影top100的响应为例,我们讲解了常用的5种提取器.<br><strong>1. 正则</strong>  </p><ul><li>“.” 表示任意非空格换行等字符</li><li>“.*?”  表示贪婪匹配,最少匹配一次</li><li>“()”  表示提取()中的内容</li><li>“\w” 表示正常字符,比如英文字母,中文等常见文字</li><li>“.+”  表示至少匹配一次任意字符  </li></ul><p><strong>2. css</strong>  </p><ul><li>“.” 表示class </li><li>“ “表示子孙节点  </li><li>img 就是img节点  </li><li>a 就是a节点</li><li>“#abd” 表示 id=”abc”的节点</li></ul><p><strong>3. xpath</strong>  </p><ul><li>“//“  # 代表从根节点搜索</li><li>“//a”  # 搜索根节点的所有a标签</li><li>“//a[@class=”nbg]”  # 搜索class=”nbg”的a标签</li><li>“…/a”  # 搜索从…节点开始的子a标签</li><li>“…/img/@src”  # 获取当前img标签的src属性</li><li>“…/p/text()”  # 获取当前p标签下的文本</li><li>“…/p//text()”  # 获取当前p标签后的所有文本(子孙文本)</li></ul><p><strong>4. pyquery</strong>  </p><ul><li>“a.nbg”  # 表示 a class=”nbg”</li><li>“a img”  # 表示 a标签的子孙img标签</li><li>.remove()  # 表示移除该节点</li><li>.items()  # 当选中多个节点时,需要使用.items() 生成可遍历对象再进行提取</li><li>.attr()  # 表示获取标签</li><li>.text()  # 表示获取文本</li></ul><p><strong>5. 混合提取</strong>  </p><ul><li>.css()  # 就是css规则的提取</li><li>.xpath()  # 就是xpath规则的提取,需要注意的是,因为scrapy的Selector支持混用,如果xpath是在某个提取器之后,那么必须使用”./“来跟进上个提取器的提取点,不能使用”//“, 因为Selector 的xapth提取器的”//“永远代表根节点<ul><li>response.css(“#id”).xpath(“./a”)  # 该规则表示id=”id” 的节点<strong>之后</strong>的所有a标签节点</li><li>response.css(“#id”).xpath(“//a”)  # 改规则就变成了提取所有的a标签节点,前面的css选择器的结果失效.</li></ul></li><li>.re()  # 就是正则的提取, 正则提取后,不需要用extract()来转化成str类型</li><li>extract()  # 将当前的选择结果转化成str类型  <h4 id="完整代码-1"><a href="#完整代码-1" class="headerlink" title="完整代码"></a><a href="https://github.com/Dustyposa/goSpider/blob/master/spider_project/douban_movie/douban_spider.ipynb" target="_blank" rel="noopener">完整代码</a></h4></li></ul>]]></content>
    
    
    <categories>
      
      <category>网络</category>
      
      <category>抓取</category>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>parser</tag>
      
      <tag>spider</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python 编写多进程 socket web静态服务器</title>
    <link href="/2020/04/06/python-server/"/>
    <url>/2020/04/06/python-server/</url>
    
    <content type="html"><![CDATA[<h3 id="服务器模型-C-S模型"><a href="#服务器模型-C-S模型" class="headerlink" title="服务器模型 C/S模型"></a>服务器模型 C/S模型</h3><p><strong>socket</strong> 是什么 ？<br><strong>一种进程间的通信技术 由伯克利大学（BSD） 发明， 才有了当前的互联网</strong></p><p><strong>几乎所有的C/S模型服务器， 底层都是socket实现的， web服务器也不例外， 只是web服务器用了：</strong></p><h4 id="HTTP协议"><a href="#HTTP协议" class="headerlink" title="HTTP协议"></a><strong>HTTP协议</strong></h4><a id="more"></a><p>用python搭建简易的web服务器：</p><h4 id="1-导入相关模块"><a href="#1-导入相关模块" class="headerlink" title="1. 导入相关模块"></a>1. 导入相关模块</h4><pre><code class="python">import os  # 导入系统模块import socket  # 导入 socket包from multiprocessing import Process  # 导入多进程模块</code></pre><h4 id="2-创建类并初始化"><a href="#2-创建类并初始化" class="headerlink" title="2. 创建类并初始化"></a>2. 创建类并初始化</h4><p><strong>初始化出部分需要的属性 方便之后方法的使用</strong><br>port 主机需要绑定的端口</p><pre><code class="python">class WebServer(object):    BASE_DIR = os.path.join(os.getcwd(), &#39;static&#39;)  # 查询文件夹， 用来查找访问的文件    RESPONSE_STATUS = {200: &#39;OK&#39;, 404: &#39;Not Found&#39;, 403: &#39;Forbid&#39;}  # 设置响应行可选返回状态码， 只选择了部分做演示    def __init__(self, port=8080):        &quot;&quot;&quot;        初始化参数        :param port:        &quot;&quot;&quot;        self.soc = self.create_server(port)  # 初始化socket对象        self.new_fd: socket.socket = ...  # 方便pycharm提示,防止pycharm报波浪线        self.request_dict = {}  # 设置空字典， 用于存储处理过后的请求头        self.response_dict = [(&#39;Server&#39;, &#39;my_server&#39;), (&#39;Content-Type&#39;, &#39;text/html; charset=utf-8&#39;)]  # 设置响应头，因为可能有多个Set-Cookie， 所以用列表中的元组存储</code></pre><h4 id="3-初始化socket对象-固定四部曲"><a href="#3-初始化socket对象-固定四部曲" class="headerlink" title="3. 初始化socket对象 固定四部曲"></a>3. 初始化socket对象 固定四部曲</h4><ol><li>创建socket对象</li><li>绑定address， ip及端口</li><li>防止服务器异常时， 端口的占用， 影响服务器的重启</li><li>转成监听模式<pre><code class="python"> # 创建socket对象 def create_server(self, port):     &quot;&quot;&quot;     用来初始化server对象     :return:     &quot;&quot;&quot;     self.soc = socket.socket()  # 创建socket对象     self.soc.bind((&#39;&#39;, port))  # 绑定套接字到address， 一般为 ip+port， 并且host一般是127.0.0.1或者不填(等内核分配)，一般无权绑定非本机ip     self.soc.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)  # 接续服务器突然宕掉时，端口暂时不能使用的问题     self.soc.listen(5)  # 转为监听状态 服务器必须     return self.soc</code></pre><h4 id="4-多进程接受请求"><a href="#4-多进程接受请求" class="headerlink" title="4. 多进程接受请求"></a>4. 多进程接受请求</h4></li><li>accept() 从缓存中拿出连接描述符 此处为 阻塞IO 加入子进程</li><li>创建子进程 此处为 阻塞IO 在子进程中处理</li><li>开启子进程</li><li>剪掉主进程对描述符的引用<pre><code class="python"> # 开启多进程 def runserver(self):     &quot;&quot;&quot;     多进程处理请求     :return:     &quot;&quot;&quot;     while True:         self.new_fd, _ = self.soc.accept()  # 从缓存中读取新的请求         fd = Process(target=self.handler)  # 转到子进程中执行         fd.start()  # 开启进程         self.new_fd.close()  # 去掉主进程引用</code></pre><h4 id="5-接受描述符发送的信息"><a href="#5-接受描述符发送的信息" class="headerlink" title="5. 接受描述符发送的信息"></a>5. 接受描述符发送的信息</h4></li></ol><pre><code class="python">    # 接收请求头    def handler(self):        &quot;&quot;&quot;        处理发送过来的信息        :return:        &quot;&quot;&quot;        print(&#39;新的链接到来，&#39;, self.new_fd)        buf: bytes = self.new_fd.recv(1024)  # 读取部分数据，主要用来处理请求行和请求头        if buf:            new_buf = buf.decode(&#39;utf8&#39;)  # 将二进制数据转成str            # 解析字符串            self._request_handler(new_buf)</code></pre><h4 id="6-处理请求头"><a href="#6-处理请求头" class="headerlink" title="6. 处理请求头"></a>6. 处理请求头</h4><ol><li>处理请求行， 推荐使用 splitlines()进行分割， split(‘\r\n’)在跨平台时不好用</li><li>处理请求体</li><li>获取文件路径</li><li>进行后续处理</li></ol><pre><code class="python">    # 解析请求头    def _request_handler(self, data: str):        &quot;&quot;&quot;        浏览器请求 格式固定        请求行: GET / HTTP/1.1\r\n        请求头: Host: 127.0.0.1\r\n               User-Agent: Mozilla5.0...\r\n        请求体: 基本为固定为POST 的内容， 此处不演示        :param data:        :return:        &quot;&quot;&quot;        data = data.splitlines()  # 进行行分割        request_head = data.pop(0).strip()  # 接受请求行        self.request_dict[&#39;Method&#39;], self.request_dict[&#39;Path&#39;], _ = request_head.split(&#39; &#39;)  # 生成请求行字典        # 遍历data部分,得到请求头信息 Host: 127.0.0.1 列表中的格式        new_data = {x[0]: x[1] for x in [i.split(&#39;:&#39;) for i in data if &#39;: &#39; in i]}        # 更新字典        self.request_dict.update(new_data)        # 获取请求路径        self.filename = self.request_dict[&#39;Path&#39;][1:]  # 获取请求的url        os.chdir(self.BASE_DIR)  # 改变查找文件        self._response_handler()</code></pre><h4 id="7-拼接及发送响应头"><a href="#7-拼接及发送响应头" class="headerlink" title="7. 拼接及发送响应头"></a>7. 拼接及发送响应头</h4><ol><li><p>等待状态码的返回</p></li><li><p>根据不同状态吗 拼接不同的响应行</p></li><li><p>拼接响应头</p></li><li><p>发送响应头</p></li><li><p>处理响应体</p><pre><code class="python"># 发送响应头 def _response_handler(self):     &quot;&quot;&quot;     响应体的格式     响应行: HTTP/1.1 200 OK\r\n     响应头: Content-Type:text/html; charset=utf-8\r\n            Server: My_server\r\n     响应体: HTML/JSON/JPG/PNG/MP3.....     &quot;&quot;&quot;     self.status = self._check_request()     response_head = f&quot;HTTP/1.1 {self.status} {self.RESPONSE_STATUS[self.status]}\r\n&quot;  # 组成请求行     response_content = &#39;&#39;.join([i[0] + &#39;: &#39; + i[1] + &#39;\r\n&#39; for i in self.response_dict])  # 组成请求头     response_end = &#39;\r\n&#39;  # 换行  头部结束     self.response = response_head + response_content + response_end     # 发送请求头信息     self.new_fd.send(self.response.encode(&#39;utf8&#39;))     self.send_response()</code></pre><h4 id="8-判断状态码，简单判断，有资源返回200，没有资源返回404"><a href="#8-判断状态码，简单判断，有资源返回200，没有资源返回404" class="headerlink" title="8. 判断状态码，简单判断，有资源返回200，没有资源返回404"></a>8. 判断状态码，简单判断，有资源返回200，没有资源返回404</h4></li><li><p>判断是否是文件</p><pre><code class="python"> @set_status def _check_request(self):     &quot;&quot;&quot;     给出返回值， 403用装饰器装饰     :return:     &quot;&quot;&quot;     if os.path.isfile(self.filename):         return 200     else:         return 404</code></pre><h4 id="9-装饰器添加User-Agent验证"><a href="#9-装饰器添加User-Agent验证" class="headerlink" title="9. 装饰器添加User-Agent验证"></a>9. 装饰器添加User-Agent验证</h4></li><li><p>在类外面定义装饰器函数，</p></li><li><p>进行User-Agent判断</p><pre><code class="python">def set_status(fun): &quot;&quot;&quot; 返回值的装饰器, 增加User-Agent判断代理是否异常， 返回403 :param fun: :return: &quot;&quot;&quot; def change(self, *args, **kwargs):     if len(self.request_dict[&#39;User-Agent&#39;]) &lt; 60:         return 403     else:         return fun(self, *args, **kwargs) return change</code></pre><h4 id="10-发送响应体，关闭连接"><a href="#10-发送响应体，关闭连接" class="headerlink" title="10. 发送响应体，关闭连接"></a>10. 发送响应体，关闭连接</h4></li></ol><ul><li>根据不同的返回值，决定如何返回<pre><code class="python">  # 发送响应体内容  def send_response(self):      if self.status == 200:          # 正常访问页面          with open(self.filename, &#39;rb&#39;) as f:              self.new_fd.send(f.read())      elif self.status == 404:          # 打开404页面          with open(&#39;404.html&#39;, &#39;rb&#39;) as f:              self.new_fd.send(f.read())      elif self.status == 403:          self.new_fd.send(&#39;ForForForbid&#39;.encode(&#39;utf8&#39;))  # 皮一下</code></pre>github上的完整代码 <a href="https://github.com/Dustyposa/segementfault/blob/master/web_server.py" target="_blank" rel="noopener">web_server</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>网络</category>
      
      <category>服务器</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python3</tag>
      
      <tag>server</tag>
      
      <tag>socket</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
